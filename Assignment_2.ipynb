{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GYkJ0fHwEEt"
      },
      "source": [
        "# Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCVj-3kVvSV7",
        "outputId": "61a51b07-4f81-4bb3-d3aa-1a4ab2554bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.15-py3-none-any.whl (5.6 kB)\n",
            "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.7-py3-none-any.whl (25 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.15 (from llama-index)\n",
            "  Downloading llama_index_core-0.10.15-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.3-py3-none-any.whl (6.6 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.1.7-py3-none-any.whl (9.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.6-py3-none-any.whl (34 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
            "Collecting llama-index-vector-stores-chroma<0.2.0,>=0.1.1 (from llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading llama_index_vector_stores_chroma-0.1.5-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (3.9.3)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.15->llama-index)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.15->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.15->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (0.27.0)\n",
            "Collecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.15->llama-index)\n",
            "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (1.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (1.5.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.15->llama-index)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (4.10.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.15->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.3.5-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.15->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.15->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.15->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.14.1)\n",
            "Collecting chromadb<0.5.0,>=0.4.22 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime<2.0.0,>=1.17.0 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.16.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.15.2)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.15->llama-index) (2.6.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.15->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.15->llama-index) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.7.0)\n",
            "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.15->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.15->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.15->llama-index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.15->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.15->llama-index)\n",
            "  Downloading marshmallow-3.21.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.15->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.15->llama-index) (2023.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.2.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.0.3)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (6.1.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.62.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.9.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.15->llama-index) (23.2)\n",
            "Collecting coloredlogs (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.12)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.15->llama-index) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.15->llama-index) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.16.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.20.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (2.0.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.13.1)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.2.2)\n",
            "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.62.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (67.7.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.17.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.5.1)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=fffdca06e26a22603ea61506f7515ebf47be9bb0a7499c0818348f443f600e5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, dirtyjson, websockets, uvloop, uvicorn, python-dotenv, pypdf, PyMuPDFb, pulsar-client, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, marshmallow, importlib-metadata, humanfriendly, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, tiktoken, starlette, pymupdf, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, bs4, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, llamaindex-py-client, kubernetes, fastapi, dataclasses-json, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, llama-index-legacy, llama-index-core, opentelemetry-instrumentation-fastapi, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-agent-openai, chromadb, llama-index-vector-stores-chroma, llama-index-program-openai, llama-index-question-gen-openai, llama-index-cli, llama-index\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed PyMuPDFb-1.23.22 asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 bs4-0.0.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 fastapi-0.110.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-6.11.0 kubernetes-29.0.0 llama-index-0.10.15 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.7 llama-index-core-0.10.15 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.3 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.7 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.6 llama-index-readers-llama-parse-0.1.3 llama-index-vector-stores-chroma-0.1.5 llama-parse-0.3.5 llamaindex-py-client-0.1.13 marshmallow-3.21.0 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.17.1 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.4.0 pymupdf-1.23.26 pypdf-4.1.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.36.3 tiktoken-0.6.0 typing-inspect-0.9.0 uvicorn-0.27.1 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n",
            "Collecting trulens_eval\n",
            "  Downloading trulens_eval-0.24.1-py3-none-any.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.5/662.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (1.25.2)\n",
            "Requirement already satisfied: frozendict>=2.3.8 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (2.4.0)\n",
            "Collecting munch>=3.0.0 (from trulens_eval)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting dill>=0.3.7 (from trulens_eval)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (4.66.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (2.31.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (1.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (4.10.0)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (1.0.1)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (2.6.3)\n",
            "Collecting merkle-json>=1.0.0 (from trulens_eval)\n",
            "  Downloading merkle_json-1.0.0-py3-none-any.whl (5.2 kB)\n",
            "Collecting langchain>=0.0.354 (from trulens_eval)\n",
            "  Downloading langchain-0.1.10-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.2/806.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core>=0.1.6 (from trulens_eval)\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (0.9.0)\n",
            "Collecting millify>=0.1.1 (from trulens_eval)\n",
            "  Downloading millify-0.1.1.tar.gz (1.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: humanize>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (4.7.0)\n",
            "Collecting streamlit>=1.31.1 (from trulens_eval)\n",
            "  Downloading streamlit-1.31.1-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-aggrid>=0.3.4.post3 (from trulens_eval)\n",
            "  Downloading streamlit_aggrid-0.3.4.post3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-extras>=0.2.7 (from trulens_eval)\n",
            "  Downloading streamlit_extras-0.4.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=2.0.19 in /usr/local/lib/python3.10/dist-packages (from trulens_eval) (2.0.27)\n",
            "Collecting alembic>=1.11.2 (from trulens_eval)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic>=1.11.2->trulens_eval)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.354->trulens_eval) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.354->trulens_eval) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.354->trulens_eval) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.354->trulens_eval) (0.6.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain>=0.0.354->trulens_eval)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain>=0.0.354->trulens_eval)\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain>=0.0.354->trulens_eval)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain>=0.0.354->trulens_eval)\n",
            "  Downloading langsmith-0.1.14-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.354->trulens_eval) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core>=0.1.6->trulens_eval) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core>=0.1.6->trulens_eval) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->trulens_eval) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->trulens_eval) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->trulens_eval) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->trulens_eval) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->trulens_eval) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->trulens_eval) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.19->trulens_eval) (3.0.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=1.31.1->trulens_eval) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<8,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (6.11.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (14.0.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (2.8.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (13.7.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit>=1.31.1->trulens_eval)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit>=1.31.1->trulens_eval)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit>=1.31.1->trulens_eval)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.1->trulens_eval) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit>=1.31.1->trulens_eval)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-decouple<4.0,>=3.6 (from streamlit-aggrid>=0.3.4.post3->trulens_eval)\n",
            "  Downloading python_decouple-3.8-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: entrypoints>=0.4 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens_eval) (0.4)\n",
            "Collecting htbuilder>=0.6.2 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading htbuilder-0.6.2-py3-none-any.whl (12 kB)\n",
            "Collecting markdownlit>=0.0.5 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading markdownlit-0.0.7-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.2.7->trulens_eval) (0.20.0)\n",
            "Collecting st-annotated-text>=3.0.0 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading st_annotated_text-4.0.1-py3-none-any.whl (9.0 kB)\n",
            "Collecting streamlit-camera-input-live>=0.2.0 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl (6.6 kB)\n",
            "Collecting streamlit-card>=0.0.4 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading streamlit_card-1.0.0-py3-none-any.whl (680 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-embedcode>=0.1.2 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading streamlit_embedcode-0.1.2-py3-none-any.whl (3.5 kB)\n",
            "Collecting streamlit-faker>=0.0.2 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading streamlit_faker-0.0.3-py3-none-any.whl (14 kB)\n",
            "Collecting streamlit-image-coordinates<0.2.0,>=0.1.1 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading streamlit_image_coordinates-0.1.6-py3-none-any.whl (6.3 kB)\n",
            "Collecting streamlit-keyup>=0.1.9 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading streamlit_keyup-0.2.3-py3-none-any.whl (7.4 kB)\n",
            "Collecting streamlit-toggle-switch>=1.0.2 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl (635 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-vertical-slider>=2.5.5 (from streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading streamlit_vertical_slider-2.5.5-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->trulens_eval) (1.0.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.354->trulens_eval) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.354->trulens_eval) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.354->trulens_eval) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.354->trulens_eval) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.354->trulens_eval) (1.9.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.31.1->trulens_eval) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.31.1->trulens_eval) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.31.1->trulens_eval) (0.12.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core>=0.1.6->trulens_eval) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core>=0.1.6->trulens_eval) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.354->trulens_eval) (3.21.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.31.1->trulens_eval)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from htbuilder>=0.6.2->streamlit-extras>=0.2.7->trulens_eval) (10.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<8,>=1.4->streamlit>=1.31.1->trulens_eval) (3.17.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain>=0.0.354->trulens_eval)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain>=0.0.354->trulens_eval) (3.9.15)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens_eval) (3.5.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens_eval) (4.9.4)\n",
            "Collecting favicon (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading favicon-0.7.0-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting pymdown-extensions (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading pymdown_extensions-10.7-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=1.31.1->trulens_eval) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=1.31.1->trulens_eval) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.31.1->trulens_eval) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.31.1->trulens_eval) (2.16.1)\n",
            "Collecting faker (from streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens_eval)\n",
            "  Downloading Faker-23.3.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens_eval) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.11.2->trulens_eval) (2.1.5)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.31.1->trulens_eval)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.31.1->trulens_eval) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.31.1->trulens_eval) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.31.1->trulens_eval) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.31.1->trulens_eval) (0.1.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from favicon->markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens_eval) (4.12.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens_eval) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens_eval) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens_eval) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens_eval) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens_eval) (3.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.7.0->favicon->markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens_eval) (2.5)\n",
            "Building wheels for collected packages: millify\n",
            "  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for millify: filename=millify-0.1.1-py3-none-any.whl size=1845 sha256=1a31adc4510f6e9e1e591c19c509ef2f6a96b27729169496727e586f56319587\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/8f/53/2759feac2e247ce89c1165c3ff12d484de7714a875ea3464f0\n",
            "Successfully built millify\n",
            "Installing collected packages: python-decouple, millify, watchdog, validators, smmap, pymdown-extensions, munch, merkle-json, Mako, jsonpointer, htbuilder, dill, st-annotated-text, pydeck, jsonpatch, gitdb, favicon, faker, alembic, langsmith, gitpython, langchain-core, streamlit, langchain-text-splitters, langchain-community, streamlit-vertical-slider, streamlit-toggle-switch, streamlit-keyup, streamlit-image-coordinates, streamlit-embedcode, streamlit-card, streamlit-camera-input-live, streamlit-aggrid, langchain, streamlit-faker, markdownlit, streamlit-extras, trulens_eval\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 dill-0.3.8 faker-23.3.0 favicon-0.7.0 gitdb-4.0.11 gitpython-3.1.42 htbuilder-0.6.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.10 langchain-community-0.0.25 langchain-core-0.1.28 langchain-text-splitters-0.0.1 langsmith-0.1.14 markdownlit-0.0.7 merkle-json-1.0.0 millify-0.1.1 munch-4.0.0 pydeck-0.8.1b0 pymdown-extensions-10.7 python-decouple-3.8 smmap-5.0.1 st-annotated-text-4.0.1 streamlit-1.31.1 streamlit-aggrid-0.3.4.post3 streamlit-camera-input-live-0.2.0 streamlit-card-1.0.0 streamlit-embedcode-0.1.2 streamlit-extras-0.4.0 streamlit-faker-0.0.3 streamlit-image-coordinates-0.1.6 streamlit-keyup-0.2.3 streamlit-toggle-switch-1.0.2 streamlit-vertical-slider-2.5.5 trulens_eval-0.24.1 validators-0.22.0 watchdog-4.0.0\n",
            "Collecting pymilvus\n",
            "  Downloading pymilvus-2.3.6-py3-none-any.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=67 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (67.7.2)\n",
            "Collecting grpcio<=1.60.0,>=1.49.1 (from pymilvus)\n",
            "  Downloading grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (3.20.3)\n",
            "Collecting environs<=9.5.0 (from pymilvus)\n",
            "  Downloading environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting ujson>=2.0.0 (from pymilvus)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.31.0)\n",
            "Collecting minio>=7.0.0 (from pymilvus)\n",
            "  Downloading minio-7.2.5-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (14.0.2)\n",
            "Requirement already satisfied: marshmallow>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from environs<=9.5.0->pymilvus) (3.21.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from environs<=9.5.0->pymilvus) (1.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus) (2024.2.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus) (2.0.7)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus) (23.1.0)\n",
            "Collecting pycryptodome (from minio>=7.0.0->pymilvus)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus) (4.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pymilvus) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pymilvus) (3.6)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.4->pymilvus) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio>=7.0.0->pymilvus) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus) (2.21)\n",
            "Installing collected packages: ujson, pycryptodome, grpcio, environs, minio, pymilvus\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.62.0\n",
            "    Uninstalling grpcio-1.62.0:\n",
            "      Successfully uninstalled grpcio-1.62.0\n",
            "Successfully installed environs-9.5.0 grpcio-1.60.0 minio-7.2.5 pycryptodome-3.20.0 pymilvus-2.3.6 ujson-5.9.0\n",
            "Collecting llama-index-vector-stores-milvus\n",
            "  Downloading llama_index_vector_stores_milvus-0.1.4-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-milvus) (0.10.15)\n",
            "Requirement already satisfied: pymilvus<3.0.0,>=2.3.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-milvus) (2.3.6)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (0.1.13)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.5.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (4.10.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=67 in /usr/local/lib/python3.10/dist-packages (from pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (67.7.2)\n",
            "Requirement already satisfied: grpcio<=1.60.0,>=1.49.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (1.60.0)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (3.20.3)\n",
            "Requirement already satisfied: environs<=9.5.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (9.5.0)\n",
            "Requirement already satisfied: ujson>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (5.9.0)\n",
            "Requirement already satisfied: minio>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (7.2.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (14.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (4.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.14.1)\n",
            "Requirement already satisfied: marshmallow>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from environs<=9.5.0->pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (3.21.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from environs<=9.5.0->pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (1.0.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (2.6.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (0.14.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (2.0.7)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (23.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (3.20.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-milvus) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio>=7.0.0->pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus<3.0.0,>=2.3.6->llama-index-vector-stores-milvus) (2.21)\n",
            "Installing collected packages: llama-index-vector-stores-milvus\n",
            "Successfully installed llama-index-vector-stores-milvus-0.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install llama-index\n",
        "!pip install trulens_eval\n",
        "!pip install pymilvus\n",
        "!pip install llama-index-vector-stores-milvus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG4jdhefwIZZ"
      },
      "source": [
        "# Coding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "i_J5b2ZrvGdy"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bZML0tLRi6o"
      },
      "source": [
        "Standard LlamaIndex query engine. Using VectorStoreIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "GfT-m3P5wCZb"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader\n",
        "documents=SimpleDirectoryReader(\"preprocessed_data\").load_data()\n",
        "# print(\"Document ID:\", documents[0].doc_id) seeing what the doc looks like\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine(similarity_top_k=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HXYDiFdgDdC"
      },
      "source": [
        "Retrievers and postprocessors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RsHc3On2gDNT"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "\n",
        "retriever=VectorIndexRetriever(index=index,similarity_top_k=4)\n",
        "postprocessor=SimilarityPostprocessor(similarity_cutoff=0.8)\n",
        "\n",
        "query_engine=RetrieverQueryEngine(retriever=retriever,\n",
        "                                  node_postprocessors=[postprocessor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqcw7ZpCf23W"
      },
      "source": [
        "Using Milvus as the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "ROvsxToMuxbI",
        "outputId": "0ba4a40f-8970-4c5a-9ed8-b8f27acb0be4"
      },
      "outputs": [],
      "source": [
        "from pymilvus import connections, Collection\n",
        "MILVUS_HOST = 'localhost'  # the location on my laptop in which milvus is running\n",
        "MILVUS_PORT = '2379'\n",
        "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "UVUbIfeMf2Qp",
        "outputId": "39c9971c-7113-4a2b-cd26-bb92ae3596a1"
      },
      "outputs": [],
      "source": [
        "#Setting up the vecor store.\n",
        "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
        "from llama_index.core.storage.storage_context import StorageContext\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "vector_store = MilvusVectorStore(dim=1536, host=\"localhost\", port=19530, overwrite=True)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")\n",
        "\n",
        "# Retriever and Postproccesor query engine as this produced best results in early testing\n",
        "retriever=VectorIndexRetriever(index=index,similarity_top_k=4)\n",
        "postprocessor=SimilarityPostprocessor(similarity_cutoff=0.8)\n",
        "\n",
        "query_engine=RetrieverQueryEngine(retriever=retriever,\n",
        "                                  node_postprocessors=[postprocessor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7zZ55FOQOgO"
      },
      "source": [
        "Running questions - this is just for when I was testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JRc3EVnQNxc",
        "outputId": "919d6e24-c61d-4da3-b6f2-d03c25be93ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Insufficient sleep can lead to various negative effects on the body, such as reduced blood flow to the skin in the face, resulting in a dull complexion with dark areas. It can also cause dark circles under the eyes, more wrinkles due to decreased collagen production, puffy eyes, and a lack of a healthy glow. Additionally, insufficient sleep can impact overall appearance, making individuals appear less happy.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.response.pprint_utils import pprint_response\n",
        "response = query_engine.query(\"What happens to my body if I do not get enough sleep?\")\n",
        "pprint_response(response,show_source=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbYI2XNwPrIw"
      },
      "source": [
        "Import Tru Lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "oSuO3_oOQRf5"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import Tru\n",
        "tru = Tru()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfsEi9S7QZQC"
      },
      "source": [
        "Creating the feedback functions that will be used in evaluation of the RAG LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btY0SlNsQYjH",
        "outputId": "fbde86df-db0b-457d-845e-d2550d2d43e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ In groundedness_measure_with_cot_reasons, input source will be set to __record__.app.query.rets.source_nodes[:].node.text.collect() .\n",
            "✅ In groundedness_measure_with_cot_reasons, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "✅ In relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "✅ In qs_relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In qs_relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize provider class\n",
        "from trulens_eval.feedback.provider.openai import OpenAI\n",
        "openai = OpenAI()\n",
        "\n",
        "# select context to be used in feedback. the location of context is app specific.\n",
        "from trulens_eval.app import App\n",
        "context = App.select_context(query_engine)\n",
        "\n",
        "# imports for feedback\n",
        "from trulens_eval import Feedback\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "from trulens_eval.feedback import Groundedness\n",
        "grounded = Groundedness(groundedness_provider=OpenAI())\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
        "    .on(context.collect()) # collect context chunks into a list\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_qs_relevance = (\n",
        "    Feedback(openai.qs_relevance)\n",
        "    .on_input()\n",
        "    .on(context)\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZf5IahbQxlK"
      },
      "source": [
        "To asses the model we wrap the query engine in a TruLLama instance to asses the model, at this point we also name the app to identify it later. We also provide the feedback functions created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "QEfM8c8BQvn0"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruLlama\n",
        "tru_query_engine_recorder = TruLlama(query_engine,\n",
        "    app_id='LlamaIndex_App8',\n",
        "    feedbacks=[f_groundedness, f_qa_relevance, f_qs_relevance])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dmKiT_1Qm3h"
      },
      "source": [
        "Retrieve records and feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "H0cay2LoUodU"
      },
      "outputs": [],
      "source": [
        "with tru_query_engine_recorder as recording:\n",
        "    query_engine.query(\"Can you list ways that heart rate can be measured?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H6uUNK5uQloT",
        "outputId": "7fad4fe0-68c7-47c9-caf9-cdbc92c0fd13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Record(record_id='record_hash_fbe810723cfff883cbd72a36efbbfd02', app_id='LlamaIndex_App8', cost=Cost(n_requests=2, n_successful_requests=2, n_classes=0, n_tokens=1131, n_stream_chunks=0, n_prompt_tokens=1106, n_completion_tokens=25, cost=0.0016925), perf=Perf(start_time=datetime.datetime(2024, 3, 4, 16, 59, 34, 566721), end_time=datetime.datetime(2024, 3, 4, 16, 59, 37, 610590)), ts=datetime.datetime(2024, 3, 4, 16, 59, 37, 611851), tags='-', meta=None, main_input='Can you list ways that heart rate can be measured?', main_output='Heart rate can be measured by listening to the chest and sensing minute changes in blood flow via photoplethysmography.', main_error=None, calls=[RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='retrieve')), RecordAppCallMethod(path=Lens().app._retriever, method=Method(obj=Obj(cls=llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever, id=140331591789456, init_bindings=None), name='retrieve')), RecordAppCallMethod(path=Lens().app._retriever, method=Method(obj=Obj(cls=llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever, id=140331591789456, init_bindings=None), name='_retrieve'))], args={'query_bundle': {'query_str': 'Can you list ways that heart rate can be measured?', 'image_path': None, 'custom_embedding_strs': None, 'embedding': [-0.029710588976740837, 0.024593038484454155, 0.009318916127085686, -0.031202662736177444, -0.0030937623232603073, 0.01523485779762268, -0.007545442786067724, -0.001422541681677103, -0.023009346798062325, -0.0006470560911111534, -0.001627047429792583, 0.04025981202721596, -0.021294770762324333, 0.005938845686614513, 0.004103202372789383, -0.004937585908919573, 0.03620241954922676, 0.03256385400891304, 0.01662222482264042, -0.014331759884953499, -0.025509225204586983, 0.012113282456994057, -0.002957970602437854, 0.01655678264796734, -0.034945935010910034, 0.017878707498311996, 0.023912442848086357, 0.00013282646250445396, 0.007067717146128416, 0.0031837448477745056, 0.03664742410182953, -0.013860578648746014, -0.030129417777061462, -0.036359477788209915, -0.025941140949726105, 0.007767945062369108, -0.004387874621897936, 0.010496868751943111, 0.007807210087776184, -0.004083570092916489, 0.013808225281536579, 0.013585723005235195, -0.007172424346208572, -0.0001872249849839136, -0.01265644934028387, 0.01591545157134533, 0.006589991971850395, -0.015692949295043945, -0.023689942434430122, 0.014881471171975136, 0.014043816365301609, -0.013193072751164436, 0.0002362040977459401, -0.0017832898302003741, 0.005582187790423632, -0.012034752406179905, 0.038479793816804886, 0.030181771144270897, 0.0045678396709263325, -0.04002422094345093, -0.005140455439686775, -0.0013988190330564976, -0.010143483057618141, 0.02454068511724472, -0.017917972058057785, -0.005254978779703379, 0.006612896453589201, 0.01475058775395155, 0.013160351663827896, 0.0025227824226021767, 0.0055167460814118385, 0.004397690761834383, -0.011085845530033112, 0.023860089480876923, 0.017250465229153633, -0.018821069970726967, -0.0006957284058444202, -0.027328507974743843, 0.01149812899529934, 0.02073197066783905, 0.004773981403559446, -0.0003589075349736959, -0.020954472944140434, 0.027249976992607117, 0.01587618701159954, -0.010732459835708141, -0.008782293647527695, 0.0036483819130808115, 0.010994226671755314, -0.006668522022664547, 0.018991218879818916, 0.005811234470456839, -0.009750831872224808, 0.011897324584424496, 0.006982643157243729, 0.004489309154450893, 0.0027387405280023813, 0.019475487992167473, -0.0017260281601920724, 0.002846719464287162, -0.010182748548686504, 0.004826334770768881, -0.022001542150974274, -0.014973090030252934, -0.02086285501718521, -0.017603851854801178, 0.0035534913185983896, -0.02952735312283039, 0.0036385655403137207, -0.012898583896458149, -0.026988210156559944, 0.03361092135310173, 0.014436467550694942, -0.01681854948401451, 0.0011599564459174871, -0.0054611205123364925, 0.010365985333919525, -0.0034618726931512356, -0.009881716221570969, 0.0014953457284718752, 0.028297046199440956, 0.019567105919122696, 0.04439573734998703, -0.010195836424827576, 0.015247945673763752, -0.010287455283105373, -0.018245181068778038, -0.00036831479519605637, 0.014371025376021862, -0.006190796848386526, 0.014907647855579853, -0.0050782859325408936, -0.006661978084594011, 0.008821558207273483, -0.022930815815925598, -0.003123211208730936, 0.01422705315053463, 0.021635068580508232, -0.013952197507023811, -0.007427647244185209, -0.0007967542624101043, -0.002825450850650668, 0.00176529330201447, -0.013716607354581356, -0.013101453892886639, 0.032720912247896194, 0.017171936109662056, 0.013795137405395508, 0.0026945671997964382, -0.013664253987371922, -0.011511217802762985, -0.004531846381723881, 0.017878707498311996, 0.009521786123514175, -0.015653684735298157, 0.0066390736028552055, 0.0011836790945380926, 0.0034553285222500563, -0.004754348658025265, -0.003982135094702244, 0.006917200982570648, 0.020286966115236282, 0.02535216324031353, -0.002185757039114833, -0.01692325621843338, 0.007957725785672665, 0.01857239007949829, -0.029605882242321968, 0.0088477348908782, 0.0005754790618084371, -0.00971156731247902, 0.03293032571673393, -0.020286966115236282, 0.022224044427275658, 0.0120543846860528, -0.004659458063542843, -0.0031853809487074614, -0.014357936568558216, -0.017983414232730865, -0.040233634412288666, -0.023100964725017548, -0.004934313707053661, 0.010810989886522293, -0.0023820826318114996, -0.007336028851568699, 0.020378585904836655, 0.007918461225926876, -0.004093386232852936, 0.020849766209721565, -0.029946180060505867, -0.006262782961130142, -0.00992752518504858, -0.011341068893671036, -0.022093160077929497, -0.6659360527992249, -0.030260300263762474, -0.009318916127085686, -0.012806965969502926, 0.04400308430194855, 0.018768716603517532, 0.008729939348995686, 0.0025669557508081198, -0.014973090030252934, 0.03410828113555908, 0.001125599374063313, 0.004819790367037058, -0.0011885871645063162, -0.01908283680677414, -0.0009333640919066966, -0.02730233035981655, -0.001274479553103447, 0.0034160634968429804, -0.003717095823958516, -0.010267823003232479, -0.03408210352063179, -0.004881960339844227, -0.01299674715846777, 0.012159091420471668, -0.00638057803735137, 0.022080073133111, -0.0014094533398747444, 0.002874532248824835, -0.015208681114017963, 0.005742520559579134, -0.0009619948687031865, 0.0023771743290126324, 0.019776519387960434, 0.014907647855579853, 0.03149060904979706, -0.02272140234708786, -0.01850694790482521, 0.034605637192726135, -0.02302243560552597, 0.039055682718753815, -0.02571863867342472, -0.01119055226445198, 0.03141207620501518, -0.022459635511040688, -0.02845410630106926, 0.009790097363293171, 0.006112266797572374, 0.014357936568558216, 0.005434943828731775, -0.014567350968718529, 0.0012262162053957582, -0.022459635511040688, -0.002247926779091358, 0.01975034363567829, -3.47404093190562e-05, -0.006599808111786842, 0.020902119576931, 0.0163473691791296, -0.021517273038625717, 0.02244654670357704, 0.003972318954765797, 0.013258513994514942, 0.000390401401091367, -0.0295011755079031, -0.004767436999827623, 0.01728973165154457, -0.04065246134996414, -0.017237376421689987, -0.008893544785678387, -0.03382033482193947, -0.0010429790709167719, -0.007630517240613699, -0.0021546720527112484, 0.009718111716210842, 0.02094138413667679, 0.011622468940913677, 0.03253767639398575, -0.010424883104860783, -0.005853771232068539, -0.009292739443480968, -0.00045727475662715733, 0.011890780180692673, -0.01880798116326332, 0.01080444548279047, -0.003396430751308799, 0.022263308987021446, -0.012512477114796638, 0.009011339396238327, 0.024252740666270256, 0.0029268856160342693, 0.0005705709336325526, 0.029658235609531403, 0.00804280024021864, -0.02130785956978798, -0.019527841359376907, 0.011956221424043179, 0.0002527690667193383, -0.007264042738825083, 0.001180407009087503, -0.005254978779703379, -0.01159629225730896, 0.004427139647305012, 0.0027485566679388285, 0.00954141840338707, -0.004675818607211113, -0.013677341863512993, -0.024828629568219185, 0.0008016623905859888, 0.024462155997753143, -0.027119092643260956, -0.025469958782196045, -0.02905617095530033, -0.00869721919298172, 0.019344603642821312, 0.003216465702280402, -0.035548001527786255, 0.015850011259317398, 0.016438987106084824, 0.008363465778529644, -0.007826842367649078, 0.024802451953291893, -0.005935573950409889, 0.047955770045518875, -0.01080444548279047, -0.0007202691049315035, 0.007866107858717442, -0.020993737503886223, -0.001366916112601757, 0.021347124129533768, -0.027119092643260956, 0.0024017151445150375, -0.01918754354119301, -0.0003885608457494527, -0.016975609585642815, 0.0073491171933710575, 0.019540930166840553, 0.014449555426836014, 0.015692949295043945, -0.0050619253888726234, -0.023545969277620316, -0.011033492162823677, -0.006285687442868948, 0.00852707028388977, -0.016870902851223946, -0.005048837047070265, -0.021059179678559303, -0.002261015120893717, 0.014672057703137398, 0.010267823003232479, 0.0013096545590087771, -0.006410026922821999, -0.03816567361354828, -0.0044565885327756405, -0.0006965464563108981, 0.010208925232291222, -0.006383850239217281, -0.0063216807320714, -0.03444857895374298, -0.017486056312918663, -0.018297534435987473, 0.023218760266900063, 0.021425655111670494, -0.021621979773044586, 0.004132651258260012, -0.006351129151880741, -0.007002275437116623, 0.0022921001072973013, -0.004041032865643501, -0.008900088258087635, -0.028532637283205986, 0.020614175125956535, 0.0021972092799842358, -0.01353336963802576, 0.024265829473733902, 0.0003014414105564356, 0.03256385400891304, -0.0126433614641428, -0.012702258303761482, -0.005156815983355045, -0.013304323889315128, 0.02026079036295414, 0.02103300392627716, -0.01998593471944332, 0.004636553581804037, 0.022878462448716164, 0.006871392019093037, -0.008906632661819458, 0.011589747853577137, -0.01570603810250759, 0.021412566304206848, 0.007996991276741028, 0.008939353749155998, -0.007283675484359264, 0.013978374190628529, 0.01624266244471073, -0.0020614175591617823, -0.0014487184816971421, -0.0034095190931111574, 0.01773473434150219, 0.033087387681007385, 0.021347124129533768, 0.005886492319405079, 0.009142223745584488, -0.006508189719170332, 0.03463181480765343, -0.0031412076205015182, 0.014030727557837963, -0.020993737503886223, 0.01412234641611576, 0.02019534818828106, -0.012355417013168335, 0.003458600491285324, 0.010078041814267635, -0.021124621853232384, -0.009515241719782352, 0.007336028851568699, 0.0015689678257331252, 0.012564830482006073, 0.014069993048906326, 0.011367245577275753, 0.0411236435174942, 2.998564923473168e-05, 0.027721157297492027, 0.006452564150094986, -0.008579423651099205, 0.011537394486367702, 0.012322695925831795, 0.023284202441573143, 0.006406754720956087, -0.014658968895673752, 0.00829147920012474, -0.0027649172116070986, 0.009129134938120842, 0.01827135868370533, 0.008867367170751095, 0.0266348235309124, 0.0123030636459589, -0.00016299105482175946, 0.014894559979438782, 0.03751125559210777, 0.008199861273169518, -0.007761400658637285, 0.010568855330348015, -0.017944149672985077, 0.032747089862823486, 0.009528330527245998, 0.016098689287900925, -0.0024295279290527105, 0.014541174285113811, 0.003087218152359128, 0.00023538607638329268, -0.019396957010030746, -0.026032758876681328, 0.02238110452890396, 0.0019665269646793604, -0.015797657892107964, 0.021765951067209244, -0.0005284427315928042, -0.015313387848436832, 0.014946913346648216, 0.028977641835808754, 0.020705794915556908, 0.03081001155078411, -0.007388382218778133, -0.008644865825772285, 0.010876432061195374, -0.0032835437450557947, 0.0010527954436838627, -0.012420859187841415, -0.012898583896458149, -0.01145886443555355, 0.0225905179977417, -0.00338334240950644, -0.0075650750659406185, 0.034370046108961105, 0.0032082856632769108, 0.02030005492269993, -0.005130639299750328, -0.004296255763620138, 0.007977358996868134, -0.011399966664612293, -0.021229328587651253, 0.0028974369633942842, 0.014698234386742115, -0.016072513535618782, -0.009253473952412605, -0.002624217187985778, 0.0025325987953692675, -0.020273877307772636, 0.02642541006207466, 0.006174436304718256, -0.017368260771036148, -0.0034913215786218643, -0.02522128075361252, -0.019567105919122696, 0.0037301841657608747, 0.018258269876241684, -0.006586719769984484, 0.01696252077817917, -0.005667262244969606, -0.004014856182038784, 0.0024033510126173496, -0.023807736113667488, -0.04149011895060539, 0.03908186033368111, 0.00749308941885829, -0.013428662903606892, -0.011517761275172234, 0.002957970602437854, -0.008435451425611973, 0.0006356037338264287, -0.010163115337491035, -0.0010307087795808911, -0.023689942434430122, 0.016713842749595642, 0.023454351350665092, -0.02083667740225792, 0.009842450730502605, 0.010824078693985939, -0.021334035322070122, -0.00814096350222826, -0.009240386076271534, -0.009888259693980217, -0.012983658351004124, 0.04494544863700867, -0.009142223745584488, 0.00023865816183388233, 0.015784569084644318, -0.02197536639869213, -0.03615006431937218, -0.009672301821410656, -0.005915941204875708, 0.025024954229593277, 0.01878180354833603, -0.020247701555490494, 0.00849434919655323, 0.003057769499719143, -0.0030937623232603073, -0.006377306301146746, -0.006331496872007847, 0.01065392978489399, -0.03745890036225319, 0.015758391469717026, 0.015444271266460419, -0.015051620081067085, -0.010182748548686504, 0.02302243560552597, 0.04858401417732239, 0.024802451953291893, 0.006495101377367973, 0.035888299345970154, 0.019671812653541565, 0.01901739463210106, -0.005814506206661463, -0.012263798154890537, 0.03476269915699959, 0.0014519905671477318, 0.006148259621113539, -0.027904395014047623, 0.003504409920424223, 0.0011730447877198458, 0.01668766513466835, 0.015365741215646267, -0.013598811812698841, 0.006436203606426716, 0.03913421183824539, -0.0057392483577132225, 0.013356677256524563, 0.01763002760708332, -0.004420595243573189, 0.021098444238305092, 0.0034160634968429804, 0.00433224905282259, -0.004397690761834383, 0.0067274197936058044, -0.01083716657012701, -0.002517874352633953, -0.02558775432407856, 0.00852707028388977, -0.004482765216380358, -0.008062433451414108, -0.0266348235309124, -0.009305828250944614, 0.0035076818894594908, -0.009848995134234428, 0.028323223814368248, 0.027956748381257057, 0.007394926622509956, 0.013068732805550098, -0.0037072794511914253, -0.0008356103207916021, -0.021425655111670494, -0.024894071742892265, -0.009168400429189205, -0.01591545157134533, -0.008134419098496437, -0.021661244332790375, 0.011753352358937263, 0.026713354513049126, 0.019331516698002815, 0.00037404094473458827, -0.007643605582416058, 0.00579814612865448, -0.0039068772457540035, -0.008592511527240276, 0.00793809350579977, -0.016229573637247086, -0.008468172512948513, -0.008592511527240276, -0.00644602021202445, -0.008520525880157948, 0.0129771139472723, 0.008906632661819458, 0.024265829473733902, 0.004041032865643501, -0.007898828946053982, 0.049814317375421524, -0.0333753302693367, 0.0021906651090830564, 0.024854805320501328, -0.0006180162308737636, 0.007931549102067947, 0.006053369026631117, -0.013219249434769154, 0.007519266102463007, -0.03628094866871834, 0.0019665269646793604, -0.005912669003009796, 0.0026503941044211388, 0.01621648482978344, 0.0016131410375237465, -0.00440750690177083, 0.010968049988150597, -0.009783552959561348, 0.01786561869084835, 0.011170919984579086, 0.012244165875017643, -0.0069041126407682896, 0.03599300608038902, 0.023415084928274155, 0.012329240329563618, 0.005218985956162214, 0.005768697243183851, -0.01063429657369852, -0.003664742223918438, 0.005065197590738535, 0.025574665516614914, -0.00933854840695858, -0.026438498869538307, 0.01598089374601841, -0.022642871364951134, -0.00033477586111985147, -0.02704056352376938, 0.010673562064766884, -0.0029808753170073032, 0.013363220728933811, 0.010025687515735626, -0.03688301518559456, -0.028742050752043724, 0.0011738627217710018, -0.015797657892107964, 0.01978960819542408, -0.013219249434769154, 0.025195103138685226, -0.018349887803196907, 0.0008662861655466259, -0.008540158160030842, 0.006112266797572374, 0.0188734233379364, -0.033689454197883606, 0.00038426622631959617, 0.011275626718997955, -0.03819185122847557, 0.0005775241297669709, 0.0003458191640675068, 0.008978618308901787, -0.030286477878689766, -0.009057149291038513, -0.01739443838596344, -0.009116046130657196, -0.004286439623683691, 0.0019092652946710587, 0.02387317828834057, 0.014240141957998276, -0.004508941899985075, 0.004198093432933092, 0.011098934337496758, -0.00960686057806015, -0.008383098058402538, -0.005699983332306147, -0.017813265323638916, -0.018467683345079422, 0.00024172574921976775, 0.007781033404171467, 0.012525565922260284, -0.01446264423429966, 0.0007538080681115389, 0.009920980781316757, -0.003821802791208029, 0.01611177809536457, 0.001451172516681254, -0.002386990701779723, -0.019632548093795776, -0.048531658947467804, 0.010778268799185753, 0.005297516006976366, 0.010326720774173737, 0.027668803930282593, -0.033087387681007385, -0.015287211164832115, 0.04172571003437042, -0.016268838196992874, 0.011321435682475567, -0.01992049254477024, -0.014868383295834064, -0.02393862046301365, 0.027249976992607117, -0.00937126949429512, 0.018454594537615776, -0.007925005629658699, -0.025770992040634155, -0.007034996524453163, 0.00466927420347929, 0.019122101366519928, -0.005968294572085142, -0.01679237373173237, -0.008265302516520023, 0.010595032013952732, -0.0046725464053452015, -0.0010266186436638236, -0.02902999520301819, 0.010379074141383171, -0.01446264423429966, 0.010660473257303238, -0.0053891343995928764, -0.004659458063542843, -0.023140229284763336, -0.018834158778190613, 0.0012106738286092877, 0.0205618217587471, -0.00522552989423275, 0.01651751808822155, -0.021085357293486595, -0.004266807343810797, -0.0005255796713754535, -0.02079741284251213, 0.019540930166840553, 0.006105722393840551, 0.04368896409869194, -0.022197868674993515, -0.0037825375329703093, -0.013507192954421043, -0.028611166402697563, -0.00638057803735137, 0.012748068198561668, 0.02231566235423088, -0.0022806476335972548, -0.009567595086991787, -0.01861165650188923, 0.024763187393546104, 0.02727615274488926, -0.020404761657118797, -0.019999021664261818, 0.0063380408100783825, 0.009057149291038513, -0.020116817206144333, -0.01122327335178852, -3.7654612242477015e-05, -0.02167433314025402, 0.026098201051354408, 0.019122101366519928, -0.011301803402602673, -0.012551742605865002, -0.013186528347432613, -0.015496624633669853, 0.04426485300064087, -0.02430509403347969, 0.024737011641263962, 0.009489065036177635, -0.018729450181126595, -0.007820297963917255, 0.010228557512164116, -0.01752532087266445, -0.0004302800225559622, 0.008671042509377003, 0.010274366475641727, 0.00338334240950644, -0.008998251520097256, 0.0055658272467553616, 0.004109746776521206, 0.002519510453566909, 0.010339808650314808, -0.00041616911767050624, 0.031071780249476433, 0.0032753634732216597, -0.009390901774168015, 0.027249976992607117, -0.01897813007235527, 0.014881471171975136, 0.016936345025897026, -0.019069747999310493, 0.01353336963802576, 0.0033866146113723516, 0.0033342610113322735, 0.036254771053791046, 0.01679237373173237, -0.03138589859008789, 0.0005186264752410352, -0.0026373055297881365, -0.007807210087776184, -0.024789365008473396, -0.011026947759091854, 0.013585723005235195, -0.029344115406274796, -0.0246061272919178, -0.02751174382865429, 0.0035829399712383747, 0.019436223432421684, 0.031464431434869766, 0.015077796764671803, 0.0024720649234950542, 0.021765951067209244, -0.005775241181254387, 0.03837508708238602, 0.01918754354119301, 0.001180407009087503, -0.028846757486462593, -0.003468416864052415, -0.008710307069122791, -0.02184448204934597, 0.007080805953592062, -0.0005120823043398559, -0.027825865894556046, -0.029684413224458694, 0.021595802158117294, 0.02612437680363655, -0.002261015120893717, 0.006858303677290678, -0.017001787200570107, 0.01276115607470274, -0.0022937359753996134, 0.008991707116365433, -0.0041228351183235645, -0.0018749083392322063, -0.025731725618243217, -0.007336028851568699, 0.025064220651984215, -0.032040320336818695, -0.012538653798401356, -0.0397886298596859, 0.003151023993268609, 0.017276642844080925, -0.0014159975107759237, -0.009260018356144428, -0.011164375580847263, 0.004296255763620138, -0.021412566304206848, 0.00380871444940567, -0.011655189096927643, 0.004862327594310045, -0.03154296055436134, 0.021019915118813515, 0.002889256691560149, -0.012617184780538082, -0.021085357293486595, 0.008736483752727509, 0.011831882409751415, -0.00403776066377759, -0.022747579962015152, -0.004636553581804037, -0.0017734735738486052, 0.007872652262449265, -0.01591545157134533, -0.005346597172319889, 0.010195836424827576, 0.029239408671855927, 0.03832273557782173, -0.03159531578421593, -0.034605637192726135, 0.007597796153277159, -0.03416063264012337, -0.013729695230722427, 0.019972845911979675, 0.002324820961803198, -0.01925298571586609, 0.02905617095530033, 0.002807454438880086, 0.010143483057618141, 0.0012147639645263553, 0.018729450181126595, -0.02498568966984749, -0.006544182542711496, 0.01995975710451603, -0.002035240875557065, -0.009286195039749146, 0.0017718374729156494, -0.013055644929409027, -0.013742784038186073, 0.023218760266900063, -0.015208681114017963, -0.009390901774168015, 0.015418094582855701, -0.007499633356928825, -0.00265857414342463, 0.0024687929544597864, -0.004603832494467497, 0.01475058775395155, 0.018219005316495895, -0.0025996766053140163, -0.027668803930282593, 0.0002938747056759894, -0.002426255727186799, -0.0008401094819419086, -0.03853214904665947, 0.009384358301758766, 0.018428418785333633, 0.0006090180249884725, 0.005009572021663189, -0.04143776372075081, -0.03609771281480789, 0.007427647244185209, -0.02235492877662182, -0.009102958254516125, 0.00493104150518775, -0.03392504155635834, 0.0259542278945446, -0.017315907403826714, 0.0015076161362230778, 0.0034356960095465183, 0.0006687336717732251, -0.0031755645759403706, 0.026791883632540703, 0.02188374660909176, -0.012113282456994057, -0.022263308987021446, -0.020718881860375404, 0.003589484142139554, -0.017538409680128098, -0.004806702025234699, -0.006586719769984484, -0.02154344879090786, -0.007807210087776184, 0.02066652849316597, 0.0035174982622265816, -0.0022070256527513266, -0.027956748381257057, -0.01240777038037777, -0.014789853245019913, 0.0016818549484014511, -0.024684656411409378, 0.001413543475791812, 0.002205389551818371, 0.002545687137171626, 0.009646125137805939, -0.036123890429735184, 0.010470692068338394, -0.017342085018754005, -0.00017004649271257222, 0.004446772392839193, 0.010496868751943111, 0.22742344439029694, -0.000854833866469562, -0.0237684715539217, 0.0230878759175539, -0.013886755332350731, 0.012106738053262234, 0.015889275819063187, 0.006246422417461872, 0.023506704717874527, 0.0038348911330103874, 0.0052451626397669315, -0.010169659741222858, -0.028401752933859825, 0.0015280666993930936, -0.0037825375329703093, -0.029684413224458694, -0.01810120977461338, -0.010437971912324429, 0.0212424173951149, -0.022813020274043083, -0.006805949844419956, -0.0053007882088422775, -0.012990202754735947, -0.020182259380817413, 0.03023412451148033, 0.025038043037056923, -0.0011934953508898616, 0.003916693385690451, 0.021111533045768738, -0.0047347163781523705, -0.018297534435987473, 0.005830866750329733, 0.004378058481961489, 0.01773473434150219, -0.011570114642381668, -0.012905128300189972, 0.01237504929304123, 0.01891268789768219, 0.01464588101953268, 0.015208681114017963, 0.020234612748026848, -0.022433457896113396, -0.0176954697817564, -0.022525077685713768, 0.010143483057618141, 0.01790488325059414, 0.009260018356144428, -0.02147800847887993, 0.014148523099720478, 0.001876544440165162, -0.01807503215968609, -0.00019090608111582696, 0.01867709681391716, 0.009580683894455433, -0.006315136328339577, -0.02642541006207466, 0.01632119156420231, 0.028532637283205986, 0.016949433833360672, 0.019815785810351372, 0.004466404672712088, 0.002684751059859991, -0.008965530432760715, 0.01814047433435917, -0.018258269876241684, 0.014973090030252934, -0.015601331368088722, -0.00010532043961575255, 0.00800353568047285, -0.002362449886277318, -0.0018847245955839753, -0.0033637098968029022, 0.007165879942476749, 0.01321270503103733, -0.021831393241882324, 0.0016205032588914037, 0.013062188401818275, 0.015300299040973186, 0.007813754491508007, 0.01756458729505539, 0.004351881332695484, -0.01594162918627262, -0.014318672008812428, -0.005474208854138851, -0.008821558207273483, -0.015548978000879288, -0.013481016270816326, 0.012525565922260284, -0.001263027312234044, 0.019331516698002815, 0.0031019425950944424, -0.0055658272467553616, -0.03348004072904587, -0.0025800440926104784, 0.003605844685807824, -0.017171936109662056, 0.005876676179468632, -0.004558023065328598, 0.005382590461522341, -0.006668522022664547, -0.003700735280290246, 0.026202907785773277, 0.004312616307288408, -0.004688906949013472, 0.0031641123350709677, 0.0013145627453923225, -0.023074788972735405, 0.011236362159252167, 0.02194918878376484, -0.021962277591228485, 0.00293670198880136, -0.04379367083311081, 0.008677585981786251, -0.01311454176902771, 0.017250465229153633, 0.01159629225730896, 0.0088477348908782, -0.002136675640940666, -0.010987683199346066, -0.00461037689819932, 0.021294770762324333, 0.0016098689520731568, -0.011537394486367702, 0.009214209392666817, 0.012741523794829845, -0.013546458445489407, 0.02073197066783905, -0.006315136328339577, 0.01611177809536457, -0.008343832567334175, 0.02221095561981201, -0.014266318641602993, 0.008219493553042412, -0.015405005775392056, -0.0026389416307210922, -7.459345943061635e-05, -0.006112266797572374, -0.008978618308901787, 0.009325460530817509, -0.006884480360895395, 0.01752532087266445, -0.008121331222355366, -0.014881471171975136, 0.008441995829343796, 0.030522068962454796, -0.016124866902828217, 0.021582715213298798, 0.02255125343799591, 0.00217430479824543, -0.018716363236308098, -0.012276886962354183, 0.011465407907962799, 0.003811986418440938, -0.01261064037680626, 0.015182503499090672, 0.015444271266460419, -0.009332004934549332, -0.005382590461522341, -0.012885496020317078, -0.014174699783325195, -0.019815785810351372, -0.00604355288669467, 0.008749572560191154, -0.0012523930054157972, -0.018284447491168976, 0.014266318641602993, -0.16596047580242157, 0.013003291562199593, 0.03633330389857292, -0.024462155997753143, -0.013860578648746014, 0.020208436995744705, 0.03523388132452965, -0.008049344643950462, -0.021386388689279556, 0.014907647855579853, 0.020679617300629616, -0.015313387848436832, -0.00797081459313631, -0.02976294234395027, 0.005346597172319889, -0.020745059475302696, -0.011314892210066319, 0.0599970668554306, 0.006832126993685961, 0.01244049146771431, 0.011622468940913677, 0.002853263635188341, 0.027249976992607117, -0.008258759044110775, 0.0050226603634655476, -0.02800910174846649, -0.027852041646838188, 0.047851063311100006, 0.013546458445489407, -0.018009589985013008, -0.011903868056833744, 0.014384113252162933, -0.008566334843635559, -0.0032671832013875246, -0.0212424173951149, -0.020653441548347473, 0.011635556817054749, -0.03329680114984512, -0.007414558902382851, -0.001059339614585042, 0.027825865894556046, 0.021386388689279556, -0.022577431052923203, -0.001088788383640349, -0.00693683372810483, -0.004541662987321615, 0.006982643157243729, -0.008422363549470901, 0.017944149672985077, -0.0367521308362484, -0.00723132211714983, -0.01726355403661728, -0.001989431446418166, -0.014449555426836014, 0.002545687137171626, -0.010019144043326378, -0.006714331451803446, 0.012178723700344563, 0.0001692284713499248, -0.031909435987472534, 0.003697463311254978, -0.02126859314739704, 0.010320176370441914, -0.004191549029201269, -0.00749308941885829, -0.00960686057806015, -0.005902852863073349, 0.0029710589442402124, -0.031019426882267, 0.005592003930360079, -0.004531846381723881, -0.030495891347527504, 0.00100535003002733, -0.03416063264012337, 0.01698869839310646, 0.0016834910493344069, -0.012872407212853432, -0.007898828946053982, -0.0022004814818501472, 0.023951709270477295, -0.0007104528485797346, 0.036019179970026016, -0.018480772152543068, 0.005971566773951054, -0.0088477348908782, 0.0019648908637464046, -0.0026389416307210922, 0.010987683199346066, -0.013107998296618462, -0.004630009178072214, 0.031909435987472534, -0.03253767639398575, -0.01510397344827652, -0.025129660964012146, -0.005755608901381493, 0.007447279989719391, -0.007643605582416058, -0.03960539400577545, 0.0306791290640831, -0.024501420557498932, 0.002285555936396122, -0.0007214961224235594, -0.012198356911540031, 0.011288715526461601, 0.0367521308362484, -0.012381593696773052, 0.0295011755079031, 0.011288715526461601, 0.04154247045516968, 0.0056836227886378765, -0.0254568699747324, -0.00915531162172556, -0.0065605430863797665, 0.03416063264012337, -0.002526054624468088, 0.03622859716415405, -0.006845215335488319, -0.01975034363567829, 0.01552280131727457, -0.012630272656679153, 0.05141109973192215, -0.005951934028416872, -0.0303388312458992, 0.037432726472616196, -0.0110400365665555, -0.018650921061635017, -0.11905176937580109, -0.009521786123514175, 0.03115030936896801, 0.00933854840695858, 0.02467156946659088, 0.02094138413667679, 0.0003719958767760545, 0.00021452648798003793, 0.005690166726708412, 0.028427930548787117, -0.01208710577338934, -0.020889030769467354, -0.010791357606649399, -0.00305122509598732, 0.011471952311694622, -0.018323712050914764, 0.0006131081026978791, -0.02225022204220295, -0.007702502887696028, 0.034841228276491165, -0.004381330218166113, -0.026791883632540703, -0.01709340512752533, 0.004237358458340168, 0.005418583285063505, -0.008991707116365433, -0.03837508708238602, 0.009227297268807888, -0.007807210087776184, 0.007990446873009205, 0.0006572813726961613, -0.014868383295834064, -0.0017554770456627011, -0.004626736976206303, -0.01961945928633213, 0.0004961308441124856, -0.0053891343995928764, -0.009672301821410656, 0.010889519937336445, -0.00611881073564291, 0.011249450035393238, 0.017839442938566208, 0.03884626924991608, -0.019907403737306595, 0.016870902851223946, -0.007695958949625492, -0.05039020627737045, 0.01353336963802576, -0.01083716657012701, -0.022577431052923203, -0.02015608362853527, -0.016255749389529228, -0.013651165179908276, -0.0034062471240758896, 0.001979615306481719, -0.03217120096087456, 0.00842890702188015, 0.0055723716504871845, -0.010490325279533863, -0.010045320726931095, 0.010195836424827576, 0.004705267492681742, -0.015143238939344883, 0.03536476194858551, 0.027328507974743843, -0.017041051760315895, -0.0313597247004509, 0.014920736663043499, 0.0036320213694125414, -0.0051175509579479694, -0.01090260874480009, 0.01352028176188469, -0.021582715213298798, 0.018428418785333633, -0.02683115005493164, 0.0060173762030899525, -0.02015608362853527, 0.00494740204885602, 0.01220490038394928, 0.004875415936112404, -0.013795137405395508, -0.008441995829343796, -0.0062333340756595135, -0.005768697243183851, -0.005575643852353096, 0.024187298491597176, -0.014920736663043499, -0.002740376628935337, -0.001933805993758142, -0.01786561869084835, 0.0007697594701312482, 0.04274660348892212, 0.008356921374797821, -0.006311864126473665, -0.02751174382865429, -0.006877935957163572, -0.00849434919655323, 0.006720875855535269, -0.007388382218778133, -0.003131391480565071, 0.00616789236664772, 0.004381330218166113, -0.0364118330180645, 0.013795137405395508, 0.012872407212853432, -0.007853019051253796, 0.0036189330276101828, 0.0009227297850884497, 0.03698772192001343, 0.005359685514122248, 0.03863685578107834, -0.014161611907184124, -0.03243296965956688, 0.001636863686144352, -0.01891268789768219, -0.012669538147747517, -0.007781033404171467, -0.00021043638116680086, 0.023349644616246223, 0.0025702277198433876, 0.015470447950065136, -0.014017639681696892, -0.008363465778529644, 0.011013859882950783, -0.004953946452587843, 0.01901739463210106, 0.002185757039114833, -0.001609050901606679, -0.00018262359662912786, 0.017616940662264824, -0.027249976992607117, -0.02454068511724472, 0.017917972058057785, -0.022368015721440315, -0.004158827941864729, 0.008121331222355366, -0.022106248885393143, -0.01083716657012701, -0.015850011259317398, 0.03031265363097191, 0.0041162907145917416, -0.005336781032383442, 0.00888045597821474, 0.007578163407742977, -0.026333792135119438, -0.021464919671416283, 0.01006495300680399, 0.018991218879818916, -0.019292250275611877, 0.0038054422475397587, 0.0009636309114284813, -0.01321270503103733, -0.0026634824462234974, 0.011727175675332546, -0.016465162858366966, -0.0064492919482290745, -0.031071780249476433, -0.014789853245019913, -0.008500893600285053, -0.024357447400689125, 0.019292250275611877, -0.027459390461444855, 0.044186320155858994, -0.005922485608607531, 0.0055102016776800156, -0.0062824152410030365, 0.024030238389968872, 0.004574383608996868, 0.010477236472070217, 0.006982643157243729, 0.010019144043326378, -0.02753792144358158, -0.01688399165868759, -0.01662222482264042, 0.002733832225203514, -0.007480001077055931, 0.014004550874233246, 0.0027485566679388285, -0.007427647244185209, 0.023375820368528366, 0.0046790908090770245, 0.00908332597464323, 0.0387677401304245, -0.006262782961130142, -0.027668803930282593, 0.0019697989337146282, 0.04065246134996414, 0.020404761657118797, -0.01285931933671236, 0.013441751711070538, -0.014960002154111862, 0.008553246967494488, -0.004191549029201269, -0.012924760580062866, -0.004181732889264822, -0.005938845686614513, -0.003753088880330324, 0.014920736663043499, -0.031673844903707504, -0.007944637909531593, 0.014855294488370419, 0.027433214709162712, -0.010365985333919525, 0.021019915118813515, 0.002529326593503356, -0.015300299040973186, -0.014266318641602993, 0.0249464251101017, -0.0018290990265086293, -0.03128119185566902, -0.008841190487146378, 0.022904640063643456, -0.0003519543388392776, 0.0323544405400753, 0.014672057703137398, 0.005951934028416872, -0.002454068511724472, -0.010222013108432293, -0.027328507974743843, -0.0038708841893821955, -0.026883503422141075, 0.009705022908747196, 0.0010986046399921179, -0.01621648482978344, -0.012597551569342613, 0.008572879247367382, 0.01914827898144722, -0.0008466536528430879, 0.015627508983016014, 0.014685146510601044, 0.00024029420455917716, 0.012682626023888588, 0.011373789981007576, 0.0036287494003772736, -0.001393910963088274, -0.01925298571586609, -0.008867367170751095, -0.024501420557498932, -0.007041540462523699, -0.012937849387526512, -0.02255125343799591, 0.06994422525167465, 0.015247945673763752, -0.0034356960095465183, 0.011923501268029213, 0.0024295279290527105, 0.02902999520301819, 0.014357936568558216, -0.0025244185235351324, -0.05376700684428215, -0.01763002760708332, 0.037406548857688904, -0.0044565885327756405, 0.00076280627399683, -0.04861018806695938, 0.00827839132398367, 0.03081001155078411, 0.013454839587211609, 0.022904640063643456, 0.005634541157633066, -0.020875943824648857, 0.015692949295043945, -0.0055658272467553616, 0.015954717993736267, -0.013651165179908276, 0.004463132470846176, -0.008513981476426125, 0.03206649422645569, -0.01897813007235527, -0.020103730261325836, -0.010529589839279652, 0.024161122739315033, 0.0008654681732878089, -0.026883503422141075, -0.0014356301398947835, 0.008605600334703922, 0.008376553654670715, -0.0017718374729156494, -0.010509957559406757, -0.0014168155612424016, 0.03046971559524536, -0.017080316320061684, -0.005058653187006712, -0.02197536639869213, -0.004387874621897936, -0.036595068871974945, 0.0015018898993730545, -0.012355417013168335, -0.0035763958003371954, -0.03452710807323456]}}, rets=[{'node': {'id_': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'b5542e96-351d-4501-a621-d2aaee1386eb', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '47845a6529a286c4db5938e0f0349691964e347496cd3c65c4a3feff45ba6666'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'bdde83a5-6a37-4e11-9adf-5717c3b28b88', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '505dfda29fbdfe6cf75948c2f2605eed66b308f218805e30fc5050105bf992da'}}, 'text': \"We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, . So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n. Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n-\\n113, Measuring Heart Rate\\n. Heart rate can be measured by\\n2, . listening to the chest\\n4, . Sensing minute changes in blood flow via \\nphotoplethysmography\\n. (\\n2, ) are ambulatory, for \\nemergency response while (\\n4, ) \\ncan be embedded in wearable sensors\\n-\\n115, . Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n. Used on watches like Apple \\nWatch where you see\\n2, LEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n-\\n117, Measuring Blood Pressure\\n. Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n. BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n. BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n. Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n-\\n119, Measuring Respiration\\n. Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n. Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n. Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n-\\n121, -\\n123, Polygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n-\\n125, -\\n127, -\\n5, stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n. Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n. The first sleep cycle is usually shortest at\\n100, minutes. Later cycles are\\n110, minutes. \\n. If you sleep for\\n5, full \\ncycles\\nSleep Explained\\n-\\n130, Why is sleep important ?\\n. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n.\", 'start_char_idx': 16001, 'end_char_idx': 19861, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8357276384880378}, {'node': {'id_': '65ee4e5e-d2af-4f4d-9438-c85b8552fc6d', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': '700ef3cc-d626-4043-8c6c-7338f125c83f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '78f58d9e57c6c8935ac8b4be1e2f5cf70fdf9b0144e19d7b8ac69c48ee7e3928'}}, 'text': 'We know the brain consists of simple but \\nmassively parallel processing\\n. Each of the 86B cells in the brain connects to\\n184, Human Memory\\n. As a re-cap from earlier MOOC on memory … \\n. Sensory – short term, \\nrapid decay unless \\nrefreshed, passed to…\\n. Short-term if attentive,\\nthe “post-it” note, \\nusually only\\n185, Brain Activity\\n. So if brain activity is “only” firing neural \\ncircuits, can we “listen” to this by sensing the \\nelectrical activity ? \\n. Yes of course\\n. BCI (Brain Computer Interface) is a \\ncommunication channel capable of operation \\nentirely on neural signals\\n. Many sensing technologies exist: \\nEEG, nIR, MEG, PET, ECoG, Local Field \\nPotentials, fMRI\\n. Each offers its own interaction paradigms and \\ncapabilities but we are interested in EEG\\n-\\n1, or\\n32, ,\\n128, (as in image)\\nor even\\n187, EEG\\n. Some more \\nexamples of \\nEEG\\n-\\n189, EEG – What to Measure ?\\n.\\nIn MOOC\\n2, -node EEG \\n.\\nSo we can use EEG to measure attention in a way that \\nis similar to “listening” to the amount of “traffic” in the \\nbrain, not localising it or determining where in the \\nbrain, just how active the brain actually is\\n.\\nBut we can do more \\nwhen we determine \\nwhere in the brain, the\\nactivity is, so we use \\nmany nodes and even\\ntriangulate to pinpoint\\nthe places in the brain \\nwhere the greatest activities\\nare\\n-\\n191, . We are interested in ERPs (Event Related \\nPotentials) electrical responses at certain scalp \\npoints, generated by the brain in response to \\nstimuli such as an image, \\nsound, touch, taste… \\n. There are several \\nknown ERPs including \\nP1, N1, P2, N2 and P3\\nwhich occur\\n170, ,\\n250, and\\n3, .\\n5543904, -\\n193, A Face\\n-\\n1996, , in certain parts of \\nyour brain (unless you were mindwandering or \\nasleep and didn’t actually see the face, so pay \\nattention !)\\n. It was probably around your occipitotemporal \\narea, slightly to the right side, \\nbetween Pz and P4\\n. If you had a couple of EEG nodes\\nthere then\\n17, seconds after\\nseeing Michael D’s face on \\nyour screen, they would have \\ndetected a voltage change\\n-\\n0, .\\n196, -\\n198, -\\n200, P300 elicitation\\n. We’re going to show a series of \\nimages, about\\n201, P300 elicitation\\n-\\n203, P300 elicitation\\n-\\n205, P300 elicitation\\n-\\n207, P300 elicitation\\n-\\n209, P300 elicitation\\n-\\n211, P300 elicitation\\n-\\n213, P300 elicitation\\n-\\n215, P300 wave\\n.\\nThere’s nothing special about the Coke \\ncan. It’s just that you did not know when \\nit was going to appear, and since I told \\nyou to look out for it, its appearance \\ncaught your attention, you recognised it\\n.\\nI could have as equally used any object \\nthat you may be looking for or expecting \\n.\\nSo there is an idea that when searching \\nfor images, we can have a BCI interface \\nbased on using EEG sensors to detect \\nwhen you see something you recognise\\n.\\nResearchers (like us) are working on this \\nkind of interface\\n-', 'start_char_idx': 25518, 'end_char_idx': 28321, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.7741041533786612}, {'node': {'id_': 'bdde83a5-6a37-4e11-9adf-5717c3b28b88', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6ddaba9026c3bfa326cb469008bb1132a55e8043ae18bfb5703bef3358e41b97'}, <NodeRelationship.NEXT: '3'>: {'node_id': '700ef3cc-d626-4043-8c6c-7338f125c83f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'bd47aad3b039faf924234cb81e420c8cea1fe256dd880b8b0070313b7ba485e7'}}, 'text': '. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n. Leads to dark circles under the eyes, \\ntopical creams used to camouflage \\n. Also more wrinkles because less \\ncollagen produced, puffy eyes, no \\n“glow”\\n. … and … you don’t look happy\\nSleep and Appearance\\n-\\n134, -\\n1, . Phone apps\\n3, . Movement radar or sonar\\n136, Presented as a Hypnogram\\n-\\n1, . Smartphone Apps\\n-\\n2, . Wrist-worn Accelerometers \\n-\\n3, . Sonar / Radar\\n-\\n4, . The Ōura Ring\\n. From a Finnish start-up, a (finger) \\nring with in-built accelerometer and \\ngyroscope and also measures \\nbody temperature, and heart rate\\n. HR sampled using IR spectrum \\nlight from\\n250, Hz so \\nable to do much more than wrist-\\nworn HR sensors\\n. Contactless battery charge lasts\\n6, weeks\\n. Low power Bluetooth download to \\nphone \\n-\\n142, And what about Alan’s Sleep ?\\n. Here’s a sample of summary data over\\n143, And what about Alan’s Sleep ?\\n-\\n145, . Some use it to inform or influence day-to-day \\nactivities\\n. Some look at trends, but the trends don’t say a lot \\nbecause other factors influence those trends \\n(travel, vacation, stress, colds and flu, sports \\nevents, etc.) and we can’t see those.\\n. That’s because sleep apps, activity apps, health \\napps, all work independently of each other, not \\nsynchronised\\n. So there is not a lot we can actually usefully do \\nwith our own sleep data or any other lifelog data\\n. We can’t easily integrate it or re-purpose it and \\nbecause it reports day-at-a-time information its \\ndifficult to get useful longitudinal analysis.\\nSo what to do with this information ?\\n-\\n1, . We can aggregate our own personal \\ndata with data from other users, \\nacross a population\\n147, . Almost all vendors who allow us gather \\nindividual data, get value from pooling \\nanonymised data\\n. Let’s look at\\n148, . Fitbit – wearable wrist-worn activity logger \\nand sleep recorder\\n. Fitbit mined 150B hours of heart rate data, \\ngathering statistics from millions of sleep \\nnights and discovered the following\\nPopulation-level Analytics from Pooled \\nIndividual Data\\n-\\n150, . Some fitbit devices also record heart \\nrate, so they mined that to correlate \\nresting heart rate (a wellness indicator) \\nwith body-mass index (a weight \\nindicator), age, and amount of exercise \\n. They found insights that cardiologists \\nwere not aware of\\n-\\n150, -billion-hours-heart-data-reveals-secrets-human-health-\\n152, Population-level Analytics from Pooled \\nIndividual Data\\n. 23andMe is a DNA testing company \\nwho’s catchphrase is to allow you to \\n”meet your genes”\\n. From a saliva sample they synthesise\\nyour DNA and search it for DNA \\nmarkers which\\n2, . Report your Genetic Health Risks (whether \\nyou have genetic variants associated with \\nincreased risk for certain(+\\n153, Population-level Analytics from \\nPooled Individual Data\\n. 23andMe provides benefit to the \\nindividual (gene markers) but even \\nmore benefit when data is pooled in \\norder to connect relatives and \\ndetermine actual exposure risk to \\ndiseases based on population analysis\\n-\\n155, -\\n157, -\\n2, years, \\nupdated monthly, showing areas where \\npeople run/cycle \\n. Next slide is DCU campus, Albert \\nCollege Park stands out clearly\\n.', 'start_char_idx': 19134, 'end_char_idx': 22931, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.7693013601835065}, {'node': {'id_': 'b5542e96-351d-4501-a621-d2aaee1386eb', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': '84aa3389-cf64-4c66-acdd-f4226b070976', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '8dc42eb46625763ae763b459257b106dd73c40c3814e9c0024dc2dae20698eed'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'b2753bf8c2867da5166f372338f053555471cef0350a4b79b3844aa82ef5a4e5'}}, 'text': '.A network of infra-red lights and cameras around the subject \\ncapture the markers and in real time, combine them to generate \\na 3D model of the user\\n.This is very accurate - sampling rate is\\n7, -\\n86, -\\n86, Motion Capture, Our Approach\\n. Inertial sensing\\n– Synthesize realistic motion from \\nInertial Measurement Units (IMU)\\n. Contextual information\\n– Single low-cost camera if available\\n. Off-line\\n– Capture prototypical movements\\n– Build motion graph\\n. Pre-capture\\n– Define IMU placement\\n– Add virtual IMU data to motion graph\\n. On-line\\n– Search motion graph\\n– Match virtual & real IMU data\\n87, -\\nHow well does it work ?\\n87, nan\\n88, -\\nKinect\\n. And then came the Microsoft Kinect !\\n. Sits on top of a TV or computer screen and \\ncontains an integrated microphone array, \\nvisible spectrum camera and IR-based depth \\ncamera\\n. Intended to be a proprietary interface to the \\nX-Box gaming console but it was quickly \\nhacked, so Microsoft gave up and released an \\nAPI so anyone could use it for anything\\n-\\n90, -\\nMicrosoft Kinect\\n. Kinect is a form of AR\\n. Works by sending out patterns of dots \\nin invisible spectrum light, and then \\npicks them up with a camera\\n. https://www.youtube.com/watch?v=dT\\nKlNGSH9Po&feature=related\\n. Using this, Kinect knows how far you \\nare from the camera (depth map) and \\ncan augment the video camera image \\non the screen\\n. One example app is the virtual dressing \\nroom where you can “try on” clothes …\\n-\\n9, nan\\n92, -\\n. Details at \\nhttps://www.youtube.com/watch?v=\\n93, -\\nSlide\\n94, -\\nTexture-based retrieval results\\n.\\nQuery :\\nTop\\n95, -\\nTexture-based retrieval results\\n.\\nQuery :\\nTop\\n96, -\\nColour-based retrieval results\\nQuery :\\nTop\\n97, -\\nKinect\\n. Best hacks … \\n. #\\n9, (wall) we did this for NMI treasure \\nroom (award-winning at MM2011)\\n. Play the others and be inspired !\\n. All revolve around sensing what you are \\ndoing, now\\n-\\n99, -\\nWeek\\n100, Sensing the Body - Physiology\\n. Our physiology is the set of outward signs that \\nour body gives constantly, to indicate what state \\nour bodies are in.\\n. For example \\n– when we perspire its an indication we’re too hot and \\nwe need to cool down; \\n– when we’ve goosepimples on our arms it means the \\nenvironment is too cold for us and we need to \\npreserve heat hence the goosepimples; \\n– when our breathing is fast it means we’re extending \\nourselves and we need to get more oxygen into our \\nblood streams because we’re exercising, or we’re \\ntense\\n-\\n102, Sensing the Body - Physiology\\n. Mostly, and the main reason we sense our bodies, is for \\nhealth reasons, \\n– we monitor our heart rate when we exercise\\n– we track our movement so as to count our exercise or number of \\nsteps taken in a day\\n– older people at home and lone workers in forests and remote areas \\nwear fall detectors to detect when accidents have occurred\\n– the hard of hearing use hearing aids and some people have their \\nheart rates regularised with implanted pacemakers, etc. \\n. While health and wellness reasons are the main reason, \\nthere are others also, like measuring our reaction to \\nadvertising material (just as an example)\\n-\\n104, . Lets see some examples …. (see slide \\nnote)\\n. We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, .', 'start_char_idx': 12884, 'end_char_idx': 16811, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.7683269285060644}], error=None, perf=Perf(start_time=datetime.datetime(2024, 3, 4, 16, 59, 35, 200250), end_time=datetime.datetime(2024, 3, 4, 16, 59, 35, 498941)), pid=555, tid=555), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='retrieve')), RecordAppCallMethod(path=Lens().app._retriever, method=Method(obj=Obj(cls=llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever, id=140331591789456, init_bindings=None), name='retrieve'))], args={'str_or_query_bundle': {'query_str': 'Can you list ways that heart rate can be measured?', 'image_path': None, 'custom_embedding_strs': None, 'embedding': [-0.029710588976740837, 0.024593038484454155, 0.009318916127085686, -0.031202662736177444, -0.0030937623232603073, 0.01523485779762268, -0.007545442786067724, -0.001422541681677103, -0.023009346798062325, -0.0006470560911111534, -0.001627047429792583, 0.04025981202721596, -0.021294770762324333, 0.005938845686614513, 0.004103202372789383, -0.004937585908919573, 0.03620241954922676, 0.03256385400891304, 0.01662222482264042, -0.014331759884953499, -0.025509225204586983, 0.012113282456994057, -0.002957970602437854, 0.01655678264796734, -0.034945935010910034, 0.017878707498311996, 0.023912442848086357, 0.00013282646250445396, 0.007067717146128416, 0.0031837448477745056, 0.03664742410182953, -0.013860578648746014, -0.030129417777061462, -0.036359477788209915, -0.025941140949726105, 0.007767945062369108, -0.004387874621897936, 0.010496868751943111, 0.007807210087776184, -0.004083570092916489, 0.013808225281536579, 0.013585723005235195, -0.007172424346208572, -0.0001872249849839136, -0.01265644934028387, 0.01591545157134533, 0.006589991971850395, -0.015692949295043945, -0.023689942434430122, 0.014881471171975136, 0.014043816365301609, -0.013193072751164436, 0.0002362040977459401, -0.0017832898302003741, 0.005582187790423632, -0.012034752406179905, 0.038479793816804886, 0.030181771144270897, 0.0045678396709263325, -0.04002422094345093, -0.005140455439686775, -0.0013988190330564976, -0.010143483057618141, 0.02454068511724472, -0.017917972058057785, -0.005254978779703379, 0.006612896453589201, 0.01475058775395155, 0.013160351663827896, 0.0025227824226021767, 0.0055167460814118385, 0.004397690761834383, -0.011085845530033112, 0.023860089480876923, 0.017250465229153633, -0.018821069970726967, -0.0006957284058444202, -0.027328507974743843, 0.01149812899529934, 0.02073197066783905, 0.004773981403559446, -0.0003589075349736959, -0.020954472944140434, 0.027249976992607117, 0.01587618701159954, -0.010732459835708141, -0.008782293647527695, 0.0036483819130808115, 0.010994226671755314, -0.006668522022664547, 0.018991218879818916, 0.005811234470456839, -0.009750831872224808, 0.011897324584424496, 0.006982643157243729, 0.004489309154450893, 0.0027387405280023813, 0.019475487992167473, -0.0017260281601920724, 0.002846719464287162, -0.010182748548686504, 0.004826334770768881, -0.022001542150974274, -0.014973090030252934, -0.02086285501718521, -0.017603851854801178, 0.0035534913185983896, -0.02952735312283039, 0.0036385655403137207, -0.012898583896458149, -0.026988210156559944, 0.03361092135310173, 0.014436467550694942, -0.01681854948401451, 0.0011599564459174871, -0.0054611205123364925, 0.010365985333919525, -0.0034618726931512356, -0.009881716221570969, 0.0014953457284718752, 0.028297046199440956, 0.019567105919122696, 0.04439573734998703, -0.010195836424827576, 0.015247945673763752, -0.010287455283105373, -0.018245181068778038, -0.00036831479519605637, 0.014371025376021862, -0.006190796848386526, 0.014907647855579853, -0.0050782859325408936, -0.006661978084594011, 0.008821558207273483, -0.022930815815925598, -0.003123211208730936, 0.01422705315053463, 0.021635068580508232, -0.013952197507023811, -0.007427647244185209, -0.0007967542624101043, -0.002825450850650668, 0.00176529330201447, -0.013716607354581356, -0.013101453892886639, 0.032720912247896194, 0.017171936109662056, 0.013795137405395508, 0.0026945671997964382, -0.013664253987371922, -0.011511217802762985, -0.004531846381723881, 0.017878707498311996, 0.009521786123514175, -0.015653684735298157, 0.0066390736028552055, 0.0011836790945380926, 0.0034553285222500563, -0.004754348658025265, -0.003982135094702244, 0.006917200982570648, 0.020286966115236282, 0.02535216324031353, -0.002185757039114833, -0.01692325621843338, 0.007957725785672665, 0.01857239007949829, -0.029605882242321968, 0.0088477348908782, 0.0005754790618084371, -0.00971156731247902, 0.03293032571673393, -0.020286966115236282, 0.022224044427275658, 0.0120543846860528, -0.004659458063542843, -0.0031853809487074614, -0.014357936568558216, -0.017983414232730865, -0.040233634412288666, -0.023100964725017548, -0.004934313707053661, 0.010810989886522293, -0.0023820826318114996, -0.007336028851568699, 0.020378585904836655, 0.007918461225926876, -0.004093386232852936, 0.020849766209721565, -0.029946180060505867, -0.006262782961130142, -0.00992752518504858, -0.011341068893671036, -0.022093160077929497, -0.6659360527992249, -0.030260300263762474, -0.009318916127085686, -0.012806965969502926, 0.04400308430194855, 0.018768716603517532, 0.008729939348995686, 0.0025669557508081198, -0.014973090030252934, 0.03410828113555908, 0.001125599374063313, 0.004819790367037058, -0.0011885871645063162, -0.01908283680677414, -0.0009333640919066966, -0.02730233035981655, -0.001274479553103447, 0.0034160634968429804, -0.003717095823958516, -0.010267823003232479, -0.03408210352063179, -0.004881960339844227, -0.01299674715846777, 0.012159091420471668, -0.00638057803735137, 0.022080073133111, -0.0014094533398747444, 0.002874532248824835, -0.015208681114017963, 0.005742520559579134, -0.0009619948687031865, 0.0023771743290126324, 0.019776519387960434, 0.014907647855579853, 0.03149060904979706, -0.02272140234708786, -0.01850694790482521, 0.034605637192726135, -0.02302243560552597, 0.039055682718753815, -0.02571863867342472, -0.01119055226445198, 0.03141207620501518, -0.022459635511040688, -0.02845410630106926, 0.009790097363293171, 0.006112266797572374, 0.014357936568558216, 0.005434943828731775, -0.014567350968718529, 0.0012262162053957582, -0.022459635511040688, -0.002247926779091358, 0.01975034363567829, -3.47404093190562e-05, -0.006599808111786842, 0.020902119576931, 0.0163473691791296, -0.021517273038625717, 0.02244654670357704, 0.003972318954765797, 0.013258513994514942, 0.000390401401091367, -0.0295011755079031, -0.004767436999827623, 0.01728973165154457, -0.04065246134996414, -0.017237376421689987, -0.008893544785678387, -0.03382033482193947, -0.0010429790709167719, -0.007630517240613699, -0.0021546720527112484, 0.009718111716210842, 0.02094138413667679, 0.011622468940913677, 0.03253767639398575, -0.010424883104860783, -0.005853771232068539, -0.009292739443480968, -0.00045727475662715733, 0.011890780180692673, -0.01880798116326332, 0.01080444548279047, -0.003396430751308799, 0.022263308987021446, -0.012512477114796638, 0.009011339396238327, 0.024252740666270256, 0.0029268856160342693, 0.0005705709336325526, 0.029658235609531403, 0.00804280024021864, -0.02130785956978798, -0.019527841359376907, 0.011956221424043179, 0.0002527690667193383, -0.007264042738825083, 0.001180407009087503, -0.005254978779703379, -0.01159629225730896, 0.004427139647305012, 0.0027485566679388285, 0.00954141840338707, -0.004675818607211113, -0.013677341863512993, -0.024828629568219185, 0.0008016623905859888, 0.024462155997753143, -0.027119092643260956, -0.025469958782196045, -0.02905617095530033, -0.00869721919298172, 0.019344603642821312, 0.003216465702280402, -0.035548001527786255, 0.015850011259317398, 0.016438987106084824, 0.008363465778529644, -0.007826842367649078, 0.024802451953291893, -0.005935573950409889, 0.047955770045518875, -0.01080444548279047, -0.0007202691049315035, 0.007866107858717442, -0.020993737503886223, -0.001366916112601757, 0.021347124129533768, -0.027119092643260956, 0.0024017151445150375, -0.01918754354119301, -0.0003885608457494527, -0.016975609585642815, 0.0073491171933710575, 0.019540930166840553, 0.014449555426836014, 0.015692949295043945, -0.0050619253888726234, -0.023545969277620316, -0.011033492162823677, -0.006285687442868948, 0.00852707028388977, -0.016870902851223946, -0.005048837047070265, -0.021059179678559303, -0.002261015120893717, 0.014672057703137398, 0.010267823003232479, 0.0013096545590087771, -0.006410026922821999, -0.03816567361354828, -0.0044565885327756405, -0.0006965464563108981, 0.010208925232291222, -0.006383850239217281, -0.0063216807320714, -0.03444857895374298, -0.017486056312918663, -0.018297534435987473, 0.023218760266900063, 0.021425655111670494, -0.021621979773044586, 0.004132651258260012, -0.006351129151880741, -0.007002275437116623, 0.0022921001072973013, -0.004041032865643501, -0.008900088258087635, -0.028532637283205986, 0.020614175125956535, 0.0021972092799842358, -0.01353336963802576, 0.024265829473733902, 0.0003014414105564356, 0.03256385400891304, -0.0126433614641428, -0.012702258303761482, -0.005156815983355045, -0.013304323889315128, 0.02026079036295414, 0.02103300392627716, -0.01998593471944332, 0.004636553581804037, 0.022878462448716164, 0.006871392019093037, -0.008906632661819458, 0.011589747853577137, -0.01570603810250759, 0.021412566304206848, 0.007996991276741028, 0.008939353749155998, -0.007283675484359264, 0.013978374190628529, 0.01624266244471073, -0.0020614175591617823, -0.0014487184816971421, -0.0034095190931111574, 0.01773473434150219, 0.033087387681007385, 0.021347124129533768, 0.005886492319405079, 0.009142223745584488, -0.006508189719170332, 0.03463181480765343, -0.0031412076205015182, 0.014030727557837963, -0.020993737503886223, 0.01412234641611576, 0.02019534818828106, -0.012355417013168335, 0.003458600491285324, 0.010078041814267635, -0.021124621853232384, -0.009515241719782352, 0.007336028851568699, 0.0015689678257331252, 0.012564830482006073, 0.014069993048906326, 0.011367245577275753, 0.0411236435174942, 2.998564923473168e-05, 0.027721157297492027, 0.006452564150094986, -0.008579423651099205, 0.011537394486367702, 0.012322695925831795, 0.023284202441573143, 0.006406754720956087, -0.014658968895673752, 0.00829147920012474, -0.0027649172116070986, 0.009129134938120842, 0.01827135868370533, 0.008867367170751095, 0.0266348235309124, 0.0123030636459589, -0.00016299105482175946, 0.014894559979438782, 0.03751125559210777, 0.008199861273169518, -0.007761400658637285, 0.010568855330348015, -0.017944149672985077, 0.032747089862823486, 0.009528330527245998, 0.016098689287900925, -0.0024295279290527105, 0.014541174285113811, 0.003087218152359128, 0.00023538607638329268, -0.019396957010030746, -0.026032758876681328, 0.02238110452890396, 0.0019665269646793604, -0.015797657892107964, 0.021765951067209244, -0.0005284427315928042, -0.015313387848436832, 0.014946913346648216, 0.028977641835808754, 0.020705794915556908, 0.03081001155078411, -0.007388382218778133, -0.008644865825772285, 0.010876432061195374, -0.0032835437450557947, 0.0010527954436838627, -0.012420859187841415, -0.012898583896458149, -0.01145886443555355, 0.0225905179977417, -0.00338334240950644, -0.0075650750659406185, 0.034370046108961105, 0.0032082856632769108, 0.02030005492269993, -0.005130639299750328, -0.004296255763620138, 0.007977358996868134, -0.011399966664612293, -0.021229328587651253, 0.0028974369633942842, 0.014698234386742115, -0.016072513535618782, -0.009253473952412605, -0.002624217187985778, 0.0025325987953692675, -0.020273877307772636, 0.02642541006207466, 0.006174436304718256, -0.017368260771036148, -0.0034913215786218643, -0.02522128075361252, -0.019567105919122696, 0.0037301841657608747, 0.018258269876241684, -0.006586719769984484, 0.01696252077817917, -0.005667262244969606, -0.004014856182038784, 0.0024033510126173496, -0.023807736113667488, -0.04149011895060539, 0.03908186033368111, 0.00749308941885829, -0.013428662903606892, -0.011517761275172234, 0.002957970602437854, -0.008435451425611973, 0.0006356037338264287, -0.010163115337491035, -0.0010307087795808911, -0.023689942434430122, 0.016713842749595642, 0.023454351350665092, -0.02083667740225792, 0.009842450730502605, 0.010824078693985939, -0.021334035322070122, -0.00814096350222826, -0.009240386076271534, -0.009888259693980217, -0.012983658351004124, 0.04494544863700867, -0.009142223745584488, 0.00023865816183388233, 0.015784569084644318, -0.02197536639869213, -0.03615006431937218, -0.009672301821410656, -0.005915941204875708, 0.025024954229593277, 0.01878180354833603, -0.020247701555490494, 0.00849434919655323, 0.003057769499719143, -0.0030937623232603073, -0.006377306301146746, -0.006331496872007847, 0.01065392978489399, -0.03745890036225319, 0.015758391469717026, 0.015444271266460419, -0.015051620081067085, -0.010182748548686504, 0.02302243560552597, 0.04858401417732239, 0.024802451953291893, 0.006495101377367973, 0.035888299345970154, 0.019671812653541565, 0.01901739463210106, -0.005814506206661463, -0.012263798154890537, 0.03476269915699959, 0.0014519905671477318, 0.006148259621113539, -0.027904395014047623, 0.003504409920424223, 0.0011730447877198458, 0.01668766513466835, 0.015365741215646267, -0.013598811812698841, 0.006436203606426716, 0.03913421183824539, -0.0057392483577132225, 0.013356677256524563, 0.01763002760708332, -0.004420595243573189, 0.021098444238305092, 0.0034160634968429804, 0.00433224905282259, -0.004397690761834383, 0.0067274197936058044, -0.01083716657012701, -0.002517874352633953, -0.02558775432407856, 0.00852707028388977, -0.004482765216380358, -0.008062433451414108, -0.0266348235309124, -0.009305828250944614, 0.0035076818894594908, -0.009848995134234428, 0.028323223814368248, 0.027956748381257057, 0.007394926622509956, 0.013068732805550098, -0.0037072794511914253, -0.0008356103207916021, -0.021425655111670494, -0.024894071742892265, -0.009168400429189205, -0.01591545157134533, -0.008134419098496437, -0.021661244332790375, 0.011753352358937263, 0.026713354513049126, 0.019331516698002815, 0.00037404094473458827, -0.007643605582416058, 0.00579814612865448, -0.0039068772457540035, -0.008592511527240276, 0.00793809350579977, -0.016229573637247086, -0.008468172512948513, -0.008592511527240276, -0.00644602021202445, -0.008520525880157948, 0.0129771139472723, 0.008906632661819458, 0.024265829473733902, 0.004041032865643501, -0.007898828946053982, 0.049814317375421524, -0.0333753302693367, 0.0021906651090830564, 0.024854805320501328, -0.0006180162308737636, 0.007931549102067947, 0.006053369026631117, -0.013219249434769154, 0.007519266102463007, -0.03628094866871834, 0.0019665269646793604, -0.005912669003009796, 0.0026503941044211388, 0.01621648482978344, 0.0016131410375237465, -0.00440750690177083, 0.010968049988150597, -0.009783552959561348, 0.01786561869084835, 0.011170919984579086, 0.012244165875017643, -0.0069041126407682896, 0.03599300608038902, 0.023415084928274155, 0.012329240329563618, 0.005218985956162214, 0.005768697243183851, -0.01063429657369852, -0.003664742223918438, 0.005065197590738535, 0.025574665516614914, -0.00933854840695858, -0.026438498869538307, 0.01598089374601841, -0.022642871364951134, -0.00033477586111985147, -0.02704056352376938, 0.010673562064766884, -0.0029808753170073032, 0.013363220728933811, 0.010025687515735626, -0.03688301518559456, -0.028742050752043724, 0.0011738627217710018, -0.015797657892107964, 0.01978960819542408, -0.013219249434769154, 0.025195103138685226, -0.018349887803196907, 0.0008662861655466259, -0.008540158160030842, 0.006112266797572374, 0.0188734233379364, -0.033689454197883606, 0.00038426622631959617, 0.011275626718997955, -0.03819185122847557, 0.0005775241297669709, 0.0003458191640675068, 0.008978618308901787, -0.030286477878689766, -0.009057149291038513, -0.01739443838596344, -0.009116046130657196, -0.004286439623683691, 0.0019092652946710587, 0.02387317828834057, 0.014240141957998276, -0.004508941899985075, 0.004198093432933092, 0.011098934337496758, -0.00960686057806015, -0.008383098058402538, -0.005699983332306147, -0.017813265323638916, -0.018467683345079422, 0.00024172574921976775, 0.007781033404171467, 0.012525565922260284, -0.01446264423429966, 0.0007538080681115389, 0.009920980781316757, -0.003821802791208029, 0.01611177809536457, 0.001451172516681254, -0.002386990701779723, -0.019632548093795776, -0.048531658947467804, 0.010778268799185753, 0.005297516006976366, 0.010326720774173737, 0.027668803930282593, -0.033087387681007385, -0.015287211164832115, 0.04172571003437042, -0.016268838196992874, 0.011321435682475567, -0.01992049254477024, -0.014868383295834064, -0.02393862046301365, 0.027249976992607117, -0.00937126949429512, 0.018454594537615776, -0.007925005629658699, -0.025770992040634155, -0.007034996524453163, 0.00466927420347929, 0.019122101366519928, -0.005968294572085142, -0.01679237373173237, -0.008265302516520023, 0.010595032013952732, -0.0046725464053452015, -0.0010266186436638236, -0.02902999520301819, 0.010379074141383171, -0.01446264423429966, 0.010660473257303238, -0.0053891343995928764, -0.004659458063542843, -0.023140229284763336, -0.018834158778190613, 0.0012106738286092877, 0.0205618217587471, -0.00522552989423275, 0.01651751808822155, -0.021085357293486595, -0.004266807343810797, -0.0005255796713754535, -0.02079741284251213, 0.019540930166840553, 0.006105722393840551, 0.04368896409869194, -0.022197868674993515, -0.0037825375329703093, -0.013507192954421043, -0.028611166402697563, -0.00638057803735137, 0.012748068198561668, 0.02231566235423088, -0.0022806476335972548, -0.009567595086991787, -0.01861165650188923, 0.024763187393546104, 0.02727615274488926, -0.020404761657118797, -0.019999021664261818, 0.0063380408100783825, 0.009057149291038513, -0.020116817206144333, -0.01122327335178852, -3.7654612242477015e-05, -0.02167433314025402, 0.026098201051354408, 0.019122101366519928, -0.011301803402602673, -0.012551742605865002, -0.013186528347432613, -0.015496624633669853, 0.04426485300064087, -0.02430509403347969, 0.024737011641263962, 0.009489065036177635, -0.018729450181126595, -0.007820297963917255, 0.010228557512164116, -0.01752532087266445, -0.0004302800225559622, 0.008671042509377003, 0.010274366475641727, 0.00338334240950644, -0.008998251520097256, 0.0055658272467553616, 0.004109746776521206, 0.002519510453566909, 0.010339808650314808, -0.00041616911767050624, 0.031071780249476433, 0.0032753634732216597, -0.009390901774168015, 0.027249976992607117, -0.01897813007235527, 0.014881471171975136, 0.016936345025897026, -0.019069747999310493, 0.01353336963802576, 0.0033866146113723516, 0.0033342610113322735, 0.036254771053791046, 0.01679237373173237, -0.03138589859008789, 0.0005186264752410352, -0.0026373055297881365, -0.007807210087776184, -0.024789365008473396, -0.011026947759091854, 0.013585723005235195, -0.029344115406274796, -0.0246061272919178, -0.02751174382865429, 0.0035829399712383747, 0.019436223432421684, 0.031464431434869766, 0.015077796764671803, 0.0024720649234950542, 0.021765951067209244, -0.005775241181254387, 0.03837508708238602, 0.01918754354119301, 0.001180407009087503, -0.028846757486462593, -0.003468416864052415, -0.008710307069122791, -0.02184448204934597, 0.007080805953592062, -0.0005120823043398559, -0.027825865894556046, -0.029684413224458694, 0.021595802158117294, 0.02612437680363655, -0.002261015120893717, 0.006858303677290678, -0.017001787200570107, 0.01276115607470274, -0.0022937359753996134, 0.008991707116365433, -0.0041228351183235645, -0.0018749083392322063, -0.025731725618243217, -0.007336028851568699, 0.025064220651984215, -0.032040320336818695, -0.012538653798401356, -0.0397886298596859, 0.003151023993268609, 0.017276642844080925, -0.0014159975107759237, -0.009260018356144428, -0.011164375580847263, 0.004296255763620138, -0.021412566304206848, 0.00380871444940567, -0.011655189096927643, 0.004862327594310045, -0.03154296055436134, 0.021019915118813515, 0.002889256691560149, -0.012617184780538082, -0.021085357293486595, 0.008736483752727509, 0.011831882409751415, -0.00403776066377759, -0.022747579962015152, -0.004636553581804037, -0.0017734735738486052, 0.007872652262449265, -0.01591545157134533, -0.005346597172319889, 0.010195836424827576, 0.029239408671855927, 0.03832273557782173, -0.03159531578421593, -0.034605637192726135, 0.007597796153277159, -0.03416063264012337, -0.013729695230722427, 0.019972845911979675, 0.002324820961803198, -0.01925298571586609, 0.02905617095530033, 0.002807454438880086, 0.010143483057618141, 0.0012147639645263553, 0.018729450181126595, -0.02498568966984749, -0.006544182542711496, 0.01995975710451603, -0.002035240875557065, -0.009286195039749146, 0.0017718374729156494, -0.013055644929409027, -0.013742784038186073, 0.023218760266900063, -0.015208681114017963, -0.009390901774168015, 0.015418094582855701, -0.007499633356928825, -0.00265857414342463, 0.0024687929544597864, -0.004603832494467497, 0.01475058775395155, 0.018219005316495895, -0.0025996766053140163, -0.027668803930282593, 0.0002938747056759894, -0.002426255727186799, -0.0008401094819419086, -0.03853214904665947, 0.009384358301758766, 0.018428418785333633, 0.0006090180249884725, 0.005009572021663189, -0.04143776372075081, -0.03609771281480789, 0.007427647244185209, -0.02235492877662182, -0.009102958254516125, 0.00493104150518775, -0.03392504155635834, 0.0259542278945446, -0.017315907403826714, 0.0015076161362230778, 0.0034356960095465183, 0.0006687336717732251, -0.0031755645759403706, 0.026791883632540703, 0.02188374660909176, -0.012113282456994057, -0.022263308987021446, -0.020718881860375404, 0.003589484142139554, -0.017538409680128098, -0.004806702025234699, -0.006586719769984484, -0.02154344879090786, -0.007807210087776184, 0.02066652849316597, 0.0035174982622265816, -0.0022070256527513266, -0.027956748381257057, -0.01240777038037777, -0.014789853245019913, 0.0016818549484014511, -0.024684656411409378, 0.001413543475791812, 0.002205389551818371, 0.002545687137171626, 0.009646125137805939, -0.036123890429735184, 0.010470692068338394, -0.017342085018754005, -0.00017004649271257222, 0.004446772392839193, 0.010496868751943111, 0.22742344439029694, -0.000854833866469562, -0.0237684715539217, 0.0230878759175539, -0.013886755332350731, 0.012106738053262234, 0.015889275819063187, 0.006246422417461872, 0.023506704717874527, 0.0038348911330103874, 0.0052451626397669315, -0.010169659741222858, -0.028401752933859825, 0.0015280666993930936, -0.0037825375329703093, -0.029684413224458694, -0.01810120977461338, -0.010437971912324429, 0.0212424173951149, -0.022813020274043083, -0.006805949844419956, -0.0053007882088422775, -0.012990202754735947, -0.020182259380817413, 0.03023412451148033, 0.025038043037056923, -0.0011934953508898616, 0.003916693385690451, 0.021111533045768738, -0.0047347163781523705, -0.018297534435987473, 0.005830866750329733, 0.004378058481961489, 0.01773473434150219, -0.011570114642381668, -0.012905128300189972, 0.01237504929304123, 0.01891268789768219, 0.01464588101953268, 0.015208681114017963, 0.020234612748026848, -0.022433457896113396, -0.0176954697817564, -0.022525077685713768, 0.010143483057618141, 0.01790488325059414, 0.009260018356144428, -0.02147800847887993, 0.014148523099720478, 0.001876544440165162, -0.01807503215968609, -0.00019090608111582696, 0.01867709681391716, 0.009580683894455433, -0.006315136328339577, -0.02642541006207466, 0.01632119156420231, 0.028532637283205986, 0.016949433833360672, 0.019815785810351372, 0.004466404672712088, 0.002684751059859991, -0.008965530432760715, 0.01814047433435917, -0.018258269876241684, 0.014973090030252934, -0.015601331368088722, -0.00010532043961575255, 0.00800353568047285, -0.002362449886277318, -0.0018847245955839753, -0.0033637098968029022, 0.007165879942476749, 0.01321270503103733, -0.021831393241882324, 0.0016205032588914037, 0.013062188401818275, 0.015300299040973186, 0.007813754491508007, 0.01756458729505539, 0.004351881332695484, -0.01594162918627262, -0.014318672008812428, -0.005474208854138851, -0.008821558207273483, -0.015548978000879288, -0.013481016270816326, 0.012525565922260284, -0.001263027312234044, 0.019331516698002815, 0.0031019425950944424, -0.0055658272467553616, -0.03348004072904587, -0.0025800440926104784, 0.003605844685807824, -0.017171936109662056, 0.005876676179468632, -0.004558023065328598, 0.005382590461522341, -0.006668522022664547, -0.003700735280290246, 0.026202907785773277, 0.004312616307288408, -0.004688906949013472, 0.0031641123350709677, 0.0013145627453923225, -0.023074788972735405, 0.011236362159252167, 0.02194918878376484, -0.021962277591228485, 0.00293670198880136, -0.04379367083311081, 0.008677585981786251, -0.01311454176902771, 0.017250465229153633, 0.01159629225730896, 0.0088477348908782, -0.002136675640940666, -0.010987683199346066, -0.00461037689819932, 0.021294770762324333, 0.0016098689520731568, -0.011537394486367702, 0.009214209392666817, 0.012741523794829845, -0.013546458445489407, 0.02073197066783905, -0.006315136328339577, 0.01611177809536457, -0.008343832567334175, 0.02221095561981201, -0.014266318641602993, 0.008219493553042412, -0.015405005775392056, -0.0026389416307210922, -7.459345943061635e-05, -0.006112266797572374, -0.008978618308901787, 0.009325460530817509, -0.006884480360895395, 0.01752532087266445, -0.008121331222355366, -0.014881471171975136, 0.008441995829343796, 0.030522068962454796, -0.016124866902828217, 0.021582715213298798, 0.02255125343799591, 0.00217430479824543, -0.018716363236308098, -0.012276886962354183, 0.011465407907962799, 0.003811986418440938, -0.01261064037680626, 0.015182503499090672, 0.015444271266460419, -0.009332004934549332, -0.005382590461522341, -0.012885496020317078, -0.014174699783325195, -0.019815785810351372, -0.00604355288669467, 0.008749572560191154, -0.0012523930054157972, -0.018284447491168976, 0.014266318641602993, -0.16596047580242157, 0.013003291562199593, 0.03633330389857292, -0.024462155997753143, -0.013860578648746014, 0.020208436995744705, 0.03523388132452965, -0.008049344643950462, -0.021386388689279556, 0.014907647855579853, 0.020679617300629616, -0.015313387848436832, -0.00797081459313631, -0.02976294234395027, 0.005346597172319889, -0.020745059475302696, -0.011314892210066319, 0.0599970668554306, 0.006832126993685961, 0.01244049146771431, 0.011622468940913677, 0.002853263635188341, 0.027249976992607117, -0.008258759044110775, 0.0050226603634655476, -0.02800910174846649, -0.027852041646838188, 0.047851063311100006, 0.013546458445489407, -0.018009589985013008, -0.011903868056833744, 0.014384113252162933, -0.008566334843635559, -0.0032671832013875246, -0.0212424173951149, -0.020653441548347473, 0.011635556817054749, -0.03329680114984512, -0.007414558902382851, -0.001059339614585042, 0.027825865894556046, 0.021386388689279556, -0.022577431052923203, -0.001088788383640349, -0.00693683372810483, -0.004541662987321615, 0.006982643157243729, -0.008422363549470901, 0.017944149672985077, -0.0367521308362484, -0.00723132211714983, -0.01726355403661728, -0.001989431446418166, -0.014449555426836014, 0.002545687137171626, -0.010019144043326378, -0.006714331451803446, 0.012178723700344563, 0.0001692284713499248, -0.031909435987472534, 0.003697463311254978, -0.02126859314739704, 0.010320176370441914, -0.004191549029201269, -0.00749308941885829, -0.00960686057806015, -0.005902852863073349, 0.0029710589442402124, -0.031019426882267, 0.005592003930360079, -0.004531846381723881, -0.030495891347527504, 0.00100535003002733, -0.03416063264012337, 0.01698869839310646, 0.0016834910493344069, -0.012872407212853432, -0.007898828946053982, -0.0022004814818501472, 0.023951709270477295, -0.0007104528485797346, 0.036019179970026016, -0.018480772152543068, 0.005971566773951054, -0.0088477348908782, 0.0019648908637464046, -0.0026389416307210922, 0.010987683199346066, -0.013107998296618462, -0.004630009178072214, 0.031909435987472534, -0.03253767639398575, -0.01510397344827652, -0.025129660964012146, -0.005755608901381493, 0.007447279989719391, -0.007643605582416058, -0.03960539400577545, 0.0306791290640831, -0.024501420557498932, 0.002285555936396122, -0.0007214961224235594, -0.012198356911540031, 0.011288715526461601, 0.0367521308362484, -0.012381593696773052, 0.0295011755079031, 0.011288715526461601, 0.04154247045516968, 0.0056836227886378765, -0.0254568699747324, -0.00915531162172556, -0.0065605430863797665, 0.03416063264012337, -0.002526054624468088, 0.03622859716415405, -0.006845215335488319, -0.01975034363567829, 0.01552280131727457, -0.012630272656679153, 0.05141109973192215, -0.005951934028416872, -0.0303388312458992, 0.037432726472616196, -0.0110400365665555, -0.018650921061635017, -0.11905176937580109, -0.009521786123514175, 0.03115030936896801, 0.00933854840695858, 0.02467156946659088, 0.02094138413667679, 0.0003719958767760545, 0.00021452648798003793, 0.005690166726708412, 0.028427930548787117, -0.01208710577338934, -0.020889030769467354, -0.010791357606649399, -0.00305122509598732, 0.011471952311694622, -0.018323712050914764, 0.0006131081026978791, -0.02225022204220295, -0.007702502887696028, 0.034841228276491165, -0.004381330218166113, -0.026791883632540703, -0.01709340512752533, 0.004237358458340168, 0.005418583285063505, -0.008991707116365433, -0.03837508708238602, 0.009227297268807888, -0.007807210087776184, 0.007990446873009205, 0.0006572813726961613, -0.014868383295834064, -0.0017554770456627011, -0.004626736976206303, -0.01961945928633213, 0.0004961308441124856, -0.0053891343995928764, -0.009672301821410656, 0.010889519937336445, -0.00611881073564291, 0.011249450035393238, 0.017839442938566208, 0.03884626924991608, -0.019907403737306595, 0.016870902851223946, -0.007695958949625492, -0.05039020627737045, 0.01353336963802576, -0.01083716657012701, -0.022577431052923203, -0.02015608362853527, -0.016255749389529228, -0.013651165179908276, -0.0034062471240758896, 0.001979615306481719, -0.03217120096087456, 0.00842890702188015, 0.0055723716504871845, -0.010490325279533863, -0.010045320726931095, 0.010195836424827576, 0.004705267492681742, -0.015143238939344883, 0.03536476194858551, 0.027328507974743843, -0.017041051760315895, -0.0313597247004509, 0.014920736663043499, 0.0036320213694125414, -0.0051175509579479694, -0.01090260874480009, 0.01352028176188469, -0.021582715213298798, 0.018428418785333633, -0.02683115005493164, 0.0060173762030899525, -0.02015608362853527, 0.00494740204885602, 0.01220490038394928, 0.004875415936112404, -0.013795137405395508, -0.008441995829343796, -0.0062333340756595135, -0.005768697243183851, -0.005575643852353096, 0.024187298491597176, -0.014920736663043499, -0.002740376628935337, -0.001933805993758142, -0.01786561869084835, 0.0007697594701312482, 0.04274660348892212, 0.008356921374797821, -0.006311864126473665, -0.02751174382865429, -0.006877935957163572, -0.00849434919655323, 0.006720875855535269, -0.007388382218778133, -0.003131391480565071, 0.00616789236664772, 0.004381330218166113, -0.0364118330180645, 0.013795137405395508, 0.012872407212853432, -0.007853019051253796, 0.0036189330276101828, 0.0009227297850884497, 0.03698772192001343, 0.005359685514122248, 0.03863685578107834, -0.014161611907184124, -0.03243296965956688, 0.001636863686144352, -0.01891268789768219, -0.012669538147747517, -0.007781033404171467, -0.00021043638116680086, 0.023349644616246223, 0.0025702277198433876, 0.015470447950065136, -0.014017639681696892, -0.008363465778529644, 0.011013859882950783, -0.004953946452587843, 0.01901739463210106, 0.002185757039114833, -0.001609050901606679, -0.00018262359662912786, 0.017616940662264824, -0.027249976992607117, -0.02454068511724472, 0.017917972058057785, -0.022368015721440315, -0.004158827941864729, 0.008121331222355366, -0.022106248885393143, -0.01083716657012701, -0.015850011259317398, 0.03031265363097191, 0.0041162907145917416, -0.005336781032383442, 0.00888045597821474, 0.007578163407742977, -0.026333792135119438, -0.021464919671416283, 0.01006495300680399, 0.018991218879818916, -0.019292250275611877, 0.0038054422475397587, 0.0009636309114284813, -0.01321270503103733, -0.0026634824462234974, 0.011727175675332546, -0.016465162858366966, -0.0064492919482290745, -0.031071780249476433, -0.014789853245019913, -0.008500893600285053, -0.024357447400689125, 0.019292250275611877, -0.027459390461444855, 0.044186320155858994, -0.005922485608607531, 0.0055102016776800156, -0.0062824152410030365, 0.024030238389968872, 0.004574383608996868, 0.010477236472070217, 0.006982643157243729, 0.010019144043326378, -0.02753792144358158, -0.01688399165868759, -0.01662222482264042, 0.002733832225203514, -0.007480001077055931, 0.014004550874233246, 0.0027485566679388285, -0.007427647244185209, 0.023375820368528366, 0.0046790908090770245, 0.00908332597464323, 0.0387677401304245, -0.006262782961130142, -0.027668803930282593, 0.0019697989337146282, 0.04065246134996414, 0.020404761657118797, -0.01285931933671236, 0.013441751711070538, -0.014960002154111862, 0.008553246967494488, -0.004191549029201269, -0.012924760580062866, -0.004181732889264822, -0.005938845686614513, -0.003753088880330324, 0.014920736663043499, -0.031673844903707504, -0.007944637909531593, 0.014855294488370419, 0.027433214709162712, -0.010365985333919525, 0.021019915118813515, 0.002529326593503356, -0.015300299040973186, -0.014266318641602993, 0.0249464251101017, -0.0018290990265086293, -0.03128119185566902, -0.008841190487146378, 0.022904640063643456, -0.0003519543388392776, 0.0323544405400753, 0.014672057703137398, 0.005951934028416872, -0.002454068511724472, -0.010222013108432293, -0.027328507974743843, -0.0038708841893821955, -0.026883503422141075, 0.009705022908747196, 0.0010986046399921179, -0.01621648482978344, -0.012597551569342613, 0.008572879247367382, 0.01914827898144722, -0.0008466536528430879, 0.015627508983016014, 0.014685146510601044, 0.00024029420455917716, 0.012682626023888588, 0.011373789981007576, 0.0036287494003772736, -0.001393910963088274, -0.01925298571586609, -0.008867367170751095, -0.024501420557498932, -0.007041540462523699, -0.012937849387526512, -0.02255125343799591, 0.06994422525167465, 0.015247945673763752, -0.0034356960095465183, 0.011923501268029213, 0.0024295279290527105, 0.02902999520301819, 0.014357936568558216, -0.0025244185235351324, -0.05376700684428215, -0.01763002760708332, 0.037406548857688904, -0.0044565885327756405, 0.00076280627399683, -0.04861018806695938, 0.00827839132398367, 0.03081001155078411, 0.013454839587211609, 0.022904640063643456, 0.005634541157633066, -0.020875943824648857, 0.015692949295043945, -0.0055658272467553616, 0.015954717993736267, -0.013651165179908276, 0.004463132470846176, -0.008513981476426125, 0.03206649422645569, -0.01897813007235527, -0.020103730261325836, -0.010529589839279652, 0.024161122739315033, 0.0008654681732878089, -0.026883503422141075, -0.0014356301398947835, 0.008605600334703922, 0.008376553654670715, -0.0017718374729156494, -0.010509957559406757, -0.0014168155612424016, 0.03046971559524536, -0.017080316320061684, -0.005058653187006712, -0.02197536639869213, -0.004387874621897936, -0.036595068871974945, 0.0015018898993730545, -0.012355417013168335, -0.0035763958003371954, -0.03452710807323456]}}, rets=[{'node': {'id_': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'b5542e96-351d-4501-a621-d2aaee1386eb', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '47845a6529a286c4db5938e0f0349691964e347496cd3c65c4a3feff45ba6666'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'bdde83a5-6a37-4e11-9adf-5717c3b28b88', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '505dfda29fbdfe6cf75948c2f2605eed66b308f218805e30fc5050105bf992da'}}, 'text': \"We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, . So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n. Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n-\\n113, Measuring Heart Rate\\n. Heart rate can be measured by\\n2, . listening to the chest\\n4, . Sensing minute changes in blood flow via \\nphotoplethysmography\\n. (\\n2, ) are ambulatory, for \\nemergency response while (\\n4, ) \\ncan be embedded in wearable sensors\\n-\\n115, . Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n. Used on watches like Apple \\nWatch where you see\\n2, LEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n-\\n117, Measuring Blood Pressure\\n. Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n. BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n. BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n. Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n-\\n119, Measuring Respiration\\n. Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n. Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n. Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n-\\n121, -\\n123, Polygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n-\\n125, -\\n127, -\\n5, stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n. Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n. The first sleep cycle is usually shortest at\\n100, minutes. Later cycles are\\n110, minutes. \\n. If you sleep for\\n5, full \\ncycles\\nSleep Explained\\n-\\n130, Why is sleep important ?\\n. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n.\", 'start_char_idx': 16001, 'end_char_idx': 19861, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8357276384880378}, {'node': {'id_': '65ee4e5e-d2af-4f4d-9438-c85b8552fc6d', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': '700ef3cc-d626-4043-8c6c-7338f125c83f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '78f58d9e57c6c8935ac8b4be1e2f5cf70fdf9b0144e19d7b8ac69c48ee7e3928'}}, 'text': 'We know the brain consists of simple but \\nmassively parallel processing\\n. Each of the 86B cells in the brain connects to\\n184, Human Memory\\n. As a re-cap from earlier MOOC on memory … \\n. Sensory – short term, \\nrapid decay unless \\nrefreshed, passed to…\\n. Short-term if attentive,\\nthe “post-it” note, \\nusually only\\n185, Brain Activity\\n. So if brain activity is “only” firing neural \\ncircuits, can we “listen” to this by sensing the \\nelectrical activity ? \\n. Yes of course\\n. BCI (Brain Computer Interface) is a \\ncommunication channel capable of operation \\nentirely on neural signals\\n. Many sensing technologies exist: \\nEEG, nIR, MEG, PET, ECoG, Local Field \\nPotentials, fMRI\\n. Each offers its own interaction paradigms and \\ncapabilities but we are interested in EEG\\n-\\n1, or\\n32, ,\\n128, (as in image)\\nor even\\n187, EEG\\n. Some more \\nexamples of \\nEEG\\n-\\n189, EEG – What to Measure ?\\n.\\nIn MOOC\\n2, -node EEG \\n.\\nSo we can use EEG to measure attention in a way that \\nis similar to “listening” to the amount of “traffic” in the \\nbrain, not localising it or determining where in the \\nbrain, just how active the brain actually is\\n.\\nBut we can do more \\nwhen we determine \\nwhere in the brain, the\\nactivity is, so we use \\nmany nodes and even\\ntriangulate to pinpoint\\nthe places in the brain \\nwhere the greatest activities\\nare\\n-\\n191, . We are interested in ERPs (Event Related \\nPotentials) electrical responses at certain scalp \\npoints, generated by the brain in response to \\nstimuli such as an image, \\nsound, touch, taste… \\n. There are several \\nknown ERPs including \\nP1, N1, P2, N2 and P3\\nwhich occur\\n170, ,\\n250, and\\n3, .\\n5543904, -\\n193, A Face\\n-\\n1996, , in certain parts of \\nyour brain (unless you were mindwandering or \\nasleep and didn’t actually see the face, so pay \\nattention !)\\n. It was probably around your occipitotemporal \\narea, slightly to the right side, \\nbetween Pz and P4\\n. If you had a couple of EEG nodes\\nthere then\\n17, seconds after\\nseeing Michael D’s face on \\nyour screen, they would have \\ndetected a voltage change\\n-\\n0, .\\n196, -\\n198, -\\n200, P300 elicitation\\n. We’re going to show a series of \\nimages, about\\n201, P300 elicitation\\n-\\n203, P300 elicitation\\n-\\n205, P300 elicitation\\n-\\n207, P300 elicitation\\n-\\n209, P300 elicitation\\n-\\n211, P300 elicitation\\n-\\n213, P300 elicitation\\n-\\n215, P300 wave\\n.\\nThere’s nothing special about the Coke \\ncan. It’s just that you did not know when \\nit was going to appear, and since I told \\nyou to look out for it, its appearance \\ncaught your attention, you recognised it\\n.\\nI could have as equally used any object \\nthat you may be looking for or expecting \\n.\\nSo there is an idea that when searching \\nfor images, we can have a BCI interface \\nbased on using EEG sensors to detect \\nwhen you see something you recognise\\n.\\nResearchers (like us) are working on this \\nkind of interface\\n-', 'start_char_idx': 25518, 'end_char_idx': 28321, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.7741041533786612}, {'node': {'id_': 'bdde83a5-6a37-4e11-9adf-5717c3b28b88', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6ddaba9026c3bfa326cb469008bb1132a55e8043ae18bfb5703bef3358e41b97'}, <NodeRelationship.NEXT: '3'>: {'node_id': '700ef3cc-d626-4043-8c6c-7338f125c83f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'bd47aad3b039faf924234cb81e420c8cea1fe256dd880b8b0070313b7ba485e7'}}, 'text': '. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n. Leads to dark circles under the eyes, \\ntopical creams used to camouflage \\n. Also more wrinkles because less \\ncollagen produced, puffy eyes, no \\n“glow”\\n. … and … you don’t look happy\\nSleep and Appearance\\n-\\n134, -\\n1, . Phone apps\\n3, . Movement radar or sonar\\n136, Presented as a Hypnogram\\n-\\n1, . Smartphone Apps\\n-\\n2, . Wrist-worn Accelerometers \\n-\\n3, . Sonar / Radar\\n-\\n4, . The Ōura Ring\\n. From a Finnish start-up, a (finger) \\nring with in-built accelerometer and \\ngyroscope and also measures \\nbody temperature, and heart rate\\n. HR sampled using IR spectrum \\nlight from\\n250, Hz so \\nable to do much more than wrist-\\nworn HR sensors\\n. Contactless battery charge lasts\\n6, weeks\\n. Low power Bluetooth download to \\nphone \\n-\\n142, And what about Alan’s Sleep ?\\n. Here’s a sample of summary data over\\n143, And what about Alan’s Sleep ?\\n-\\n145, . Some use it to inform or influence day-to-day \\nactivities\\n. Some look at trends, but the trends don’t say a lot \\nbecause other factors influence those trends \\n(travel, vacation, stress, colds and flu, sports \\nevents, etc.) and we can’t see those.\\n. That’s because sleep apps, activity apps, health \\napps, all work independently of each other, not \\nsynchronised\\n. So there is not a lot we can actually usefully do \\nwith our own sleep data or any other lifelog data\\n. We can’t easily integrate it or re-purpose it and \\nbecause it reports day-at-a-time information its \\ndifficult to get useful longitudinal analysis.\\nSo what to do with this information ?\\n-\\n1, . We can aggregate our own personal \\ndata with data from other users, \\nacross a population\\n147, . Almost all vendors who allow us gather \\nindividual data, get value from pooling \\nanonymised data\\n. Let’s look at\\n148, . Fitbit – wearable wrist-worn activity logger \\nand sleep recorder\\n. Fitbit mined 150B hours of heart rate data, \\ngathering statistics from millions of sleep \\nnights and discovered the following\\nPopulation-level Analytics from Pooled \\nIndividual Data\\n-\\n150, . Some fitbit devices also record heart \\nrate, so they mined that to correlate \\nresting heart rate (a wellness indicator) \\nwith body-mass index (a weight \\nindicator), age, and amount of exercise \\n. They found insights that cardiologists \\nwere not aware of\\n-\\n150, -billion-hours-heart-data-reveals-secrets-human-health-\\n152, Population-level Analytics from Pooled \\nIndividual Data\\n. 23andMe is a DNA testing company \\nwho’s catchphrase is to allow you to \\n”meet your genes”\\n. From a saliva sample they synthesise\\nyour DNA and search it for DNA \\nmarkers which\\n2, . Report your Genetic Health Risks (whether \\nyou have genetic variants associated with \\nincreased risk for certain(+\\n153, Population-level Analytics from \\nPooled Individual Data\\n. 23andMe provides benefit to the \\nindividual (gene markers) but even \\nmore benefit when data is pooled in \\norder to connect relatives and \\ndetermine actual exposure risk to \\ndiseases based on population analysis\\n-\\n155, -\\n157, -\\n2, years, \\nupdated monthly, showing areas where \\npeople run/cycle \\n. Next slide is DCU campus, Albert \\nCollege Park stands out clearly\\n.', 'start_char_idx': 19134, 'end_char_idx': 22931, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.7693013601835065}, {'node': {'id_': 'b5542e96-351d-4501-a621-d2aaee1386eb', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': '84aa3389-cf64-4c66-acdd-f4226b070976', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '8dc42eb46625763ae763b459257b106dd73c40c3814e9c0024dc2dae20698eed'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'b2753bf8c2867da5166f372338f053555471cef0350a4b79b3844aa82ef5a4e5'}}, 'text': '.A network of infra-red lights and cameras around the subject \\ncapture the markers and in real time, combine them to generate \\na 3D model of the user\\n.This is very accurate - sampling rate is\\n7, -\\n86, -\\n86, Motion Capture, Our Approach\\n. Inertial sensing\\n– Synthesize realistic motion from \\nInertial Measurement Units (IMU)\\n. Contextual information\\n– Single low-cost camera if available\\n. Off-line\\n– Capture prototypical movements\\n– Build motion graph\\n. Pre-capture\\n– Define IMU placement\\n– Add virtual IMU data to motion graph\\n. On-line\\n– Search motion graph\\n– Match virtual & real IMU data\\n87, -\\nHow well does it work ?\\n87, nan\\n88, -\\nKinect\\n. And then came the Microsoft Kinect !\\n. Sits on top of a TV or computer screen and \\ncontains an integrated microphone array, \\nvisible spectrum camera and IR-based depth \\ncamera\\n. Intended to be a proprietary interface to the \\nX-Box gaming console but it was quickly \\nhacked, so Microsoft gave up and released an \\nAPI so anyone could use it for anything\\n-\\n90, -\\nMicrosoft Kinect\\n. Kinect is a form of AR\\n. Works by sending out patterns of dots \\nin invisible spectrum light, and then \\npicks them up with a camera\\n. https://www.youtube.com/watch?v=dT\\nKlNGSH9Po&feature=related\\n. Using this, Kinect knows how far you \\nare from the camera (depth map) and \\ncan augment the video camera image \\non the screen\\n. One example app is the virtual dressing \\nroom where you can “try on” clothes …\\n-\\n9, nan\\n92, -\\n. Details at \\nhttps://www.youtube.com/watch?v=\\n93, -\\nSlide\\n94, -\\nTexture-based retrieval results\\n.\\nQuery :\\nTop\\n95, -\\nTexture-based retrieval results\\n.\\nQuery :\\nTop\\n96, -\\nColour-based retrieval results\\nQuery :\\nTop\\n97, -\\nKinect\\n. Best hacks … \\n. #\\n9, (wall) we did this for NMI treasure \\nroom (award-winning at MM2011)\\n. Play the others and be inspired !\\n. All revolve around sensing what you are \\ndoing, now\\n-\\n99, -\\nWeek\\n100, Sensing the Body - Physiology\\n. Our physiology is the set of outward signs that \\nour body gives constantly, to indicate what state \\nour bodies are in.\\n. For example \\n– when we perspire its an indication we’re too hot and \\nwe need to cool down; \\n– when we’ve goosepimples on our arms it means the \\nenvironment is too cold for us and we need to \\npreserve heat hence the goosepimples; \\n– when our breathing is fast it means we’re extending \\nourselves and we need to get more oxygen into our \\nblood streams because we’re exercising, or we’re \\ntense\\n-\\n102, Sensing the Body - Physiology\\n. Mostly, and the main reason we sense our bodies, is for \\nhealth reasons, \\n– we monitor our heart rate when we exercise\\n– we track our movement so as to count our exercise or number of \\nsteps taken in a day\\n– older people at home and lone workers in forests and remote areas \\nwear fall detectors to detect when accidents have occurred\\n– the hard of hearing use hearing aids and some people have their \\nheart rates regularised with implanted pacemakers, etc. \\n. While health and wellness reasons are the main reason, \\nthere are others also, like measuring our reaction to \\nadvertising material (just as an example)\\n-\\n104, . Lets see some examples …. (see slide \\nnote)\\n. We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, .', 'start_char_idx': 12884, 'end_char_idx': 16811, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.7683269285060644}], error=None, perf=Perf(start_time=datetime.datetime(2024, 3, 4, 16, 59, 34, 988665), end_time=datetime.datetime(2024, 3, 4, 16, 59, 35, 507266)), pid=555, tid=555), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='retrieve')), RecordAppCallMethod(path=Lens().app._node_postprocessors[0], method=Method(obj=Obj(cls=llama_index.core.postprocessor.node.SimilarityPostprocessor, id=140331674851776, init_bindings=None), name='_postprocess_nodes'))], args={'nodes': [{'node': {'id_': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'b5542e96-351d-4501-a621-d2aaee1386eb', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '47845a6529a286c4db5938e0f0349691964e347496cd3c65c4a3feff45ba6666'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'bdde83a5-6a37-4e11-9adf-5717c3b28b88', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '505dfda29fbdfe6cf75948c2f2605eed66b308f218805e30fc5050105bf992da'}}, 'text': \"We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, . So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n. Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n-\\n113, Measuring Heart Rate\\n. Heart rate can be measured by\\n2, . listening to the chest\\n4, . Sensing minute changes in blood flow via \\nphotoplethysmography\\n. (\\n2, ) are ambulatory, for \\nemergency response while (\\n4, ) \\ncan be embedded in wearable sensors\\n-\\n115, . Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n. Used on watches like Apple \\nWatch where you see\\n2, LEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n-\\n117, Measuring Blood Pressure\\n. Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n. BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n. BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n. Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n-\\n119, Measuring Respiration\\n. Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n. Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n. Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n-\\n121, -\\n123, Polygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n-\\n125, -\\n127, -\\n5, stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n. Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n. The first sleep cycle is usually shortest at\\n100, minutes. Later cycles are\\n110, minutes. \\n. If you sleep for\\n5, full \\ncycles\\nSleep Explained\\n-\\n130, Why is sleep important ?\\n. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n.\", 'start_char_idx': 16001, 'end_char_idx': 19861, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8357276384880378}, {'node': {'id_': '65ee4e5e-d2af-4f4d-9438-c85b8552fc6d', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': '700ef3cc-d626-4043-8c6c-7338f125c83f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '78f58d9e57c6c8935ac8b4be1e2f5cf70fdf9b0144e19d7b8ac69c48ee7e3928'}}, 'text': 'We know the brain consists of simple but \\nmassively parallel processing\\n. Each of the 86B cells in the brain connects to\\n184, Human Memory\\n. As a re-cap from earlier MOOC on memory … \\n. Sensory – short term, \\nrapid decay unless \\nrefreshed, passed to…\\n. Short-term if attentive,\\nthe “post-it” note, \\nusually only\\n185, Brain Activity\\n. So if brain activity is “only” firing neural \\ncircuits, can we “listen” to this by sensing the \\nelectrical activity ? \\n. Yes of course\\n. BCI (Brain Computer Interface) is a \\ncommunication channel capable of operation \\nentirely on neural signals\\n. Many sensing technologies exist: \\nEEG, nIR, MEG, PET, ECoG, Local Field \\nPotentials, fMRI\\n. Each offers its own interaction paradigms and \\ncapabilities but we are interested in EEG\\n-\\n1, or\\n32, ,\\n128, (as in image)\\nor even\\n187, EEG\\n. Some more \\nexamples of \\nEEG\\n-\\n189, EEG – What to Measure ?\\n.\\nIn MOOC\\n2, -node EEG \\n.\\nSo we can use EEG to measure attention in a way that \\nis similar to “listening” to the amount of “traffic” in the \\nbrain, not localising it or determining where in the \\nbrain, just how active the brain actually is\\n.\\nBut we can do more \\nwhen we determine \\nwhere in the brain, the\\nactivity is, so we use \\nmany nodes and even\\ntriangulate to pinpoint\\nthe places in the brain \\nwhere the greatest activities\\nare\\n-\\n191, . We are interested in ERPs (Event Related \\nPotentials) electrical responses at certain scalp \\npoints, generated by the brain in response to \\nstimuli such as an image, \\nsound, touch, taste… \\n. There are several \\nknown ERPs including \\nP1, N1, P2, N2 and P3\\nwhich occur\\n170, ,\\n250, and\\n3, .\\n5543904, -\\n193, A Face\\n-\\n1996, , in certain parts of \\nyour brain (unless you were mindwandering or \\nasleep and didn’t actually see the face, so pay \\nattention !)\\n. It was probably around your occipitotemporal \\narea, slightly to the right side, \\nbetween Pz and P4\\n. If you had a couple of EEG nodes\\nthere then\\n17, seconds after\\nseeing Michael D’s face on \\nyour screen, they would have \\ndetected a voltage change\\n-\\n0, .\\n196, -\\n198, -\\n200, P300 elicitation\\n. We’re going to show a series of \\nimages, about\\n201, P300 elicitation\\n-\\n203, P300 elicitation\\n-\\n205, P300 elicitation\\n-\\n207, P300 elicitation\\n-\\n209, P300 elicitation\\n-\\n211, P300 elicitation\\n-\\n213, P300 elicitation\\n-\\n215, P300 wave\\n.\\nThere’s nothing special about the Coke \\ncan. It’s just that you did not know when \\nit was going to appear, and since I told \\nyou to look out for it, its appearance \\ncaught your attention, you recognised it\\n.\\nI could have as equally used any object \\nthat you may be looking for or expecting \\n.\\nSo there is an idea that when searching \\nfor images, we can have a BCI interface \\nbased on using EEG sensors to detect \\nwhen you see something you recognise\\n.\\nResearchers (like us) are working on this \\nkind of interface\\n-', 'start_char_idx': 25518, 'end_char_idx': 28321, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.7741041533786612}, {'node': {'id_': 'bdde83a5-6a37-4e11-9adf-5717c3b28b88', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6ddaba9026c3bfa326cb469008bb1132a55e8043ae18bfb5703bef3358e41b97'}, <NodeRelationship.NEXT: '3'>: {'node_id': '700ef3cc-d626-4043-8c6c-7338f125c83f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'bd47aad3b039faf924234cb81e420c8cea1fe256dd880b8b0070313b7ba485e7'}}, 'text': '. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n. Leads to dark circles under the eyes, \\ntopical creams used to camouflage \\n. Also more wrinkles because less \\ncollagen produced, puffy eyes, no \\n“glow”\\n. … and … you don’t look happy\\nSleep and Appearance\\n-\\n134, -\\n1, . Phone apps\\n3, . Movement radar or sonar\\n136, Presented as a Hypnogram\\n-\\n1, . Smartphone Apps\\n-\\n2, . Wrist-worn Accelerometers \\n-\\n3, . Sonar / Radar\\n-\\n4, . The Ōura Ring\\n. From a Finnish start-up, a (finger) \\nring with in-built accelerometer and \\ngyroscope and also measures \\nbody temperature, and heart rate\\n. HR sampled using IR spectrum \\nlight from\\n250, Hz so \\nable to do much more than wrist-\\nworn HR sensors\\n. Contactless battery charge lasts\\n6, weeks\\n. Low power Bluetooth download to \\nphone \\n-\\n142, And what about Alan’s Sleep ?\\n. Here’s a sample of summary data over\\n143, And what about Alan’s Sleep ?\\n-\\n145, . Some use it to inform or influence day-to-day \\nactivities\\n. Some look at trends, but the trends don’t say a lot \\nbecause other factors influence those trends \\n(travel, vacation, stress, colds and flu, sports \\nevents, etc.) and we can’t see those.\\n. That’s because sleep apps, activity apps, health \\napps, all work independently of each other, not \\nsynchronised\\n. So there is not a lot we can actually usefully do \\nwith our own sleep data or any other lifelog data\\n. We can’t easily integrate it or re-purpose it and \\nbecause it reports day-at-a-time information its \\ndifficult to get useful longitudinal analysis.\\nSo what to do with this information ?\\n-\\n1, . We can aggregate our own personal \\ndata with data from other users, \\nacross a population\\n147, . Almost all vendors who allow us gather \\nindividual data, get value from pooling \\nanonymised data\\n. Let’s look at\\n148, . Fitbit – wearable wrist-worn activity logger \\nand sleep recorder\\n. Fitbit mined 150B hours of heart rate data, \\ngathering statistics from millions of sleep \\nnights and discovered the following\\nPopulation-level Analytics from Pooled \\nIndividual Data\\n-\\n150, . Some fitbit devices also record heart \\nrate, so they mined that to correlate \\nresting heart rate (a wellness indicator) \\nwith body-mass index (a weight \\nindicator), age, and amount of exercise \\n. They found insights that cardiologists \\nwere not aware of\\n-\\n150, -billion-hours-heart-data-reveals-secrets-human-health-\\n152, Population-level Analytics from Pooled \\nIndividual Data\\n. 23andMe is a DNA testing company \\nwho’s catchphrase is to allow you to \\n”meet your genes”\\n. From a saliva sample they synthesise\\nyour DNA and search it for DNA \\nmarkers which\\n2, . Report your Genetic Health Risks (whether \\nyou have genetic variants associated with \\nincreased risk for certain(+\\n153, Population-level Analytics from \\nPooled Individual Data\\n. 23andMe provides benefit to the \\nindividual (gene markers) but even \\nmore benefit when data is pooled in \\norder to connect relatives and \\ndetermine actual exposure risk to \\ndiseases based on population analysis\\n-\\n155, -\\n157, -\\n2, years, \\nupdated monthly, showing areas where \\npeople run/cycle \\n. Next slide is DCU campus, Albert \\nCollege Park stands out clearly\\n.', 'start_char_idx': 19134, 'end_char_idx': 22931, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.7693013601835065}, {'node': {'id_': 'b5542e96-351d-4501-a621-d2aaee1386eb', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': '84aa3389-cf64-4c66-acdd-f4226b070976', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '8dc42eb46625763ae763b459257b106dd73c40c3814e9c0024dc2dae20698eed'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': 'b2753bf8c2867da5166f372338f053555471cef0350a4b79b3844aa82ef5a4e5'}}, 'text': '.A network of infra-red lights and cameras around the subject \\ncapture the markers and in real time, combine them to generate \\na 3D model of the user\\n.This is very accurate - sampling rate is\\n7, -\\n86, -\\n86, Motion Capture, Our Approach\\n. Inertial sensing\\n– Synthesize realistic motion from \\nInertial Measurement Units (IMU)\\n. Contextual information\\n– Single low-cost camera if available\\n. Off-line\\n– Capture prototypical movements\\n– Build motion graph\\n. Pre-capture\\n– Define IMU placement\\n– Add virtual IMU data to motion graph\\n. On-line\\n– Search motion graph\\n– Match virtual & real IMU data\\n87, -\\nHow well does it work ?\\n87, nan\\n88, -\\nKinect\\n. And then came the Microsoft Kinect !\\n. Sits on top of a TV or computer screen and \\ncontains an integrated microphone array, \\nvisible spectrum camera and IR-based depth \\ncamera\\n. Intended to be a proprietary interface to the \\nX-Box gaming console but it was quickly \\nhacked, so Microsoft gave up and released an \\nAPI so anyone could use it for anything\\n-\\n90, -\\nMicrosoft Kinect\\n. Kinect is a form of AR\\n. Works by sending out patterns of dots \\nin invisible spectrum light, and then \\npicks them up with a camera\\n. https://www.youtube.com/watch?v=dT\\nKlNGSH9Po&feature=related\\n. Using this, Kinect knows how far you \\nare from the camera (depth map) and \\ncan augment the video camera image \\non the screen\\n. One example app is the virtual dressing \\nroom where you can “try on” clothes …\\n-\\n9, nan\\n92, -\\n. Details at \\nhttps://www.youtube.com/watch?v=\\n93, -\\nSlide\\n94, -\\nTexture-based retrieval results\\n.\\nQuery :\\nTop\\n95, -\\nTexture-based retrieval results\\n.\\nQuery :\\nTop\\n96, -\\nColour-based retrieval results\\nQuery :\\nTop\\n97, -\\nKinect\\n. Best hacks … \\n. #\\n9, (wall) we did this for NMI treasure \\nroom (award-winning at MM2011)\\n. Play the others and be inspired !\\n. All revolve around sensing what you are \\ndoing, now\\n-\\n99, -\\nWeek\\n100, Sensing the Body - Physiology\\n. Our physiology is the set of outward signs that \\nour body gives constantly, to indicate what state \\nour bodies are in.\\n. For example \\n– when we perspire its an indication we’re too hot and \\nwe need to cool down; \\n– when we’ve goosepimples on our arms it means the \\nenvironment is too cold for us and we need to \\npreserve heat hence the goosepimples; \\n– when our breathing is fast it means we’re extending \\nourselves and we need to get more oxygen into our \\nblood streams because we’re exercising, or we’re \\ntense\\n-\\n102, Sensing the Body - Physiology\\n. Mostly, and the main reason we sense our bodies, is for \\nhealth reasons, \\n– we monitor our heart rate when we exercise\\n– we track our movement so as to count our exercise or number of \\nsteps taken in a day\\n– older people at home and lone workers in forests and remote areas \\nwear fall detectors to detect when accidents have occurred\\n– the hard of hearing use hearing aids and some people have their \\nheart rates regularised with implanted pacemakers, etc. \\n. While health and wellness reasons are the main reason, \\nthere are others also, like measuring our reaction to \\nadvertising material (just as an example)\\n-\\n104, . Lets see some examples …. (see slide \\nnote)\\n. We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, .', 'start_char_idx': 12884, 'end_char_idx': 16811, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.7683269285060644}], 'query_bundle': {'query_str': 'Can you list ways that heart rate can be measured?', 'image_path': None, 'custom_embedding_strs': None, 'embedding': [-0.029710588976740837, 0.024593038484454155, 0.009318916127085686, -0.031202662736177444, -0.0030937623232603073, 0.01523485779762268, -0.007545442786067724, -0.001422541681677103, -0.023009346798062325, -0.0006470560911111534, -0.001627047429792583, 0.04025981202721596, -0.021294770762324333, 0.005938845686614513, 0.004103202372789383, -0.004937585908919573, 0.03620241954922676, 0.03256385400891304, 0.01662222482264042, -0.014331759884953499, -0.025509225204586983, 0.012113282456994057, -0.002957970602437854, 0.01655678264796734, -0.034945935010910034, 0.017878707498311996, 0.023912442848086357, 0.00013282646250445396, 0.007067717146128416, 0.0031837448477745056, 0.03664742410182953, -0.013860578648746014, -0.030129417777061462, -0.036359477788209915, -0.025941140949726105, 0.007767945062369108, -0.004387874621897936, 0.010496868751943111, 0.007807210087776184, -0.004083570092916489, 0.013808225281536579, 0.013585723005235195, -0.007172424346208572, -0.0001872249849839136, -0.01265644934028387, 0.01591545157134533, 0.006589991971850395, -0.015692949295043945, -0.023689942434430122, 0.014881471171975136, 0.014043816365301609, -0.013193072751164436, 0.0002362040977459401, -0.0017832898302003741, 0.005582187790423632, -0.012034752406179905, 0.038479793816804886, 0.030181771144270897, 0.0045678396709263325, -0.04002422094345093, -0.005140455439686775, -0.0013988190330564976, -0.010143483057618141, 0.02454068511724472, -0.017917972058057785, -0.005254978779703379, 0.006612896453589201, 0.01475058775395155, 0.013160351663827896, 0.0025227824226021767, 0.0055167460814118385, 0.004397690761834383, -0.011085845530033112, 0.023860089480876923, 0.017250465229153633, -0.018821069970726967, -0.0006957284058444202, -0.027328507974743843, 0.01149812899529934, 0.02073197066783905, 0.004773981403559446, -0.0003589075349736959, -0.020954472944140434, 0.027249976992607117, 0.01587618701159954, -0.010732459835708141, -0.008782293647527695, 0.0036483819130808115, 0.010994226671755314, -0.006668522022664547, 0.018991218879818916, 0.005811234470456839, -0.009750831872224808, 0.011897324584424496, 0.006982643157243729, 0.004489309154450893, 0.0027387405280023813, 0.019475487992167473, -0.0017260281601920724, 0.002846719464287162, -0.010182748548686504, 0.004826334770768881, -0.022001542150974274, -0.014973090030252934, -0.02086285501718521, -0.017603851854801178, 0.0035534913185983896, -0.02952735312283039, 0.0036385655403137207, -0.012898583896458149, -0.026988210156559944, 0.03361092135310173, 0.014436467550694942, -0.01681854948401451, 0.0011599564459174871, -0.0054611205123364925, 0.010365985333919525, -0.0034618726931512356, -0.009881716221570969, 0.0014953457284718752, 0.028297046199440956, 0.019567105919122696, 0.04439573734998703, -0.010195836424827576, 0.015247945673763752, -0.010287455283105373, -0.018245181068778038, -0.00036831479519605637, 0.014371025376021862, -0.006190796848386526, 0.014907647855579853, -0.0050782859325408936, -0.006661978084594011, 0.008821558207273483, -0.022930815815925598, -0.003123211208730936, 0.01422705315053463, 0.021635068580508232, -0.013952197507023811, -0.007427647244185209, -0.0007967542624101043, -0.002825450850650668, 0.00176529330201447, -0.013716607354581356, -0.013101453892886639, 0.032720912247896194, 0.017171936109662056, 0.013795137405395508, 0.0026945671997964382, -0.013664253987371922, -0.011511217802762985, -0.004531846381723881, 0.017878707498311996, 0.009521786123514175, -0.015653684735298157, 0.0066390736028552055, 0.0011836790945380926, 0.0034553285222500563, -0.004754348658025265, -0.003982135094702244, 0.006917200982570648, 0.020286966115236282, 0.02535216324031353, -0.002185757039114833, -0.01692325621843338, 0.007957725785672665, 0.01857239007949829, -0.029605882242321968, 0.0088477348908782, 0.0005754790618084371, -0.00971156731247902, 0.03293032571673393, -0.020286966115236282, 0.022224044427275658, 0.0120543846860528, -0.004659458063542843, -0.0031853809487074614, -0.014357936568558216, -0.017983414232730865, -0.040233634412288666, -0.023100964725017548, -0.004934313707053661, 0.010810989886522293, -0.0023820826318114996, -0.007336028851568699, 0.020378585904836655, 0.007918461225926876, -0.004093386232852936, 0.020849766209721565, -0.029946180060505867, -0.006262782961130142, -0.00992752518504858, -0.011341068893671036, -0.022093160077929497, -0.6659360527992249, -0.030260300263762474, -0.009318916127085686, -0.012806965969502926, 0.04400308430194855, 0.018768716603517532, 0.008729939348995686, 0.0025669557508081198, -0.014973090030252934, 0.03410828113555908, 0.001125599374063313, 0.004819790367037058, -0.0011885871645063162, -0.01908283680677414, -0.0009333640919066966, -0.02730233035981655, -0.001274479553103447, 0.0034160634968429804, -0.003717095823958516, -0.010267823003232479, -0.03408210352063179, -0.004881960339844227, -0.01299674715846777, 0.012159091420471668, -0.00638057803735137, 0.022080073133111, -0.0014094533398747444, 0.002874532248824835, -0.015208681114017963, 0.005742520559579134, -0.0009619948687031865, 0.0023771743290126324, 0.019776519387960434, 0.014907647855579853, 0.03149060904979706, -0.02272140234708786, -0.01850694790482521, 0.034605637192726135, -0.02302243560552597, 0.039055682718753815, -0.02571863867342472, -0.01119055226445198, 0.03141207620501518, -0.022459635511040688, -0.02845410630106926, 0.009790097363293171, 0.006112266797572374, 0.014357936568558216, 0.005434943828731775, -0.014567350968718529, 0.0012262162053957582, -0.022459635511040688, -0.002247926779091358, 0.01975034363567829, -3.47404093190562e-05, -0.006599808111786842, 0.020902119576931, 0.0163473691791296, -0.021517273038625717, 0.02244654670357704, 0.003972318954765797, 0.013258513994514942, 0.000390401401091367, -0.0295011755079031, -0.004767436999827623, 0.01728973165154457, -0.04065246134996414, -0.017237376421689987, -0.008893544785678387, -0.03382033482193947, -0.0010429790709167719, -0.007630517240613699, -0.0021546720527112484, 0.009718111716210842, 0.02094138413667679, 0.011622468940913677, 0.03253767639398575, -0.010424883104860783, -0.005853771232068539, -0.009292739443480968, -0.00045727475662715733, 0.011890780180692673, -0.01880798116326332, 0.01080444548279047, -0.003396430751308799, 0.022263308987021446, -0.012512477114796638, 0.009011339396238327, 0.024252740666270256, 0.0029268856160342693, 0.0005705709336325526, 0.029658235609531403, 0.00804280024021864, -0.02130785956978798, -0.019527841359376907, 0.011956221424043179, 0.0002527690667193383, -0.007264042738825083, 0.001180407009087503, -0.005254978779703379, -0.01159629225730896, 0.004427139647305012, 0.0027485566679388285, 0.00954141840338707, -0.004675818607211113, -0.013677341863512993, -0.024828629568219185, 0.0008016623905859888, 0.024462155997753143, -0.027119092643260956, -0.025469958782196045, -0.02905617095530033, -0.00869721919298172, 0.019344603642821312, 0.003216465702280402, -0.035548001527786255, 0.015850011259317398, 0.016438987106084824, 0.008363465778529644, -0.007826842367649078, 0.024802451953291893, -0.005935573950409889, 0.047955770045518875, -0.01080444548279047, -0.0007202691049315035, 0.007866107858717442, -0.020993737503886223, -0.001366916112601757, 0.021347124129533768, -0.027119092643260956, 0.0024017151445150375, -0.01918754354119301, -0.0003885608457494527, -0.016975609585642815, 0.0073491171933710575, 0.019540930166840553, 0.014449555426836014, 0.015692949295043945, -0.0050619253888726234, -0.023545969277620316, -0.011033492162823677, -0.006285687442868948, 0.00852707028388977, -0.016870902851223946, -0.005048837047070265, -0.021059179678559303, -0.002261015120893717, 0.014672057703137398, 0.010267823003232479, 0.0013096545590087771, -0.006410026922821999, -0.03816567361354828, -0.0044565885327756405, -0.0006965464563108981, 0.010208925232291222, -0.006383850239217281, -0.0063216807320714, -0.03444857895374298, -0.017486056312918663, -0.018297534435987473, 0.023218760266900063, 0.021425655111670494, -0.021621979773044586, 0.004132651258260012, -0.006351129151880741, -0.007002275437116623, 0.0022921001072973013, -0.004041032865643501, -0.008900088258087635, -0.028532637283205986, 0.020614175125956535, 0.0021972092799842358, -0.01353336963802576, 0.024265829473733902, 0.0003014414105564356, 0.03256385400891304, -0.0126433614641428, -0.012702258303761482, -0.005156815983355045, -0.013304323889315128, 0.02026079036295414, 0.02103300392627716, -0.01998593471944332, 0.004636553581804037, 0.022878462448716164, 0.006871392019093037, -0.008906632661819458, 0.011589747853577137, -0.01570603810250759, 0.021412566304206848, 0.007996991276741028, 0.008939353749155998, -0.007283675484359264, 0.013978374190628529, 0.01624266244471073, -0.0020614175591617823, -0.0014487184816971421, -0.0034095190931111574, 0.01773473434150219, 0.033087387681007385, 0.021347124129533768, 0.005886492319405079, 0.009142223745584488, -0.006508189719170332, 0.03463181480765343, -0.0031412076205015182, 0.014030727557837963, -0.020993737503886223, 0.01412234641611576, 0.02019534818828106, -0.012355417013168335, 0.003458600491285324, 0.010078041814267635, -0.021124621853232384, -0.009515241719782352, 0.007336028851568699, 0.0015689678257331252, 0.012564830482006073, 0.014069993048906326, 0.011367245577275753, 0.0411236435174942, 2.998564923473168e-05, 0.027721157297492027, 0.006452564150094986, -0.008579423651099205, 0.011537394486367702, 0.012322695925831795, 0.023284202441573143, 0.006406754720956087, -0.014658968895673752, 0.00829147920012474, -0.0027649172116070986, 0.009129134938120842, 0.01827135868370533, 0.008867367170751095, 0.0266348235309124, 0.0123030636459589, -0.00016299105482175946, 0.014894559979438782, 0.03751125559210777, 0.008199861273169518, -0.007761400658637285, 0.010568855330348015, -0.017944149672985077, 0.032747089862823486, 0.009528330527245998, 0.016098689287900925, -0.0024295279290527105, 0.014541174285113811, 0.003087218152359128, 0.00023538607638329268, -0.019396957010030746, -0.026032758876681328, 0.02238110452890396, 0.0019665269646793604, -0.015797657892107964, 0.021765951067209244, -0.0005284427315928042, -0.015313387848436832, 0.014946913346648216, 0.028977641835808754, 0.020705794915556908, 0.03081001155078411, -0.007388382218778133, -0.008644865825772285, 0.010876432061195374, -0.0032835437450557947, 0.0010527954436838627, -0.012420859187841415, -0.012898583896458149, -0.01145886443555355, 0.0225905179977417, -0.00338334240950644, -0.0075650750659406185, 0.034370046108961105, 0.0032082856632769108, 0.02030005492269993, -0.005130639299750328, -0.004296255763620138, 0.007977358996868134, -0.011399966664612293, -0.021229328587651253, 0.0028974369633942842, 0.014698234386742115, -0.016072513535618782, -0.009253473952412605, -0.002624217187985778, 0.0025325987953692675, -0.020273877307772636, 0.02642541006207466, 0.006174436304718256, -0.017368260771036148, -0.0034913215786218643, -0.02522128075361252, -0.019567105919122696, 0.0037301841657608747, 0.018258269876241684, -0.006586719769984484, 0.01696252077817917, -0.005667262244969606, -0.004014856182038784, 0.0024033510126173496, -0.023807736113667488, -0.04149011895060539, 0.03908186033368111, 0.00749308941885829, -0.013428662903606892, -0.011517761275172234, 0.002957970602437854, -0.008435451425611973, 0.0006356037338264287, -0.010163115337491035, -0.0010307087795808911, -0.023689942434430122, 0.016713842749595642, 0.023454351350665092, -0.02083667740225792, 0.009842450730502605, 0.010824078693985939, -0.021334035322070122, -0.00814096350222826, -0.009240386076271534, -0.009888259693980217, -0.012983658351004124, 0.04494544863700867, -0.009142223745584488, 0.00023865816183388233, 0.015784569084644318, -0.02197536639869213, -0.03615006431937218, -0.009672301821410656, -0.005915941204875708, 0.025024954229593277, 0.01878180354833603, -0.020247701555490494, 0.00849434919655323, 0.003057769499719143, -0.0030937623232603073, -0.006377306301146746, -0.006331496872007847, 0.01065392978489399, -0.03745890036225319, 0.015758391469717026, 0.015444271266460419, -0.015051620081067085, -0.010182748548686504, 0.02302243560552597, 0.04858401417732239, 0.024802451953291893, 0.006495101377367973, 0.035888299345970154, 0.019671812653541565, 0.01901739463210106, -0.005814506206661463, -0.012263798154890537, 0.03476269915699959, 0.0014519905671477318, 0.006148259621113539, -0.027904395014047623, 0.003504409920424223, 0.0011730447877198458, 0.01668766513466835, 0.015365741215646267, -0.013598811812698841, 0.006436203606426716, 0.03913421183824539, -0.0057392483577132225, 0.013356677256524563, 0.01763002760708332, -0.004420595243573189, 0.021098444238305092, 0.0034160634968429804, 0.00433224905282259, -0.004397690761834383, 0.0067274197936058044, -0.01083716657012701, -0.002517874352633953, -0.02558775432407856, 0.00852707028388977, -0.004482765216380358, -0.008062433451414108, -0.0266348235309124, -0.009305828250944614, 0.0035076818894594908, -0.009848995134234428, 0.028323223814368248, 0.027956748381257057, 0.007394926622509956, 0.013068732805550098, -0.0037072794511914253, -0.0008356103207916021, -0.021425655111670494, -0.024894071742892265, -0.009168400429189205, -0.01591545157134533, -0.008134419098496437, -0.021661244332790375, 0.011753352358937263, 0.026713354513049126, 0.019331516698002815, 0.00037404094473458827, -0.007643605582416058, 0.00579814612865448, -0.0039068772457540035, -0.008592511527240276, 0.00793809350579977, -0.016229573637247086, -0.008468172512948513, -0.008592511527240276, -0.00644602021202445, -0.008520525880157948, 0.0129771139472723, 0.008906632661819458, 0.024265829473733902, 0.004041032865643501, -0.007898828946053982, 0.049814317375421524, -0.0333753302693367, 0.0021906651090830564, 0.024854805320501328, -0.0006180162308737636, 0.007931549102067947, 0.006053369026631117, -0.013219249434769154, 0.007519266102463007, -0.03628094866871834, 0.0019665269646793604, -0.005912669003009796, 0.0026503941044211388, 0.01621648482978344, 0.0016131410375237465, -0.00440750690177083, 0.010968049988150597, -0.009783552959561348, 0.01786561869084835, 0.011170919984579086, 0.012244165875017643, -0.0069041126407682896, 0.03599300608038902, 0.023415084928274155, 0.012329240329563618, 0.005218985956162214, 0.005768697243183851, -0.01063429657369852, -0.003664742223918438, 0.005065197590738535, 0.025574665516614914, -0.00933854840695858, -0.026438498869538307, 0.01598089374601841, -0.022642871364951134, -0.00033477586111985147, -0.02704056352376938, 0.010673562064766884, -0.0029808753170073032, 0.013363220728933811, 0.010025687515735626, -0.03688301518559456, -0.028742050752043724, 0.0011738627217710018, -0.015797657892107964, 0.01978960819542408, -0.013219249434769154, 0.025195103138685226, -0.018349887803196907, 0.0008662861655466259, -0.008540158160030842, 0.006112266797572374, 0.0188734233379364, -0.033689454197883606, 0.00038426622631959617, 0.011275626718997955, -0.03819185122847557, 0.0005775241297669709, 0.0003458191640675068, 0.008978618308901787, -0.030286477878689766, -0.009057149291038513, -0.01739443838596344, -0.009116046130657196, -0.004286439623683691, 0.0019092652946710587, 0.02387317828834057, 0.014240141957998276, -0.004508941899985075, 0.004198093432933092, 0.011098934337496758, -0.00960686057806015, -0.008383098058402538, -0.005699983332306147, -0.017813265323638916, -0.018467683345079422, 0.00024172574921976775, 0.007781033404171467, 0.012525565922260284, -0.01446264423429966, 0.0007538080681115389, 0.009920980781316757, -0.003821802791208029, 0.01611177809536457, 0.001451172516681254, -0.002386990701779723, -0.019632548093795776, -0.048531658947467804, 0.010778268799185753, 0.005297516006976366, 0.010326720774173737, 0.027668803930282593, -0.033087387681007385, -0.015287211164832115, 0.04172571003437042, -0.016268838196992874, 0.011321435682475567, -0.01992049254477024, -0.014868383295834064, -0.02393862046301365, 0.027249976992607117, -0.00937126949429512, 0.018454594537615776, -0.007925005629658699, -0.025770992040634155, -0.007034996524453163, 0.00466927420347929, 0.019122101366519928, -0.005968294572085142, -0.01679237373173237, -0.008265302516520023, 0.010595032013952732, -0.0046725464053452015, -0.0010266186436638236, -0.02902999520301819, 0.010379074141383171, -0.01446264423429966, 0.010660473257303238, -0.0053891343995928764, -0.004659458063542843, -0.023140229284763336, -0.018834158778190613, 0.0012106738286092877, 0.0205618217587471, -0.00522552989423275, 0.01651751808822155, -0.021085357293486595, -0.004266807343810797, -0.0005255796713754535, -0.02079741284251213, 0.019540930166840553, 0.006105722393840551, 0.04368896409869194, -0.022197868674993515, -0.0037825375329703093, -0.013507192954421043, -0.028611166402697563, -0.00638057803735137, 0.012748068198561668, 0.02231566235423088, -0.0022806476335972548, -0.009567595086991787, -0.01861165650188923, 0.024763187393546104, 0.02727615274488926, -0.020404761657118797, -0.019999021664261818, 0.0063380408100783825, 0.009057149291038513, -0.020116817206144333, -0.01122327335178852, -3.7654612242477015e-05, -0.02167433314025402, 0.026098201051354408, 0.019122101366519928, -0.011301803402602673, -0.012551742605865002, -0.013186528347432613, -0.015496624633669853, 0.04426485300064087, -0.02430509403347969, 0.024737011641263962, 0.009489065036177635, -0.018729450181126595, -0.007820297963917255, 0.010228557512164116, -0.01752532087266445, -0.0004302800225559622, 0.008671042509377003, 0.010274366475641727, 0.00338334240950644, -0.008998251520097256, 0.0055658272467553616, 0.004109746776521206, 0.002519510453566909, 0.010339808650314808, -0.00041616911767050624, 0.031071780249476433, 0.0032753634732216597, -0.009390901774168015, 0.027249976992607117, -0.01897813007235527, 0.014881471171975136, 0.016936345025897026, -0.019069747999310493, 0.01353336963802576, 0.0033866146113723516, 0.0033342610113322735, 0.036254771053791046, 0.01679237373173237, -0.03138589859008789, 0.0005186264752410352, -0.0026373055297881365, -0.007807210087776184, -0.024789365008473396, -0.011026947759091854, 0.013585723005235195, -0.029344115406274796, -0.0246061272919178, -0.02751174382865429, 0.0035829399712383747, 0.019436223432421684, 0.031464431434869766, 0.015077796764671803, 0.0024720649234950542, 0.021765951067209244, -0.005775241181254387, 0.03837508708238602, 0.01918754354119301, 0.001180407009087503, -0.028846757486462593, -0.003468416864052415, -0.008710307069122791, -0.02184448204934597, 0.007080805953592062, -0.0005120823043398559, -0.027825865894556046, -0.029684413224458694, 0.021595802158117294, 0.02612437680363655, -0.002261015120893717, 0.006858303677290678, -0.017001787200570107, 0.01276115607470274, -0.0022937359753996134, 0.008991707116365433, -0.0041228351183235645, -0.0018749083392322063, -0.025731725618243217, -0.007336028851568699, 0.025064220651984215, -0.032040320336818695, -0.012538653798401356, -0.0397886298596859, 0.003151023993268609, 0.017276642844080925, -0.0014159975107759237, -0.009260018356144428, -0.011164375580847263, 0.004296255763620138, -0.021412566304206848, 0.00380871444940567, -0.011655189096927643, 0.004862327594310045, -0.03154296055436134, 0.021019915118813515, 0.002889256691560149, -0.012617184780538082, -0.021085357293486595, 0.008736483752727509, 0.011831882409751415, -0.00403776066377759, -0.022747579962015152, -0.004636553581804037, -0.0017734735738486052, 0.007872652262449265, -0.01591545157134533, -0.005346597172319889, 0.010195836424827576, 0.029239408671855927, 0.03832273557782173, -0.03159531578421593, -0.034605637192726135, 0.007597796153277159, -0.03416063264012337, -0.013729695230722427, 0.019972845911979675, 0.002324820961803198, -0.01925298571586609, 0.02905617095530033, 0.002807454438880086, 0.010143483057618141, 0.0012147639645263553, 0.018729450181126595, -0.02498568966984749, -0.006544182542711496, 0.01995975710451603, -0.002035240875557065, -0.009286195039749146, 0.0017718374729156494, -0.013055644929409027, -0.013742784038186073, 0.023218760266900063, -0.015208681114017963, -0.009390901774168015, 0.015418094582855701, -0.007499633356928825, -0.00265857414342463, 0.0024687929544597864, -0.004603832494467497, 0.01475058775395155, 0.018219005316495895, -0.0025996766053140163, -0.027668803930282593, 0.0002938747056759894, -0.002426255727186799, -0.0008401094819419086, -0.03853214904665947, 0.009384358301758766, 0.018428418785333633, 0.0006090180249884725, 0.005009572021663189, -0.04143776372075081, -0.03609771281480789, 0.007427647244185209, -0.02235492877662182, -0.009102958254516125, 0.00493104150518775, -0.03392504155635834, 0.0259542278945446, -0.017315907403826714, 0.0015076161362230778, 0.0034356960095465183, 0.0006687336717732251, -0.0031755645759403706, 0.026791883632540703, 0.02188374660909176, -0.012113282456994057, -0.022263308987021446, -0.020718881860375404, 0.003589484142139554, -0.017538409680128098, -0.004806702025234699, -0.006586719769984484, -0.02154344879090786, -0.007807210087776184, 0.02066652849316597, 0.0035174982622265816, -0.0022070256527513266, -0.027956748381257057, -0.01240777038037777, -0.014789853245019913, 0.0016818549484014511, -0.024684656411409378, 0.001413543475791812, 0.002205389551818371, 0.002545687137171626, 0.009646125137805939, -0.036123890429735184, 0.010470692068338394, -0.017342085018754005, -0.00017004649271257222, 0.004446772392839193, 0.010496868751943111, 0.22742344439029694, -0.000854833866469562, -0.0237684715539217, 0.0230878759175539, -0.013886755332350731, 0.012106738053262234, 0.015889275819063187, 0.006246422417461872, 0.023506704717874527, 0.0038348911330103874, 0.0052451626397669315, -0.010169659741222858, -0.028401752933859825, 0.0015280666993930936, -0.0037825375329703093, -0.029684413224458694, -0.01810120977461338, -0.010437971912324429, 0.0212424173951149, -0.022813020274043083, -0.006805949844419956, -0.0053007882088422775, -0.012990202754735947, -0.020182259380817413, 0.03023412451148033, 0.025038043037056923, -0.0011934953508898616, 0.003916693385690451, 0.021111533045768738, -0.0047347163781523705, -0.018297534435987473, 0.005830866750329733, 0.004378058481961489, 0.01773473434150219, -0.011570114642381668, -0.012905128300189972, 0.01237504929304123, 0.01891268789768219, 0.01464588101953268, 0.015208681114017963, 0.020234612748026848, -0.022433457896113396, -0.0176954697817564, -0.022525077685713768, 0.010143483057618141, 0.01790488325059414, 0.009260018356144428, -0.02147800847887993, 0.014148523099720478, 0.001876544440165162, -0.01807503215968609, -0.00019090608111582696, 0.01867709681391716, 0.009580683894455433, -0.006315136328339577, -0.02642541006207466, 0.01632119156420231, 0.028532637283205986, 0.016949433833360672, 0.019815785810351372, 0.004466404672712088, 0.002684751059859991, -0.008965530432760715, 0.01814047433435917, -0.018258269876241684, 0.014973090030252934, -0.015601331368088722, -0.00010532043961575255, 0.00800353568047285, -0.002362449886277318, -0.0018847245955839753, -0.0033637098968029022, 0.007165879942476749, 0.01321270503103733, -0.021831393241882324, 0.0016205032588914037, 0.013062188401818275, 0.015300299040973186, 0.007813754491508007, 0.01756458729505539, 0.004351881332695484, -0.01594162918627262, -0.014318672008812428, -0.005474208854138851, -0.008821558207273483, -0.015548978000879288, -0.013481016270816326, 0.012525565922260284, -0.001263027312234044, 0.019331516698002815, 0.0031019425950944424, -0.0055658272467553616, -0.03348004072904587, -0.0025800440926104784, 0.003605844685807824, -0.017171936109662056, 0.005876676179468632, -0.004558023065328598, 0.005382590461522341, -0.006668522022664547, -0.003700735280290246, 0.026202907785773277, 0.004312616307288408, -0.004688906949013472, 0.0031641123350709677, 0.0013145627453923225, -0.023074788972735405, 0.011236362159252167, 0.02194918878376484, -0.021962277591228485, 0.00293670198880136, -0.04379367083311081, 0.008677585981786251, -0.01311454176902771, 0.017250465229153633, 0.01159629225730896, 0.0088477348908782, -0.002136675640940666, -0.010987683199346066, -0.00461037689819932, 0.021294770762324333, 0.0016098689520731568, -0.011537394486367702, 0.009214209392666817, 0.012741523794829845, -0.013546458445489407, 0.02073197066783905, -0.006315136328339577, 0.01611177809536457, -0.008343832567334175, 0.02221095561981201, -0.014266318641602993, 0.008219493553042412, -0.015405005775392056, -0.0026389416307210922, -7.459345943061635e-05, -0.006112266797572374, -0.008978618308901787, 0.009325460530817509, -0.006884480360895395, 0.01752532087266445, -0.008121331222355366, -0.014881471171975136, 0.008441995829343796, 0.030522068962454796, -0.016124866902828217, 0.021582715213298798, 0.02255125343799591, 0.00217430479824543, -0.018716363236308098, -0.012276886962354183, 0.011465407907962799, 0.003811986418440938, -0.01261064037680626, 0.015182503499090672, 0.015444271266460419, -0.009332004934549332, -0.005382590461522341, -0.012885496020317078, -0.014174699783325195, -0.019815785810351372, -0.00604355288669467, 0.008749572560191154, -0.0012523930054157972, -0.018284447491168976, 0.014266318641602993, -0.16596047580242157, 0.013003291562199593, 0.03633330389857292, -0.024462155997753143, -0.013860578648746014, 0.020208436995744705, 0.03523388132452965, -0.008049344643950462, -0.021386388689279556, 0.014907647855579853, 0.020679617300629616, -0.015313387848436832, -0.00797081459313631, -0.02976294234395027, 0.005346597172319889, -0.020745059475302696, -0.011314892210066319, 0.0599970668554306, 0.006832126993685961, 0.01244049146771431, 0.011622468940913677, 0.002853263635188341, 0.027249976992607117, -0.008258759044110775, 0.0050226603634655476, -0.02800910174846649, -0.027852041646838188, 0.047851063311100006, 0.013546458445489407, -0.018009589985013008, -0.011903868056833744, 0.014384113252162933, -0.008566334843635559, -0.0032671832013875246, -0.0212424173951149, -0.020653441548347473, 0.011635556817054749, -0.03329680114984512, -0.007414558902382851, -0.001059339614585042, 0.027825865894556046, 0.021386388689279556, -0.022577431052923203, -0.001088788383640349, -0.00693683372810483, -0.004541662987321615, 0.006982643157243729, -0.008422363549470901, 0.017944149672985077, -0.0367521308362484, -0.00723132211714983, -0.01726355403661728, -0.001989431446418166, -0.014449555426836014, 0.002545687137171626, -0.010019144043326378, -0.006714331451803446, 0.012178723700344563, 0.0001692284713499248, -0.031909435987472534, 0.003697463311254978, -0.02126859314739704, 0.010320176370441914, -0.004191549029201269, -0.00749308941885829, -0.00960686057806015, -0.005902852863073349, 0.0029710589442402124, -0.031019426882267, 0.005592003930360079, -0.004531846381723881, -0.030495891347527504, 0.00100535003002733, -0.03416063264012337, 0.01698869839310646, 0.0016834910493344069, -0.012872407212853432, -0.007898828946053982, -0.0022004814818501472, 0.023951709270477295, -0.0007104528485797346, 0.036019179970026016, -0.018480772152543068, 0.005971566773951054, -0.0088477348908782, 0.0019648908637464046, -0.0026389416307210922, 0.010987683199346066, -0.013107998296618462, -0.004630009178072214, 0.031909435987472534, -0.03253767639398575, -0.01510397344827652, -0.025129660964012146, -0.005755608901381493, 0.007447279989719391, -0.007643605582416058, -0.03960539400577545, 0.0306791290640831, -0.024501420557498932, 0.002285555936396122, -0.0007214961224235594, -0.012198356911540031, 0.011288715526461601, 0.0367521308362484, -0.012381593696773052, 0.0295011755079031, 0.011288715526461601, 0.04154247045516968, 0.0056836227886378765, -0.0254568699747324, -0.00915531162172556, -0.0065605430863797665, 0.03416063264012337, -0.002526054624468088, 0.03622859716415405, -0.006845215335488319, -0.01975034363567829, 0.01552280131727457, -0.012630272656679153, 0.05141109973192215, -0.005951934028416872, -0.0303388312458992, 0.037432726472616196, -0.0110400365665555, -0.018650921061635017, -0.11905176937580109, -0.009521786123514175, 0.03115030936896801, 0.00933854840695858, 0.02467156946659088, 0.02094138413667679, 0.0003719958767760545, 0.00021452648798003793, 0.005690166726708412, 0.028427930548787117, -0.01208710577338934, -0.020889030769467354, -0.010791357606649399, -0.00305122509598732, 0.011471952311694622, -0.018323712050914764, 0.0006131081026978791, -0.02225022204220295, -0.007702502887696028, 0.034841228276491165, -0.004381330218166113, -0.026791883632540703, -0.01709340512752533, 0.004237358458340168, 0.005418583285063505, -0.008991707116365433, -0.03837508708238602, 0.009227297268807888, -0.007807210087776184, 0.007990446873009205, 0.0006572813726961613, -0.014868383295834064, -0.0017554770456627011, -0.004626736976206303, -0.01961945928633213, 0.0004961308441124856, -0.0053891343995928764, -0.009672301821410656, 0.010889519937336445, -0.00611881073564291, 0.011249450035393238, 0.017839442938566208, 0.03884626924991608, -0.019907403737306595, 0.016870902851223946, -0.007695958949625492, -0.05039020627737045, 0.01353336963802576, -0.01083716657012701, -0.022577431052923203, -0.02015608362853527, -0.016255749389529228, -0.013651165179908276, -0.0034062471240758896, 0.001979615306481719, -0.03217120096087456, 0.00842890702188015, 0.0055723716504871845, -0.010490325279533863, -0.010045320726931095, 0.010195836424827576, 0.004705267492681742, -0.015143238939344883, 0.03536476194858551, 0.027328507974743843, -0.017041051760315895, -0.0313597247004509, 0.014920736663043499, 0.0036320213694125414, -0.0051175509579479694, -0.01090260874480009, 0.01352028176188469, -0.021582715213298798, 0.018428418785333633, -0.02683115005493164, 0.0060173762030899525, -0.02015608362853527, 0.00494740204885602, 0.01220490038394928, 0.004875415936112404, -0.013795137405395508, -0.008441995829343796, -0.0062333340756595135, -0.005768697243183851, -0.005575643852353096, 0.024187298491597176, -0.014920736663043499, -0.002740376628935337, -0.001933805993758142, -0.01786561869084835, 0.0007697594701312482, 0.04274660348892212, 0.008356921374797821, -0.006311864126473665, -0.02751174382865429, -0.006877935957163572, -0.00849434919655323, 0.006720875855535269, -0.007388382218778133, -0.003131391480565071, 0.00616789236664772, 0.004381330218166113, -0.0364118330180645, 0.013795137405395508, 0.012872407212853432, -0.007853019051253796, 0.0036189330276101828, 0.0009227297850884497, 0.03698772192001343, 0.005359685514122248, 0.03863685578107834, -0.014161611907184124, -0.03243296965956688, 0.001636863686144352, -0.01891268789768219, -0.012669538147747517, -0.007781033404171467, -0.00021043638116680086, 0.023349644616246223, 0.0025702277198433876, 0.015470447950065136, -0.014017639681696892, -0.008363465778529644, 0.011013859882950783, -0.004953946452587843, 0.01901739463210106, 0.002185757039114833, -0.001609050901606679, -0.00018262359662912786, 0.017616940662264824, -0.027249976992607117, -0.02454068511724472, 0.017917972058057785, -0.022368015721440315, -0.004158827941864729, 0.008121331222355366, -0.022106248885393143, -0.01083716657012701, -0.015850011259317398, 0.03031265363097191, 0.0041162907145917416, -0.005336781032383442, 0.00888045597821474, 0.007578163407742977, -0.026333792135119438, -0.021464919671416283, 0.01006495300680399, 0.018991218879818916, -0.019292250275611877, 0.0038054422475397587, 0.0009636309114284813, -0.01321270503103733, -0.0026634824462234974, 0.011727175675332546, -0.016465162858366966, -0.0064492919482290745, -0.031071780249476433, -0.014789853245019913, -0.008500893600285053, -0.024357447400689125, 0.019292250275611877, -0.027459390461444855, 0.044186320155858994, -0.005922485608607531, 0.0055102016776800156, -0.0062824152410030365, 0.024030238389968872, 0.004574383608996868, 0.010477236472070217, 0.006982643157243729, 0.010019144043326378, -0.02753792144358158, -0.01688399165868759, -0.01662222482264042, 0.002733832225203514, -0.007480001077055931, 0.014004550874233246, 0.0027485566679388285, -0.007427647244185209, 0.023375820368528366, 0.0046790908090770245, 0.00908332597464323, 0.0387677401304245, -0.006262782961130142, -0.027668803930282593, 0.0019697989337146282, 0.04065246134996414, 0.020404761657118797, -0.01285931933671236, 0.013441751711070538, -0.014960002154111862, 0.008553246967494488, -0.004191549029201269, -0.012924760580062866, -0.004181732889264822, -0.005938845686614513, -0.003753088880330324, 0.014920736663043499, -0.031673844903707504, -0.007944637909531593, 0.014855294488370419, 0.027433214709162712, -0.010365985333919525, 0.021019915118813515, 0.002529326593503356, -0.015300299040973186, -0.014266318641602993, 0.0249464251101017, -0.0018290990265086293, -0.03128119185566902, -0.008841190487146378, 0.022904640063643456, -0.0003519543388392776, 0.0323544405400753, 0.014672057703137398, 0.005951934028416872, -0.002454068511724472, -0.010222013108432293, -0.027328507974743843, -0.0038708841893821955, -0.026883503422141075, 0.009705022908747196, 0.0010986046399921179, -0.01621648482978344, -0.012597551569342613, 0.008572879247367382, 0.01914827898144722, -0.0008466536528430879, 0.015627508983016014, 0.014685146510601044, 0.00024029420455917716, 0.012682626023888588, 0.011373789981007576, 0.0036287494003772736, -0.001393910963088274, -0.01925298571586609, -0.008867367170751095, -0.024501420557498932, -0.007041540462523699, -0.012937849387526512, -0.02255125343799591, 0.06994422525167465, 0.015247945673763752, -0.0034356960095465183, 0.011923501268029213, 0.0024295279290527105, 0.02902999520301819, 0.014357936568558216, -0.0025244185235351324, -0.05376700684428215, -0.01763002760708332, 0.037406548857688904, -0.0044565885327756405, 0.00076280627399683, -0.04861018806695938, 0.00827839132398367, 0.03081001155078411, 0.013454839587211609, 0.022904640063643456, 0.005634541157633066, -0.020875943824648857, 0.015692949295043945, -0.0055658272467553616, 0.015954717993736267, -0.013651165179908276, 0.004463132470846176, -0.008513981476426125, 0.03206649422645569, -0.01897813007235527, -0.020103730261325836, -0.010529589839279652, 0.024161122739315033, 0.0008654681732878089, -0.026883503422141075, -0.0014356301398947835, 0.008605600334703922, 0.008376553654670715, -0.0017718374729156494, -0.010509957559406757, -0.0014168155612424016, 0.03046971559524536, -0.017080316320061684, -0.005058653187006712, -0.02197536639869213, -0.004387874621897936, -0.036595068871974945, 0.0015018898993730545, -0.012355417013168335, -0.0035763958003371954, -0.03452710807323456]}}, rets=[{'node': {'id_': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'b5542e96-351d-4501-a621-d2aaee1386eb', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '47845a6529a286c4db5938e0f0349691964e347496cd3c65c4a3feff45ba6666'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'bdde83a5-6a37-4e11-9adf-5717c3b28b88', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '505dfda29fbdfe6cf75948c2f2605eed66b308f218805e30fc5050105bf992da'}}, 'text': \"We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, . So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n. Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n-\\n113, Measuring Heart Rate\\n. Heart rate can be measured by\\n2, . listening to the chest\\n4, . Sensing minute changes in blood flow via \\nphotoplethysmography\\n. (\\n2, ) are ambulatory, for \\nemergency response while (\\n4, ) \\ncan be embedded in wearable sensors\\n-\\n115, . Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n. Used on watches like Apple \\nWatch where you see\\n2, LEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n-\\n117, Measuring Blood Pressure\\n. Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n. BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n. BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n. Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n-\\n119, Measuring Respiration\\n. Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n. Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n. Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n-\\n121, -\\n123, Polygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n-\\n125, -\\n127, -\\n5, stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n. Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n. The first sleep cycle is usually shortest at\\n100, minutes. Later cycles are\\n110, minutes. \\n. If you sleep for\\n5, full \\ncycles\\nSleep Explained\\n-\\n130, Why is sleep important ?\\n. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n.\", 'start_char_idx': 16001, 'end_char_idx': 19861, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8357276384880378}], error=None, perf=Perf(start_time=datetime.datetime(2024, 3, 4, 16, 59, 35, 609152), end_time=datetime.datetime(2024, 3, 4, 16, 59, 35, 704597)), pid=555, tid=555), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='retrieve'))], args={'query_bundle': {'query_str': 'Can you list ways that heart rate can be measured?', 'image_path': None, 'custom_embedding_strs': None, 'embedding': [-0.029710588976740837, 0.024593038484454155, 0.009318916127085686, -0.031202662736177444, -0.0030937623232603073, 0.01523485779762268, -0.007545442786067724, -0.001422541681677103, -0.023009346798062325, -0.0006470560911111534, -0.001627047429792583, 0.04025981202721596, -0.021294770762324333, 0.005938845686614513, 0.004103202372789383, -0.004937585908919573, 0.03620241954922676, 0.03256385400891304, 0.01662222482264042, -0.014331759884953499, -0.025509225204586983, 0.012113282456994057, -0.002957970602437854, 0.01655678264796734, -0.034945935010910034, 0.017878707498311996, 0.023912442848086357, 0.00013282646250445396, 0.007067717146128416, 0.0031837448477745056, 0.03664742410182953, -0.013860578648746014, -0.030129417777061462, -0.036359477788209915, -0.025941140949726105, 0.007767945062369108, -0.004387874621897936, 0.010496868751943111, 0.007807210087776184, -0.004083570092916489, 0.013808225281536579, 0.013585723005235195, -0.007172424346208572, -0.0001872249849839136, -0.01265644934028387, 0.01591545157134533, 0.006589991971850395, -0.015692949295043945, -0.023689942434430122, 0.014881471171975136, 0.014043816365301609, -0.013193072751164436, 0.0002362040977459401, -0.0017832898302003741, 0.005582187790423632, -0.012034752406179905, 0.038479793816804886, 0.030181771144270897, 0.0045678396709263325, -0.04002422094345093, -0.005140455439686775, -0.0013988190330564976, -0.010143483057618141, 0.02454068511724472, -0.017917972058057785, -0.005254978779703379, 0.006612896453589201, 0.01475058775395155, 0.013160351663827896, 0.0025227824226021767, 0.0055167460814118385, 0.004397690761834383, -0.011085845530033112, 0.023860089480876923, 0.017250465229153633, -0.018821069970726967, -0.0006957284058444202, -0.027328507974743843, 0.01149812899529934, 0.02073197066783905, 0.004773981403559446, -0.0003589075349736959, -0.020954472944140434, 0.027249976992607117, 0.01587618701159954, -0.010732459835708141, -0.008782293647527695, 0.0036483819130808115, 0.010994226671755314, -0.006668522022664547, 0.018991218879818916, 0.005811234470456839, -0.009750831872224808, 0.011897324584424496, 0.006982643157243729, 0.004489309154450893, 0.0027387405280023813, 0.019475487992167473, -0.0017260281601920724, 0.002846719464287162, -0.010182748548686504, 0.004826334770768881, -0.022001542150974274, -0.014973090030252934, -0.02086285501718521, -0.017603851854801178, 0.0035534913185983896, -0.02952735312283039, 0.0036385655403137207, -0.012898583896458149, -0.026988210156559944, 0.03361092135310173, 0.014436467550694942, -0.01681854948401451, 0.0011599564459174871, -0.0054611205123364925, 0.010365985333919525, -0.0034618726931512356, -0.009881716221570969, 0.0014953457284718752, 0.028297046199440956, 0.019567105919122696, 0.04439573734998703, -0.010195836424827576, 0.015247945673763752, -0.010287455283105373, -0.018245181068778038, -0.00036831479519605637, 0.014371025376021862, -0.006190796848386526, 0.014907647855579853, -0.0050782859325408936, -0.006661978084594011, 0.008821558207273483, -0.022930815815925598, -0.003123211208730936, 0.01422705315053463, 0.021635068580508232, -0.013952197507023811, -0.007427647244185209, -0.0007967542624101043, -0.002825450850650668, 0.00176529330201447, -0.013716607354581356, -0.013101453892886639, 0.032720912247896194, 0.017171936109662056, 0.013795137405395508, 0.0026945671997964382, -0.013664253987371922, -0.011511217802762985, -0.004531846381723881, 0.017878707498311996, 0.009521786123514175, -0.015653684735298157, 0.0066390736028552055, 0.0011836790945380926, 0.0034553285222500563, -0.004754348658025265, -0.003982135094702244, 0.006917200982570648, 0.020286966115236282, 0.02535216324031353, -0.002185757039114833, -0.01692325621843338, 0.007957725785672665, 0.01857239007949829, -0.029605882242321968, 0.0088477348908782, 0.0005754790618084371, -0.00971156731247902, 0.03293032571673393, -0.020286966115236282, 0.022224044427275658, 0.0120543846860528, -0.004659458063542843, -0.0031853809487074614, -0.014357936568558216, -0.017983414232730865, -0.040233634412288666, -0.023100964725017548, -0.004934313707053661, 0.010810989886522293, -0.0023820826318114996, -0.007336028851568699, 0.020378585904836655, 0.007918461225926876, -0.004093386232852936, 0.020849766209721565, -0.029946180060505867, -0.006262782961130142, -0.00992752518504858, -0.011341068893671036, -0.022093160077929497, -0.6659360527992249, -0.030260300263762474, -0.009318916127085686, -0.012806965969502926, 0.04400308430194855, 0.018768716603517532, 0.008729939348995686, 0.0025669557508081198, -0.014973090030252934, 0.03410828113555908, 0.001125599374063313, 0.004819790367037058, -0.0011885871645063162, -0.01908283680677414, -0.0009333640919066966, -0.02730233035981655, -0.001274479553103447, 0.0034160634968429804, -0.003717095823958516, -0.010267823003232479, -0.03408210352063179, -0.004881960339844227, -0.01299674715846777, 0.012159091420471668, -0.00638057803735137, 0.022080073133111, -0.0014094533398747444, 0.002874532248824835, -0.015208681114017963, 0.005742520559579134, -0.0009619948687031865, 0.0023771743290126324, 0.019776519387960434, 0.014907647855579853, 0.03149060904979706, -0.02272140234708786, -0.01850694790482521, 0.034605637192726135, -0.02302243560552597, 0.039055682718753815, -0.02571863867342472, -0.01119055226445198, 0.03141207620501518, -0.022459635511040688, -0.02845410630106926, 0.009790097363293171, 0.006112266797572374, 0.014357936568558216, 0.005434943828731775, -0.014567350968718529, 0.0012262162053957582, -0.022459635511040688, -0.002247926779091358, 0.01975034363567829, -3.47404093190562e-05, -0.006599808111786842, 0.020902119576931, 0.0163473691791296, -0.021517273038625717, 0.02244654670357704, 0.003972318954765797, 0.013258513994514942, 0.000390401401091367, -0.0295011755079031, -0.004767436999827623, 0.01728973165154457, -0.04065246134996414, -0.017237376421689987, -0.008893544785678387, -0.03382033482193947, -0.0010429790709167719, -0.007630517240613699, -0.0021546720527112484, 0.009718111716210842, 0.02094138413667679, 0.011622468940913677, 0.03253767639398575, -0.010424883104860783, -0.005853771232068539, -0.009292739443480968, -0.00045727475662715733, 0.011890780180692673, -0.01880798116326332, 0.01080444548279047, -0.003396430751308799, 0.022263308987021446, -0.012512477114796638, 0.009011339396238327, 0.024252740666270256, 0.0029268856160342693, 0.0005705709336325526, 0.029658235609531403, 0.00804280024021864, -0.02130785956978798, -0.019527841359376907, 0.011956221424043179, 0.0002527690667193383, -0.007264042738825083, 0.001180407009087503, -0.005254978779703379, -0.01159629225730896, 0.004427139647305012, 0.0027485566679388285, 0.00954141840338707, -0.004675818607211113, -0.013677341863512993, -0.024828629568219185, 0.0008016623905859888, 0.024462155997753143, -0.027119092643260956, -0.025469958782196045, -0.02905617095530033, -0.00869721919298172, 0.019344603642821312, 0.003216465702280402, -0.035548001527786255, 0.015850011259317398, 0.016438987106084824, 0.008363465778529644, -0.007826842367649078, 0.024802451953291893, -0.005935573950409889, 0.047955770045518875, -0.01080444548279047, -0.0007202691049315035, 0.007866107858717442, -0.020993737503886223, -0.001366916112601757, 0.021347124129533768, -0.027119092643260956, 0.0024017151445150375, -0.01918754354119301, -0.0003885608457494527, -0.016975609585642815, 0.0073491171933710575, 0.019540930166840553, 0.014449555426836014, 0.015692949295043945, -0.0050619253888726234, -0.023545969277620316, -0.011033492162823677, -0.006285687442868948, 0.00852707028388977, -0.016870902851223946, -0.005048837047070265, -0.021059179678559303, -0.002261015120893717, 0.014672057703137398, 0.010267823003232479, 0.0013096545590087771, -0.006410026922821999, -0.03816567361354828, -0.0044565885327756405, -0.0006965464563108981, 0.010208925232291222, -0.006383850239217281, -0.0063216807320714, -0.03444857895374298, -0.017486056312918663, -0.018297534435987473, 0.023218760266900063, 0.021425655111670494, -0.021621979773044586, 0.004132651258260012, -0.006351129151880741, -0.007002275437116623, 0.0022921001072973013, -0.004041032865643501, -0.008900088258087635, -0.028532637283205986, 0.020614175125956535, 0.0021972092799842358, -0.01353336963802576, 0.024265829473733902, 0.0003014414105564356, 0.03256385400891304, -0.0126433614641428, -0.012702258303761482, -0.005156815983355045, -0.013304323889315128, 0.02026079036295414, 0.02103300392627716, -0.01998593471944332, 0.004636553581804037, 0.022878462448716164, 0.006871392019093037, -0.008906632661819458, 0.011589747853577137, -0.01570603810250759, 0.021412566304206848, 0.007996991276741028, 0.008939353749155998, -0.007283675484359264, 0.013978374190628529, 0.01624266244471073, -0.0020614175591617823, -0.0014487184816971421, -0.0034095190931111574, 0.01773473434150219, 0.033087387681007385, 0.021347124129533768, 0.005886492319405079, 0.009142223745584488, -0.006508189719170332, 0.03463181480765343, -0.0031412076205015182, 0.014030727557837963, -0.020993737503886223, 0.01412234641611576, 0.02019534818828106, -0.012355417013168335, 0.003458600491285324, 0.010078041814267635, -0.021124621853232384, -0.009515241719782352, 0.007336028851568699, 0.0015689678257331252, 0.012564830482006073, 0.014069993048906326, 0.011367245577275753, 0.0411236435174942, 2.998564923473168e-05, 0.027721157297492027, 0.006452564150094986, -0.008579423651099205, 0.011537394486367702, 0.012322695925831795, 0.023284202441573143, 0.006406754720956087, -0.014658968895673752, 0.00829147920012474, -0.0027649172116070986, 0.009129134938120842, 0.01827135868370533, 0.008867367170751095, 0.0266348235309124, 0.0123030636459589, -0.00016299105482175946, 0.014894559979438782, 0.03751125559210777, 0.008199861273169518, -0.007761400658637285, 0.010568855330348015, -0.017944149672985077, 0.032747089862823486, 0.009528330527245998, 0.016098689287900925, -0.0024295279290527105, 0.014541174285113811, 0.003087218152359128, 0.00023538607638329268, -0.019396957010030746, -0.026032758876681328, 0.02238110452890396, 0.0019665269646793604, -0.015797657892107964, 0.021765951067209244, -0.0005284427315928042, -0.015313387848436832, 0.014946913346648216, 0.028977641835808754, 0.020705794915556908, 0.03081001155078411, -0.007388382218778133, -0.008644865825772285, 0.010876432061195374, -0.0032835437450557947, 0.0010527954436838627, -0.012420859187841415, -0.012898583896458149, -0.01145886443555355, 0.0225905179977417, -0.00338334240950644, -0.0075650750659406185, 0.034370046108961105, 0.0032082856632769108, 0.02030005492269993, -0.005130639299750328, -0.004296255763620138, 0.007977358996868134, -0.011399966664612293, -0.021229328587651253, 0.0028974369633942842, 0.014698234386742115, -0.016072513535618782, -0.009253473952412605, -0.002624217187985778, 0.0025325987953692675, -0.020273877307772636, 0.02642541006207466, 0.006174436304718256, -0.017368260771036148, -0.0034913215786218643, -0.02522128075361252, -0.019567105919122696, 0.0037301841657608747, 0.018258269876241684, -0.006586719769984484, 0.01696252077817917, -0.005667262244969606, -0.004014856182038784, 0.0024033510126173496, -0.023807736113667488, -0.04149011895060539, 0.03908186033368111, 0.00749308941885829, -0.013428662903606892, -0.011517761275172234, 0.002957970602437854, -0.008435451425611973, 0.0006356037338264287, -0.010163115337491035, -0.0010307087795808911, -0.023689942434430122, 0.016713842749595642, 0.023454351350665092, -0.02083667740225792, 0.009842450730502605, 0.010824078693985939, -0.021334035322070122, -0.00814096350222826, -0.009240386076271534, -0.009888259693980217, -0.012983658351004124, 0.04494544863700867, -0.009142223745584488, 0.00023865816183388233, 0.015784569084644318, -0.02197536639869213, -0.03615006431937218, -0.009672301821410656, -0.005915941204875708, 0.025024954229593277, 0.01878180354833603, -0.020247701555490494, 0.00849434919655323, 0.003057769499719143, -0.0030937623232603073, -0.006377306301146746, -0.006331496872007847, 0.01065392978489399, -0.03745890036225319, 0.015758391469717026, 0.015444271266460419, -0.015051620081067085, -0.010182748548686504, 0.02302243560552597, 0.04858401417732239, 0.024802451953291893, 0.006495101377367973, 0.035888299345970154, 0.019671812653541565, 0.01901739463210106, -0.005814506206661463, -0.012263798154890537, 0.03476269915699959, 0.0014519905671477318, 0.006148259621113539, -0.027904395014047623, 0.003504409920424223, 0.0011730447877198458, 0.01668766513466835, 0.015365741215646267, -0.013598811812698841, 0.006436203606426716, 0.03913421183824539, -0.0057392483577132225, 0.013356677256524563, 0.01763002760708332, -0.004420595243573189, 0.021098444238305092, 0.0034160634968429804, 0.00433224905282259, -0.004397690761834383, 0.0067274197936058044, -0.01083716657012701, -0.002517874352633953, -0.02558775432407856, 0.00852707028388977, -0.004482765216380358, -0.008062433451414108, -0.0266348235309124, -0.009305828250944614, 0.0035076818894594908, -0.009848995134234428, 0.028323223814368248, 0.027956748381257057, 0.007394926622509956, 0.013068732805550098, -0.0037072794511914253, -0.0008356103207916021, -0.021425655111670494, -0.024894071742892265, -0.009168400429189205, -0.01591545157134533, -0.008134419098496437, -0.021661244332790375, 0.011753352358937263, 0.026713354513049126, 0.019331516698002815, 0.00037404094473458827, -0.007643605582416058, 0.00579814612865448, -0.0039068772457540035, -0.008592511527240276, 0.00793809350579977, -0.016229573637247086, -0.008468172512948513, -0.008592511527240276, -0.00644602021202445, -0.008520525880157948, 0.0129771139472723, 0.008906632661819458, 0.024265829473733902, 0.004041032865643501, -0.007898828946053982, 0.049814317375421524, -0.0333753302693367, 0.0021906651090830564, 0.024854805320501328, -0.0006180162308737636, 0.007931549102067947, 0.006053369026631117, -0.013219249434769154, 0.007519266102463007, -0.03628094866871834, 0.0019665269646793604, -0.005912669003009796, 0.0026503941044211388, 0.01621648482978344, 0.0016131410375237465, -0.00440750690177083, 0.010968049988150597, -0.009783552959561348, 0.01786561869084835, 0.011170919984579086, 0.012244165875017643, -0.0069041126407682896, 0.03599300608038902, 0.023415084928274155, 0.012329240329563618, 0.005218985956162214, 0.005768697243183851, -0.01063429657369852, -0.003664742223918438, 0.005065197590738535, 0.025574665516614914, -0.00933854840695858, -0.026438498869538307, 0.01598089374601841, -0.022642871364951134, -0.00033477586111985147, -0.02704056352376938, 0.010673562064766884, -0.0029808753170073032, 0.013363220728933811, 0.010025687515735626, -0.03688301518559456, -0.028742050752043724, 0.0011738627217710018, -0.015797657892107964, 0.01978960819542408, -0.013219249434769154, 0.025195103138685226, -0.018349887803196907, 0.0008662861655466259, -0.008540158160030842, 0.006112266797572374, 0.0188734233379364, -0.033689454197883606, 0.00038426622631959617, 0.011275626718997955, -0.03819185122847557, 0.0005775241297669709, 0.0003458191640675068, 0.008978618308901787, -0.030286477878689766, -0.009057149291038513, -0.01739443838596344, -0.009116046130657196, -0.004286439623683691, 0.0019092652946710587, 0.02387317828834057, 0.014240141957998276, -0.004508941899985075, 0.004198093432933092, 0.011098934337496758, -0.00960686057806015, -0.008383098058402538, -0.005699983332306147, -0.017813265323638916, -0.018467683345079422, 0.00024172574921976775, 0.007781033404171467, 0.012525565922260284, -0.01446264423429966, 0.0007538080681115389, 0.009920980781316757, -0.003821802791208029, 0.01611177809536457, 0.001451172516681254, -0.002386990701779723, -0.019632548093795776, -0.048531658947467804, 0.010778268799185753, 0.005297516006976366, 0.010326720774173737, 0.027668803930282593, -0.033087387681007385, -0.015287211164832115, 0.04172571003437042, -0.016268838196992874, 0.011321435682475567, -0.01992049254477024, -0.014868383295834064, -0.02393862046301365, 0.027249976992607117, -0.00937126949429512, 0.018454594537615776, -0.007925005629658699, -0.025770992040634155, -0.007034996524453163, 0.00466927420347929, 0.019122101366519928, -0.005968294572085142, -0.01679237373173237, -0.008265302516520023, 0.010595032013952732, -0.0046725464053452015, -0.0010266186436638236, -0.02902999520301819, 0.010379074141383171, -0.01446264423429966, 0.010660473257303238, -0.0053891343995928764, -0.004659458063542843, -0.023140229284763336, -0.018834158778190613, 0.0012106738286092877, 0.0205618217587471, -0.00522552989423275, 0.01651751808822155, -0.021085357293486595, -0.004266807343810797, -0.0005255796713754535, -0.02079741284251213, 0.019540930166840553, 0.006105722393840551, 0.04368896409869194, -0.022197868674993515, -0.0037825375329703093, -0.013507192954421043, -0.028611166402697563, -0.00638057803735137, 0.012748068198561668, 0.02231566235423088, -0.0022806476335972548, -0.009567595086991787, -0.01861165650188923, 0.024763187393546104, 0.02727615274488926, -0.020404761657118797, -0.019999021664261818, 0.0063380408100783825, 0.009057149291038513, -0.020116817206144333, -0.01122327335178852, -3.7654612242477015e-05, -0.02167433314025402, 0.026098201051354408, 0.019122101366519928, -0.011301803402602673, -0.012551742605865002, -0.013186528347432613, -0.015496624633669853, 0.04426485300064087, -0.02430509403347969, 0.024737011641263962, 0.009489065036177635, -0.018729450181126595, -0.007820297963917255, 0.010228557512164116, -0.01752532087266445, -0.0004302800225559622, 0.008671042509377003, 0.010274366475641727, 0.00338334240950644, -0.008998251520097256, 0.0055658272467553616, 0.004109746776521206, 0.002519510453566909, 0.010339808650314808, -0.00041616911767050624, 0.031071780249476433, 0.0032753634732216597, -0.009390901774168015, 0.027249976992607117, -0.01897813007235527, 0.014881471171975136, 0.016936345025897026, -0.019069747999310493, 0.01353336963802576, 0.0033866146113723516, 0.0033342610113322735, 0.036254771053791046, 0.01679237373173237, -0.03138589859008789, 0.0005186264752410352, -0.0026373055297881365, -0.007807210087776184, -0.024789365008473396, -0.011026947759091854, 0.013585723005235195, -0.029344115406274796, -0.0246061272919178, -0.02751174382865429, 0.0035829399712383747, 0.019436223432421684, 0.031464431434869766, 0.015077796764671803, 0.0024720649234950542, 0.021765951067209244, -0.005775241181254387, 0.03837508708238602, 0.01918754354119301, 0.001180407009087503, -0.028846757486462593, -0.003468416864052415, -0.008710307069122791, -0.02184448204934597, 0.007080805953592062, -0.0005120823043398559, -0.027825865894556046, -0.029684413224458694, 0.021595802158117294, 0.02612437680363655, -0.002261015120893717, 0.006858303677290678, -0.017001787200570107, 0.01276115607470274, -0.0022937359753996134, 0.008991707116365433, -0.0041228351183235645, -0.0018749083392322063, -0.025731725618243217, -0.007336028851568699, 0.025064220651984215, -0.032040320336818695, -0.012538653798401356, -0.0397886298596859, 0.003151023993268609, 0.017276642844080925, -0.0014159975107759237, -0.009260018356144428, -0.011164375580847263, 0.004296255763620138, -0.021412566304206848, 0.00380871444940567, -0.011655189096927643, 0.004862327594310045, -0.03154296055436134, 0.021019915118813515, 0.002889256691560149, -0.012617184780538082, -0.021085357293486595, 0.008736483752727509, 0.011831882409751415, -0.00403776066377759, -0.022747579962015152, -0.004636553581804037, -0.0017734735738486052, 0.007872652262449265, -0.01591545157134533, -0.005346597172319889, 0.010195836424827576, 0.029239408671855927, 0.03832273557782173, -0.03159531578421593, -0.034605637192726135, 0.007597796153277159, -0.03416063264012337, -0.013729695230722427, 0.019972845911979675, 0.002324820961803198, -0.01925298571586609, 0.02905617095530033, 0.002807454438880086, 0.010143483057618141, 0.0012147639645263553, 0.018729450181126595, -0.02498568966984749, -0.006544182542711496, 0.01995975710451603, -0.002035240875557065, -0.009286195039749146, 0.0017718374729156494, -0.013055644929409027, -0.013742784038186073, 0.023218760266900063, -0.015208681114017963, -0.009390901774168015, 0.015418094582855701, -0.007499633356928825, -0.00265857414342463, 0.0024687929544597864, -0.004603832494467497, 0.01475058775395155, 0.018219005316495895, -0.0025996766053140163, -0.027668803930282593, 0.0002938747056759894, -0.002426255727186799, -0.0008401094819419086, -0.03853214904665947, 0.009384358301758766, 0.018428418785333633, 0.0006090180249884725, 0.005009572021663189, -0.04143776372075081, -0.03609771281480789, 0.007427647244185209, -0.02235492877662182, -0.009102958254516125, 0.00493104150518775, -0.03392504155635834, 0.0259542278945446, -0.017315907403826714, 0.0015076161362230778, 0.0034356960095465183, 0.0006687336717732251, -0.0031755645759403706, 0.026791883632540703, 0.02188374660909176, -0.012113282456994057, -0.022263308987021446, -0.020718881860375404, 0.003589484142139554, -0.017538409680128098, -0.004806702025234699, -0.006586719769984484, -0.02154344879090786, -0.007807210087776184, 0.02066652849316597, 0.0035174982622265816, -0.0022070256527513266, -0.027956748381257057, -0.01240777038037777, -0.014789853245019913, 0.0016818549484014511, -0.024684656411409378, 0.001413543475791812, 0.002205389551818371, 0.002545687137171626, 0.009646125137805939, -0.036123890429735184, 0.010470692068338394, -0.017342085018754005, -0.00017004649271257222, 0.004446772392839193, 0.010496868751943111, 0.22742344439029694, -0.000854833866469562, -0.0237684715539217, 0.0230878759175539, -0.013886755332350731, 0.012106738053262234, 0.015889275819063187, 0.006246422417461872, 0.023506704717874527, 0.0038348911330103874, 0.0052451626397669315, -0.010169659741222858, -0.028401752933859825, 0.0015280666993930936, -0.0037825375329703093, -0.029684413224458694, -0.01810120977461338, -0.010437971912324429, 0.0212424173951149, -0.022813020274043083, -0.006805949844419956, -0.0053007882088422775, -0.012990202754735947, -0.020182259380817413, 0.03023412451148033, 0.025038043037056923, -0.0011934953508898616, 0.003916693385690451, 0.021111533045768738, -0.0047347163781523705, -0.018297534435987473, 0.005830866750329733, 0.004378058481961489, 0.01773473434150219, -0.011570114642381668, -0.012905128300189972, 0.01237504929304123, 0.01891268789768219, 0.01464588101953268, 0.015208681114017963, 0.020234612748026848, -0.022433457896113396, -0.0176954697817564, -0.022525077685713768, 0.010143483057618141, 0.01790488325059414, 0.009260018356144428, -0.02147800847887993, 0.014148523099720478, 0.001876544440165162, -0.01807503215968609, -0.00019090608111582696, 0.01867709681391716, 0.009580683894455433, -0.006315136328339577, -0.02642541006207466, 0.01632119156420231, 0.028532637283205986, 0.016949433833360672, 0.019815785810351372, 0.004466404672712088, 0.002684751059859991, -0.008965530432760715, 0.01814047433435917, -0.018258269876241684, 0.014973090030252934, -0.015601331368088722, -0.00010532043961575255, 0.00800353568047285, -0.002362449886277318, -0.0018847245955839753, -0.0033637098968029022, 0.007165879942476749, 0.01321270503103733, -0.021831393241882324, 0.0016205032588914037, 0.013062188401818275, 0.015300299040973186, 0.007813754491508007, 0.01756458729505539, 0.004351881332695484, -0.01594162918627262, -0.014318672008812428, -0.005474208854138851, -0.008821558207273483, -0.015548978000879288, -0.013481016270816326, 0.012525565922260284, -0.001263027312234044, 0.019331516698002815, 0.0031019425950944424, -0.0055658272467553616, -0.03348004072904587, -0.0025800440926104784, 0.003605844685807824, -0.017171936109662056, 0.005876676179468632, -0.004558023065328598, 0.005382590461522341, -0.006668522022664547, -0.003700735280290246, 0.026202907785773277, 0.004312616307288408, -0.004688906949013472, 0.0031641123350709677, 0.0013145627453923225, -0.023074788972735405, 0.011236362159252167, 0.02194918878376484, -0.021962277591228485, 0.00293670198880136, -0.04379367083311081, 0.008677585981786251, -0.01311454176902771, 0.017250465229153633, 0.01159629225730896, 0.0088477348908782, -0.002136675640940666, -0.010987683199346066, -0.00461037689819932, 0.021294770762324333, 0.0016098689520731568, -0.011537394486367702, 0.009214209392666817, 0.012741523794829845, -0.013546458445489407, 0.02073197066783905, -0.006315136328339577, 0.01611177809536457, -0.008343832567334175, 0.02221095561981201, -0.014266318641602993, 0.008219493553042412, -0.015405005775392056, -0.0026389416307210922, -7.459345943061635e-05, -0.006112266797572374, -0.008978618308901787, 0.009325460530817509, -0.006884480360895395, 0.01752532087266445, -0.008121331222355366, -0.014881471171975136, 0.008441995829343796, 0.030522068962454796, -0.016124866902828217, 0.021582715213298798, 0.02255125343799591, 0.00217430479824543, -0.018716363236308098, -0.012276886962354183, 0.011465407907962799, 0.003811986418440938, -0.01261064037680626, 0.015182503499090672, 0.015444271266460419, -0.009332004934549332, -0.005382590461522341, -0.012885496020317078, -0.014174699783325195, -0.019815785810351372, -0.00604355288669467, 0.008749572560191154, -0.0012523930054157972, -0.018284447491168976, 0.014266318641602993, -0.16596047580242157, 0.013003291562199593, 0.03633330389857292, -0.024462155997753143, -0.013860578648746014, 0.020208436995744705, 0.03523388132452965, -0.008049344643950462, -0.021386388689279556, 0.014907647855579853, 0.020679617300629616, -0.015313387848436832, -0.00797081459313631, -0.02976294234395027, 0.005346597172319889, -0.020745059475302696, -0.011314892210066319, 0.0599970668554306, 0.006832126993685961, 0.01244049146771431, 0.011622468940913677, 0.002853263635188341, 0.027249976992607117, -0.008258759044110775, 0.0050226603634655476, -0.02800910174846649, -0.027852041646838188, 0.047851063311100006, 0.013546458445489407, -0.018009589985013008, -0.011903868056833744, 0.014384113252162933, -0.008566334843635559, -0.0032671832013875246, -0.0212424173951149, -0.020653441548347473, 0.011635556817054749, -0.03329680114984512, -0.007414558902382851, -0.001059339614585042, 0.027825865894556046, 0.021386388689279556, -0.022577431052923203, -0.001088788383640349, -0.00693683372810483, -0.004541662987321615, 0.006982643157243729, -0.008422363549470901, 0.017944149672985077, -0.0367521308362484, -0.00723132211714983, -0.01726355403661728, -0.001989431446418166, -0.014449555426836014, 0.002545687137171626, -0.010019144043326378, -0.006714331451803446, 0.012178723700344563, 0.0001692284713499248, -0.031909435987472534, 0.003697463311254978, -0.02126859314739704, 0.010320176370441914, -0.004191549029201269, -0.00749308941885829, -0.00960686057806015, -0.005902852863073349, 0.0029710589442402124, -0.031019426882267, 0.005592003930360079, -0.004531846381723881, -0.030495891347527504, 0.00100535003002733, -0.03416063264012337, 0.01698869839310646, 0.0016834910493344069, -0.012872407212853432, -0.007898828946053982, -0.0022004814818501472, 0.023951709270477295, -0.0007104528485797346, 0.036019179970026016, -0.018480772152543068, 0.005971566773951054, -0.0088477348908782, 0.0019648908637464046, -0.0026389416307210922, 0.010987683199346066, -0.013107998296618462, -0.004630009178072214, 0.031909435987472534, -0.03253767639398575, -0.01510397344827652, -0.025129660964012146, -0.005755608901381493, 0.007447279989719391, -0.007643605582416058, -0.03960539400577545, 0.0306791290640831, -0.024501420557498932, 0.002285555936396122, -0.0007214961224235594, -0.012198356911540031, 0.011288715526461601, 0.0367521308362484, -0.012381593696773052, 0.0295011755079031, 0.011288715526461601, 0.04154247045516968, 0.0056836227886378765, -0.0254568699747324, -0.00915531162172556, -0.0065605430863797665, 0.03416063264012337, -0.002526054624468088, 0.03622859716415405, -0.006845215335488319, -0.01975034363567829, 0.01552280131727457, -0.012630272656679153, 0.05141109973192215, -0.005951934028416872, -0.0303388312458992, 0.037432726472616196, -0.0110400365665555, -0.018650921061635017, -0.11905176937580109, -0.009521786123514175, 0.03115030936896801, 0.00933854840695858, 0.02467156946659088, 0.02094138413667679, 0.0003719958767760545, 0.00021452648798003793, 0.005690166726708412, 0.028427930548787117, -0.01208710577338934, -0.020889030769467354, -0.010791357606649399, -0.00305122509598732, 0.011471952311694622, -0.018323712050914764, 0.0006131081026978791, -0.02225022204220295, -0.007702502887696028, 0.034841228276491165, -0.004381330218166113, -0.026791883632540703, -0.01709340512752533, 0.004237358458340168, 0.005418583285063505, -0.008991707116365433, -0.03837508708238602, 0.009227297268807888, -0.007807210087776184, 0.007990446873009205, 0.0006572813726961613, -0.014868383295834064, -0.0017554770456627011, -0.004626736976206303, -0.01961945928633213, 0.0004961308441124856, -0.0053891343995928764, -0.009672301821410656, 0.010889519937336445, -0.00611881073564291, 0.011249450035393238, 0.017839442938566208, 0.03884626924991608, -0.019907403737306595, 0.016870902851223946, -0.007695958949625492, -0.05039020627737045, 0.01353336963802576, -0.01083716657012701, -0.022577431052923203, -0.02015608362853527, -0.016255749389529228, -0.013651165179908276, -0.0034062471240758896, 0.001979615306481719, -0.03217120096087456, 0.00842890702188015, 0.0055723716504871845, -0.010490325279533863, -0.010045320726931095, 0.010195836424827576, 0.004705267492681742, -0.015143238939344883, 0.03536476194858551, 0.027328507974743843, -0.017041051760315895, -0.0313597247004509, 0.014920736663043499, 0.0036320213694125414, -0.0051175509579479694, -0.01090260874480009, 0.01352028176188469, -0.021582715213298798, 0.018428418785333633, -0.02683115005493164, 0.0060173762030899525, -0.02015608362853527, 0.00494740204885602, 0.01220490038394928, 0.004875415936112404, -0.013795137405395508, -0.008441995829343796, -0.0062333340756595135, -0.005768697243183851, -0.005575643852353096, 0.024187298491597176, -0.014920736663043499, -0.002740376628935337, -0.001933805993758142, -0.01786561869084835, 0.0007697594701312482, 0.04274660348892212, 0.008356921374797821, -0.006311864126473665, -0.02751174382865429, -0.006877935957163572, -0.00849434919655323, 0.006720875855535269, -0.007388382218778133, -0.003131391480565071, 0.00616789236664772, 0.004381330218166113, -0.0364118330180645, 0.013795137405395508, 0.012872407212853432, -0.007853019051253796, 0.0036189330276101828, 0.0009227297850884497, 0.03698772192001343, 0.005359685514122248, 0.03863685578107834, -0.014161611907184124, -0.03243296965956688, 0.001636863686144352, -0.01891268789768219, -0.012669538147747517, -0.007781033404171467, -0.00021043638116680086, 0.023349644616246223, 0.0025702277198433876, 0.015470447950065136, -0.014017639681696892, -0.008363465778529644, 0.011013859882950783, -0.004953946452587843, 0.01901739463210106, 0.002185757039114833, -0.001609050901606679, -0.00018262359662912786, 0.017616940662264824, -0.027249976992607117, -0.02454068511724472, 0.017917972058057785, -0.022368015721440315, -0.004158827941864729, 0.008121331222355366, -0.022106248885393143, -0.01083716657012701, -0.015850011259317398, 0.03031265363097191, 0.0041162907145917416, -0.005336781032383442, 0.00888045597821474, 0.007578163407742977, -0.026333792135119438, -0.021464919671416283, 0.01006495300680399, 0.018991218879818916, -0.019292250275611877, 0.0038054422475397587, 0.0009636309114284813, -0.01321270503103733, -0.0026634824462234974, 0.011727175675332546, -0.016465162858366966, -0.0064492919482290745, -0.031071780249476433, -0.014789853245019913, -0.008500893600285053, -0.024357447400689125, 0.019292250275611877, -0.027459390461444855, 0.044186320155858994, -0.005922485608607531, 0.0055102016776800156, -0.0062824152410030365, 0.024030238389968872, 0.004574383608996868, 0.010477236472070217, 0.006982643157243729, 0.010019144043326378, -0.02753792144358158, -0.01688399165868759, -0.01662222482264042, 0.002733832225203514, -0.007480001077055931, 0.014004550874233246, 0.0027485566679388285, -0.007427647244185209, 0.023375820368528366, 0.0046790908090770245, 0.00908332597464323, 0.0387677401304245, -0.006262782961130142, -0.027668803930282593, 0.0019697989337146282, 0.04065246134996414, 0.020404761657118797, -0.01285931933671236, 0.013441751711070538, -0.014960002154111862, 0.008553246967494488, -0.004191549029201269, -0.012924760580062866, -0.004181732889264822, -0.005938845686614513, -0.003753088880330324, 0.014920736663043499, -0.031673844903707504, -0.007944637909531593, 0.014855294488370419, 0.027433214709162712, -0.010365985333919525, 0.021019915118813515, 0.002529326593503356, -0.015300299040973186, -0.014266318641602993, 0.0249464251101017, -0.0018290990265086293, -0.03128119185566902, -0.008841190487146378, 0.022904640063643456, -0.0003519543388392776, 0.0323544405400753, 0.014672057703137398, 0.005951934028416872, -0.002454068511724472, -0.010222013108432293, -0.027328507974743843, -0.0038708841893821955, -0.026883503422141075, 0.009705022908747196, 0.0010986046399921179, -0.01621648482978344, -0.012597551569342613, 0.008572879247367382, 0.01914827898144722, -0.0008466536528430879, 0.015627508983016014, 0.014685146510601044, 0.00024029420455917716, 0.012682626023888588, 0.011373789981007576, 0.0036287494003772736, -0.001393910963088274, -0.01925298571586609, -0.008867367170751095, -0.024501420557498932, -0.007041540462523699, -0.012937849387526512, -0.02255125343799591, 0.06994422525167465, 0.015247945673763752, -0.0034356960095465183, 0.011923501268029213, 0.0024295279290527105, 0.02902999520301819, 0.014357936568558216, -0.0025244185235351324, -0.05376700684428215, -0.01763002760708332, 0.037406548857688904, -0.0044565885327756405, 0.00076280627399683, -0.04861018806695938, 0.00827839132398367, 0.03081001155078411, 0.013454839587211609, 0.022904640063643456, 0.005634541157633066, -0.020875943824648857, 0.015692949295043945, -0.0055658272467553616, 0.015954717993736267, -0.013651165179908276, 0.004463132470846176, -0.008513981476426125, 0.03206649422645569, -0.01897813007235527, -0.020103730261325836, -0.010529589839279652, 0.024161122739315033, 0.0008654681732878089, -0.026883503422141075, -0.0014356301398947835, 0.008605600334703922, 0.008376553654670715, -0.0017718374729156494, -0.010509957559406757, -0.0014168155612424016, 0.03046971559524536, -0.017080316320061684, -0.005058653187006712, -0.02197536639869213, -0.004387874621897936, -0.036595068871974945, 0.0015018898993730545, -0.012355417013168335, -0.0035763958003371954, -0.03452710807323456]}}, rets=[{'node': {'id_': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'b5542e96-351d-4501-a621-d2aaee1386eb', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '47845a6529a286c4db5938e0f0349691964e347496cd3c65c4a3feff45ba6666'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'bdde83a5-6a37-4e11-9adf-5717c3b28b88', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '505dfda29fbdfe6cf75948c2f2605eed66b308f218805e30fc5050105bf992da'}}, 'text': \"We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, . So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n. Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n-\\n113, Measuring Heart Rate\\n. Heart rate can be measured by\\n2, . listening to the chest\\n4, . Sensing minute changes in blood flow via \\nphotoplethysmography\\n. (\\n2, ) are ambulatory, for \\nemergency response while (\\n4, ) \\ncan be embedded in wearable sensors\\n-\\n115, . Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n. Used on watches like Apple \\nWatch where you see\\n2, LEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n-\\n117, Measuring Blood Pressure\\n. Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n. BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n. BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n. Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n-\\n119, Measuring Respiration\\n. Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n. Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n. Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n-\\n121, -\\n123, Polygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n-\\n125, -\\n127, -\\n5, stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n. Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n. The first sleep cycle is usually shortest at\\n100, minutes. Later cycles are\\n110, minutes. \\n. If you sleep for\\n5, full \\ncycles\\nSleep Explained\\n-\\n130, Why is sleep important ?\\n. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n.\", 'start_char_idx': 16001, 'end_char_idx': 19861, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8357276384880378}], error=None, perf=Perf(start_time=datetime.datetime(2024, 3, 4, 16, 59, 34, 776213), end_time=datetime.datetime(2024, 3, 4, 16, 59, 35, 712747)), pid=555, tid=555), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine, id=140331591613408, init_bindings=None), name='get_response')), RecordAppCallMethod(path=Lens().app._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.refine.Refine, id=140331591613408, init_bindings=None), name='get_response')), RecordAppCallMethod(path=Lens().app._response_synthesizer._llm, method=Method(obj=Obj(cls=llama_index.llms.openai.base.OpenAI, id=140331692327856, init_bindings=None), name='wrapped_llm_chat'))], args={'_self': {'callback_manager': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'llama_index.core.callbacks', 'module_name': 'llama_index.core.callbacks.base'}, 'bases': None}, 'id': 140331758759616, 'init_bindings': None}}, 'system_prompt': None, 'messages_to_prompt': {'__tru_non_serialized_object': {'cls': {'name': 'function', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}, 'id': 140331909749424, 'init_bindings': None}}, 'completion_to_prompt': {'__tru_non_serialized_object': {'cls': {'name': 'function', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}, 'id': 140331910254880, 'init_bindings': None}}, 'output_parser': None, 'pydantic_program_mode': <PydanticProgramMode.DEFAULT: 'default'>, 'query_wrapper_prompt': None, 'model': 'gpt-3.5-turbo', 'temperature': 0.1, 'max_tokens': None, 'additional_kwargs': {}, 'max_retries': 3, 'timeout': 60.0, 'default_headers': None, 'reuse_client': True, 'api_key': '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', 'api_base': 'https://api.openai.com/v1', 'api_version': ''}, 'messages': [{'role': <MessageRole.SYSTEM: 'system'>, 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\", 'additional_kwargs': {}}, {'role': <MessageRole.USER: 'user'>, 'content': \"Context information is below.\\n---------------------\\nfile_path: /content/preprocessed_data/preproccesed.csv\\n\\nWe’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, . So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n. Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n-\\n113, Measuring Heart Rate\\n. Heart rate can be measured by\\n2, . listening to the chest\\n4, . Sensing minute changes in blood flow via \\nphotoplethysmography\\n. (\\n2, ) are ambulatory, for \\nemergency response while (\\n4, ) \\ncan be embedded in wearable sensors\\n-\\n115, . Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n. Used on watches like Apple \\nWatch where you see\\n2, LEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n-\\n117, Measuring Blood Pressure\\n. Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n. BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n. BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n. Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n-\\n119, Measuring Respiration\\n. Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n. Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n. Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n-\\n121, -\\n123, Polygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n-\\n125, -\\n127, -\\n5, stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n. Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n. The first sleep cycle is usually shortest at\\n100, minutes. Later cycles are\\n110, minutes. \\n. If you sleep for\\n5, full \\ncycles\\nSleep Explained\\n-\\n130, Why is sleep important ?\\n. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n.\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: Can you list ways that heart rate can be measured?\\nAnswer: \", 'additional_kwargs': {}}]}, rets={'message': {'role': <MessageRole.ASSISTANT: 'assistant'>, 'content': 'Heart rate can be measured by listening to the chest and sensing minute changes in blood flow via photoplethysmography.', 'additional_kwargs': {}}, 'raw': {'id': 'chatcmpl-8z5x2UA1SOXhnUxhwrkLYmD6nWoMP', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'Heart rate can be measured by listening to the chest and sensing minute changes in blood flow via photoplethysmography.', 'role': 'assistant', 'function_call': None, 'tool_calls': None}}], 'created': 1709571576, 'model': 'gpt-3.5-turbo-0125', 'object': 'chat.completion', 'system_fingerprint': 'fp_2b778c6b35', 'usage': {'completion_tokens': 25, 'prompt_tokens': 1095, 'total_tokens': 1120}}, 'delta': None, 'additional_kwargs': {}}, error=None, perf=Perf(start_time=datetime.datetime(2024, 3, 4, 16, 59, 36, 156328), end_time=datetime.datetime(2024, 3, 4, 16, 59, 37, 607505)), pid=555, tid=555), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine, id=140331591613408, init_bindings=None), name='get_response')), RecordAppCallMethod(path=Lens().app._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.refine.Refine, id=140331591613408, init_bindings=None), name='get_response'))], args={'query_str': 'Can you list ways that heart rate can be measured?', 'text_chunks': [\"file_path: /content/preprocessed_data/preproccesed.csv\\n\\nWe’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, . So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n. Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n-\\n113, Measuring Heart Rate\\n. Heart rate can be measured by\\n2, . listening to the chest\\n4, . Sensing minute changes in blood flow via \\nphotoplethysmography\\n. (\\n2, ) are ambulatory, for \\nemergency response while (\\n4, ) \\ncan be embedded in wearable sensors\\n-\\n115, . Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n. Used on watches like Apple \\nWatch where you see\\n2, LEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n-\\n117, Measuring Blood Pressure\\n. Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n. BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n. BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n. Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n-\\n119, Measuring Respiration\\n. Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n. Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n. Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n-\\n121, -\\n123, Polygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n-\\n125, -\\n127, -\\n5, stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n. Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n. The first sleep cycle is usually shortest at\\n100, minutes. Later cycles are\\n110, minutes. \\n. If you sleep for\\n5, full \\ncycles\\nSleep Explained\\n-\\n130, Why is sleep important ?\\n. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n.\"], 'prev_response': None}, rets='Heart rate can be measured by listening to the chest and sensing minute changes in blood flow via photoplethysmography.', error=None, perf=Perf(start_time=datetime.datetime(2024, 3, 4, 16, 59, 35, 960981), end_time=datetime.datetime(2024, 3, 4, 16, 59, 37, 610316)), pid=555, tid=555), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='query')), RecordAppCallMethod(path=Lens().app._response_synthesizer, method=Method(obj=Obj(cls=llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine, id=140331591613408, init_bindings=None), name='get_response'))], args={'query_str': 'Can you list ways that heart rate can be measured?', 'text_chunks': [\"file_path: /content/preprocessed_data/preproccesed.csv\\n\\nWe’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, . So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n. Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n-\\n113, Measuring Heart Rate\\n. Heart rate can be measured by\\n2, . listening to the chest\\n4, . Sensing minute changes in blood flow via \\nphotoplethysmography\\n. (\\n2, ) are ambulatory, for \\nemergency response while (\\n4, ) \\ncan be embedded in wearable sensors\\n-\\n115, . Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n. Used on watches like Apple \\nWatch where you see\\n2, LEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n-\\n117, Measuring Blood Pressure\\n. Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n. BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n. BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n. Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n-\\n119, Measuring Respiration\\n. Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n. Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n. Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n-\\n121, -\\n123, Polygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n-\\n125, -\\n127, -\\n5, stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n. Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n. The first sleep cycle is usually shortest at\\n100, minutes. Later cycles are\\n110, minutes. \\n. If you sleep for\\n5, full \\ncycles\\nSleep Explained\\n-\\n130, Why is sleep important ?\\n. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n.\"]}, rets='Heart rate can be measured by listening to the chest and sensing minute changes in blood flow via photoplethysmography.', error=None, perf=Perf(start_time=datetime.datetime(2024, 3, 4, 16, 59, 35, 795903), end_time=datetime.datetime(2024, 3, 4, 16, 59, 37, 610421)), pid=555, tid=555), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, id=140331591791424, init_bindings=None), name='query'))], args={'str_or_query_bundle': 'Can you list ways that heart rate can be measured?'}, rets={'response': 'Heart rate can be measured by listening to the chest and sensing minute changes in blood flow via photoplethysmography.', 'source_nodes': [{'node': {'id_': 'c026c4a3-533e-4c49-b14f-8df14045a40f', 'embedding': None, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'excluded_embed_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'excluded_llm_metadata_keys': ['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': 'f9f22fb6-6e47-4986-8ddd-39df0139ef69', 'node_type': <ObjectType.DOCUMENT: '4'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '6cac8f9dee72703582af2ee414bdc488be3cbc3ef13e00b6a26f31a96dbb15ee'}, <NodeRelationship.PREVIOUS: '2'>: {'node_id': 'b5542e96-351d-4501-a621-d2aaee1386eb', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}, 'hash': '47845a6529a286c4db5938e0f0349691964e347496cd3c65c4a3feff45ba6666'}, <NodeRelationship.NEXT: '3'>: {'node_id': 'bdde83a5-6a37-4e11-9adf-5717c3b28b88', 'node_type': <ObjectType.TEXT: '1'>, 'metadata': {}, 'hash': '505dfda29fbdfe6cf75948c2f2605eed66b308f218805e30fc5050105bf992da'}}, 'text': \"We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n. Lets see them … \\n-\\n106, -\\n108, . These adverts are different … they \\ninduce a sense of … cute !\\n. They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n. You get a warm fuzzy feeling inside \\nwhen seeing these\\n-\\n110, . Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-\\n111, . So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n. Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n-\\n113, Measuring Heart Rate\\n. Heart rate can be measured by\\n2, . listening to the chest\\n4, . Sensing minute changes in blood flow via \\nphotoplethysmography\\n. (\\n2, ) are ambulatory, for \\nemergency response while (\\n4, ) \\ncan be embedded in wearable sensors\\n-\\n115, . Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n. Used on watches like Apple \\nWatch where you see\\n2, LEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n-\\n117, Measuring Blood Pressure\\n. Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n. BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n. BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n. Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n-\\n119, Measuring Respiration\\n. Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n. Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n. Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n-\\n121, -\\n123, Polygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n-\\n125, -\\n127, -\\n5, stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n. Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n. The first sleep cycle is usually shortest at\\n100, minutes. Later cycles are\\n110, minutes. \\n. If you sleep for\\n5, full \\ncycles\\nSleep Explained\\n-\\n130, Why is sleep important ?\\n. It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n. Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n. Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n. Orthosomnia - preoccupation with perfecting \\nsleep data\\n-\\n132, . Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n.\", 'start_char_idx': 16001, 'end_char_idx': 19861, 'text_template': '{metadata_str}\\n\\n{content}', 'metadata_template': '{key}: {value}', 'metadata_seperator': '\\n'}, 'score': 0.8357276384880378}], 'metadata': {'c026c4a3-533e-4c49-b14f-8df14045a40f': {'file_path': '/content/preprocessed_data/preproccesed.csv', 'file_name': '/content/preprocessed_data/preproccesed.csv', 'file_type': 'text/csv', 'file_size': 28775, 'creation_date': '2024-03-04', 'last_modified_date': '2024-03-04'}}}, error=None, perf=Perf(start_time=datetime.datetime(2024, 3, 4, 16, 59, 34, 566721), end_time=datetime.datetime(2024, 3, 4, 16, 59, 37, 610590)), pid=555, tid=555)], feedback_and_future_results=[(Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.groundedness.Groundedness, id=140331588692032, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'Groundedness', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundedness'}, 'bases': [{'name': 'Groundedness', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundedness'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'groundedness_provider': {'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'model_engine': 'gpt-3.5-turbo'}})), name='groundedness_measure_with_cot_reasons'), aggregator=Method(obj=Obj(cls=trulens_eval.feedback.groundedness.Groundedness, id=140331588692032, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'Groundedness', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundedness'}, 'bases': [{'name': 'Groundedness', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundedness'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'groundedness_provider': {'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'model_engine': 'gpt-3.5-turbo'}})), name='grounded_statements_aggregator'), feedback_definition_id='feedback_definition_hash_3666c4bf5f21c0728d199f53bf4f7e2e', selectors={'source': Lens().__record__.app.query.rets.source_nodes[:].node.text.collect(), 'statement': Lens().__record__.main_output}, supplied_name=None, higher_is_better=True, imp=<bound method Groundedness.groundedness_measure_with_cot_reasons of Groundedness(tru_class_info=trulens_eval.feedback.groundedness.Groundedness, groundedness_provider=OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=Endpoint(openai), model_engine='gpt-3.5-turbo'))>, agg=<bound method Groundedness.grounded_statements_aggregator of Groundedness(tru_class_info=trulens_eval.feedback.groundedness.Groundedness, groundedness_provider=OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=Endpoint(openai), model_engine='gpt-3.5-turbo'))>), <Future at 0x7fa17ec5a890 state=finished returned FeedbackResult>), (Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.provider.openai.OpenAI, id=140331594490048, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'model_engine': 'gpt-3.5-turbo'})), name='relevance'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_d63840a253b1e3fc3074b60912d30ab0', selectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output}, supplied_name=None, higher_is_better=True, imp=<bound method LLMProvider.relevance of OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=Endpoint(openai), model_engine='gpt-3.5-turbo')>, agg=<function mean at 0x7fa1d81721b0>), <Future at 0x7fa17ec586d0 state=running>), (Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.provider.openai.OpenAI, id=140331594490048, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'model_engine': 'gpt-3.5-turbo'})), name='qs_relevance'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_2324595945ccbacc0a895b98508ea156', selectors={'question': Lens().__record__.main_input, 'statement': Lens().__record__.app.query.rets.source_nodes[:].node.text}, supplied_name=None, higher_is_better=True, imp=<bound method LLMProvider.qs_relevance of OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=Endpoint(openai), model_engine='gpt-3.5-turbo')>, agg=<function mean at 0x7fa1d81721b0>), <Future at 0x7fa17ecb1540 state=running>)], feedback_results=[<Future at 0x7fa17ec5a890 state=finished returned FeedbackResult>, <Future at 0x7fa17ec586d0 state=running>, <Future at 0x7fa17ecb1540 state=running>])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# The record of the app invocation can be retrieved from the `recording`:\n",
        "rec = recording.get()\n",
        "\n",
        "display(rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTfcwLq1VUuB",
        "outputId": "11d14d6e-6f69-4fb6-c858-a306ab68b3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "groundedness_measure_with_cot_reasons 1.0\n",
            "relevance 0.8\n",
            "qs_relevance 0.2\n"
          ]
        }
      ],
      "source": [
        "# The results of the feedback functions can be retrieved using the `wait_for_feedback_result` method. Also prints a score for your metrics below seperate to the average one printed using get_leaderboard()\n",
        "for feedback, feedback_result in rec.wait_for_feedback_results().items():\n",
        "    print(feedback.name, feedback_result.result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "JFCaIZe5UtyW",
        "outputId": "9ac856e0-4987-4662-cd60-869813fd6bed"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"tru\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"qs_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.20000000000000004,\n        \"max\": 0.20000000000000004,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.20000000000000004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groundedness_measure_with_cot_reasons\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9333333333333332,\n        \"max\": 0.9333333333333332,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9333333333333332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3.6666666666666665,\n        \"max\": 3.6666666666666665,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.6666666666666665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0016395000000000001,\n        \"max\": 0.0016395000000000001,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0016395000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d1f08b8b-b664-43e9-a0fe-dba3c2e2320f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qs_relevance</th>\n",
              "      <th>groundedness_measure_with_cot_reasons</th>\n",
              "      <th>relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LlamaIndex_App8</th>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>0.00164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1f08b8b-b664-43e9-a0fe-dba3c2e2320f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1f08b8b-b664-43e9-a0fe-dba3c2e2320f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1f08b8b-b664-43e9-a0fe-dba3c2e2320f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                 qs_relevance  groundedness_measure_with_cot_reasons  \\\n",
              "app_id                                                                 \n",
              "LlamaIndex_App8           0.2                                    1.0   \n",
              "\n",
              "                 relevance   latency  total_cost  \n",
              "app_id                                            \n",
              "LlamaIndex_App8   0.933333  3.666667     0.00164  "
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "records, feedback = tru.get_records_and_feedback(app_ids=[\"LlamaIndex_App8\"])\n",
        "\n",
        "records.head()\n",
        "\n",
        "tru.get_leaderboard(app_ids=[\"LlamaIndex_App8\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xFcZyzVw4lx"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Yb32-SJpxkIK",
        "outputId": "335b0da0-3b5a-44da-c3f9-6377e1322da4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"- 1 -\\nMOOC 2: Sensing the Human\\n- 2 -\\nOverview\\n• In MOOC-1 we looked at the human brain and \\nhuman memory and how it works, and often \\ndoesn’t, and how we use search and \\ninformation seeking to support our memory \\nfunction.  \\n• In MOOC-2 we’ll look at technologies for \\nsensing the human body and where it is and \\nwhat its doing, and applications which use \\nsuch sensing\\n• This covers sensing location, sensing the \\nbody’s activities, sensing our physiology with a \\nparticular focus on sleep applications, and \\nfinishing with sensing activity in the brain\\n- 3 -\\nWhy Know About User Context ?\\n•\\nThere are many reasons for wanting to sense the human \\nbody and where it is and what its doing … health is an \\nobvious one\\n•\\nThere’s also information-finding, when we search for \\ninformation it is usually about documents and pages, and \\nuser query & matching but knowing what we’re doing \\nand/or where we are when we’re seeking information will \\nhelp improve the systems we use\\n•\\nBut we don’t know why the user is searching, or what \\nthey are doing while searching, or what their emotional or \\nother state is, why they need to find information or what \\nthe effect of the information finding will be, so search is \\nstateless, it doesn’t have context;\\n•\\nWhat kinds of contexts about a user can we capture and \\nhow could we fold these into information access ?\\n- 4 -\\nKinds of Context\\n• There is no universally agreed \\nclassification of “user context”, just an \\narbitrary one, different kinds of user \\ncontext that can be captured.\\n• I divide it into 4 areas as follows\\n– Location – where you are on planet earth\\n– Human Activity – what you are doing, now\\n– Your body – what signals are your body \\ngiving about its state\\n– Brain Computer Interfaces\\n- 5 -\\nWeek 1: Sensing Location\\n• Week 1: Sensing Actual Location\\n• GPS how it works, in smartphones, \\ncomputers, watches, cars, etc.\\n• A review of some Location Based \\nServices (LBS) that use actual location \\n• Strava and MapMyRun for the individual\\n• Google and Apple tracking … iPhone \\nlocations … to illustrate ethical and data \\nprivacy issues.\\n- 6 -\\nLocation Tracking - GPS\\n• GPS is a system of c.20 satellites in \\ngeostationary orbit around the early, at \\n20,000km altitude.\\n• Each emits a different radio frequency signal\\n• On earth, a GPS receiver (phone, watch, \\nsatnav, etc.) picks up signals from a number \\nof satellites with direct line of sight, the signal \\nincludes the time taken for the signal to reach \\nthe receiver\\n• Using simple triangulation, the receiver’s \\nlocation is determined\\n• This works all over the planet but not \\nunderground, indoors or in natural or man-\\nmade canyons (cities) \\n- 7 -\\nLocation Tracking – Cellular masts \\n• GPS is based on satellites but its not \\nthe only location identifier\\n• Phones collect cellular network signals \\nincluding signal strength, from masts \\nwhich have fixed, known locations so \\nphones also use cellular data to \\ndetermine location\\n• These work indoor but depend on a \\ndense array of phone coverage masts, \\nso not great in rural areas, for example, \\nor where there’s just one mast for \\ncontact\\n- 8 -\\nLocation tracking - WiFi\\n• Some companies have mapped the \\navailability of WiFi networks in urban \\nareas – a form of extreme Wardriving\\n• They pick up availability of public and \\nprivate WiFis, not to log in, just to \\nrecord that they are there\\n• A WiFi-enabled device will “see” a \\nnumber of available WiFi networks, \\nincluding signal strength (a proxy for \\ndistance) and use this to triangulate \\nlocation\\n- 9 -\\nDetermining Location\\n• Using any of GPS, cellular networks and \\nWiFi networks, or more likely a \\ncombination of all three, a smartphone \\ncan determine location to within a \\ncouple of meters, outdoor or indoor\\n• This used to be computationally \\nexpensive but now smartphones have \\ndedicated chips to do this, so it \\neffectively costs almost nothing.\\n- 10 -\\nUsing Location on Smartphones\\n• There are many services which use \\nsmartphone location which we take for \\ngranted\\n– Google and Apple maps for directions from \\nyour location\\n– Personalised services like searching for \\nnearest pizza restaurant\\n– Pinning the location of your tent at a music \\nfestival \\n– Sharing your location on WhatsApp so \\nfriends can meet or on Free Now or Uber so \\ndriver can find you\\n– … can you think of more ?\\n- 11 -\\nUsing Location on Smartphones\\n•\\nLocation Based Services (LBS) using actual location are \\npretty much complete, they are reliable, they work, \\nthey bring us advantage, its hard to think of ways to \\nimprove them\\n•\\nThey first appeared in early 1990s with standalone GPS \\ndevices coupled to phones\\n•\\nLBS initially were outdoor and then through 2000s \\nmoved indoors into shopping malls, museums, airports, \\nmany other indoor environments\\n•\\nIn May 2000 President Clinton passed a law to make \\nhigh quality GPS available to everyone, not just military\\n•\\nAs evidence of how well they work, what would the \\nworld be like if they were taken away … no satnav, no \\nUber, no Free Now taxis, no location-awareness on \\nphones … no thanks !\\n•\\nLets look at some LBS applications\\n- 12 -\\nTypes of LBS\\nHaosheng Huang, Georg Gartner, Jukka M. Krisp, Martin Raubal & Nico Van de Weghe (2018) \\nLocation based services: ongoing evolution and research agenda, Journal of Location Based Services, \\n12:2, 63-93, DOI: 10.1080/17489725.2018.1508763 \\n- 13 -\\nHaosheng Huang, Georg Gartner, Jukka M. Krisp, Martin Raubal & Nico Van de Weghe (2018) \\nLocation based services: ongoing evolution and research agenda, Journal of Location Based Services, \\n12:2, 63-93, DOI: 10.1080/17489725.2018.1508763 \\n- 14 -\\nMobile Guides\\n• Mobile Guides are like tourist route \\nguides, downloadable apps on \\nsmartphones\\n• Similar to travel guides but being \\nlocation-based they can personalize \\nmessages .. You are only 100m from an \\ninteresting exhibit or tourist spot\\n• Because the know the location of the \\nuser they are great opportunities for \\ntourist advertising … “eat at our \\nrestaurant”, or “visit our museum”\\n- 15 -\\nHaosheng Huang, Georg Gartner, Jukka M. Krisp, Martin Raubal & Nico Van de Weghe (2018) \\nLocation based services: ongoing evolution and research agenda, Journal of Location Based Services, \\n12:2, 63-93, DOI: 10.1080/17489725.2018.1508763 \\n- 16 -\\nLocation-Based Social Networking\\n• FourSquare used to have 50M users but not as \\npopular now \\n• Users used to “check in” to locations and rate \\nthem and accumulate points the more they \\ntravelled\\n• Based on which of your friends checked into \\nwhere, and their ratings, a user is \\nrecommended places to go nearby\\n• Not as popular now because Facebook does \\nlocation check-ins and people are now more \\nwary of tracking of users’ locations, and \\nFoursquare is openly tracking\\n- 17 -\\nHaosheng Huang, Georg Gartner, Jukka M. Krisp, Martin Raubal & Nico Van de Weghe (2018) \\nLocation based services: ongoing evolution and research agenda, Journal of Location Based Services, \\n12:2, 63-93, DOI: 10.1080/17489725.2018.1508763 \\n- 18 -\\nAssistive Systems\\n• Assistive LBS is more than navigation \\nfor the elderly, it supports older adults \\nwith memory loss or dementia and their \\ncaregivers during getting lost events\\n• Sometimes used by defining physical \\nareas where normal activities take place \\nlike the route to the shops or to friends \\n(called geofencing) and when deviating \\nfrom geofenced areas it triggers a \\n“potentially getting lost” event\\n- 19 -\\nHaosheng Huang, Georg Gartner, Jukka M. Krisp, Martin Raubal & Nico Van de Weghe (2018) \\nLocation based services: ongoing evolution and research agenda, Journal of Location Based Services, \\n12:2, 63-93, DOI: 10.1080/17489725.2018.1508763 \\n- 20 -\\nOther Apps\\n• An open-ended catch-all category\\n– LBS safety is lone workers carrying trackers\\n– Advertising is in-taxi screens showing \\nadverts for local restaurants based on taxi \\nlocation, or Google search results on \\nsmartphone filtered for location\\n– Education is Loop on mobiles, tailoring \\ncontent depending on whether you’re on-\\ncampus or not\\n- 21 -\\nHaosheng Huang, Georg Gartner, Jukka M. Krisp, Martin Raubal & Nico Van de Weghe (2018) \\nLocation based services: ongoing evolution and research agenda, Journal of Location Based Services, \\n12:2, 63-93, DOI: 10.1080/17489725.2018.1508763 \\n- 22 -\\nLBS in Transport\\n• This one is easy …\\n– “Free Now” or Uber .. You track the taxi, \\nthe taxi tracks you\\n– Parking … nearest available spots, or where \\nyou parked your car (Google Maps)\\n– Bus or train arrival times, on-screen bus \\nlocations\\n– Estimated arrival times on \\nnavigation apps based on \\nwhere you are, and where \\neverybody else is, namely \\ncausing traffic jams\\n- 23 -\\nHaosheng Huang, Georg Gartner, Jukka M. Krisp, Martin Raubal & Nico Van de Weghe (2018) \\nLocation based services: ongoing evolution and research agenda, Journal of Location Based Services, \\n12:2, 63-93, DOI: 10.1080/17489725.2018.1508763 \\n- 24 -\\nLBS Fitness Monitoring\\n• Strava a service for running/cycling that \\nuses a smartphone or watch to record \\nruns or bike rides\\n• It logs (GPS) location and from that it \\ngives time, pace, elevation gain and \\nprofile, power output (bike), calories, \\nmap .. all very useful and interesting for \\neach individual\\n• MapMyRun, several others exist\\n- 25 -\\n- 26 -\\nHaosheng Huang, Georg Gartner, Jukka M. Krisp, Martin Raubal & Nico Van de Weghe (2018) \\nLocation based services: ongoing evolution and research agenda, Journal of Location Based Services, \\n12:2, 63-93, DOI: 10.1080/17489725.2018.1508763 \\n- 27 -\\nLBS games – Pokémon Go\\n• Released in 2016, Pokémon Go is an \\naugmented reality mobile game for \\nsmartphones\\n• If you’ve played it, you’ll know it; if you \\nhaven’t then it will seem weird !\\n• Basically your cameraphone screen is \\naugmented with cartoon characters that you \\nhave to “catch” and the characters exist at \\nprecise (GPS) locations so you have to go to \\nthose locations to find them\\n• If these are rare characters in the game, then \\nmany players will gather there, with \\nsmartphones and battery packs because their \\nphone batteries run out ;-)\\n- 28 -\\nPokémon Go\\n- 29 -\\nPokémon Go\\n- 30 -\\nPokémon Go\\n- 31 -\\nPokémon Go\\n- 32 -\\nPokémon Go\\n• Here’s a videograb of me \\nplating Pokémon Go, at \\nhome, the blue lines are \\nroads, houses are not \\nmarked.\\n• There are no Pokémons \\naround so I’d have to \\nmove somewhere to find \\nthem or wait until they \\npop up (see how it \\npromotes exercise by \\nmaking me move \\nelsewhere ;-)\\n- 33 -\\nHaosheng Huang, Georg Gartner, Jukka M. Krisp, Martin Raubal & Nico Van de Weghe (2018) \\nLocation based services: ongoing evolution and research agenda, Journal of Location Based Services, \\n12:2, 63-93, DOI: 10.1080/17489725.2018.1508763 \\n- 34 -\\nLBS Navigation\\n• Navigation was the first LBS service, for \\nsatnav or for games\\n• Aimed at mobile navigation and guiding\\n• This is Google Maps on your \\nsmartphone\\n• Used for navigation (pedestrian and \\nvehicular)\\n• Has in-built personalised advertising\\n- 35 -\\nAugmented Reality\\n• One of the very attractive types of \\ntechnology on smartphones which use \\nlocation, camera and screen is \\naugmented reality (AR)\\n• Virtual Reality (VR) is not the same, its \\nimmersive, you wear a headset which \\ncontrols all that you see, and you \\nbelieve you move into a different world\\n• In the picture here, I’m making pottery \\non a spinning wheel, or so I believe\\n• VR platforms include Microsoft HoloLens \\nor Oculus Rift (which is Facebook’s)\\n- 36 -\\nAugmented Reality\\n• AR is different, its a form of interaction \\nwhich exploits location-as-context using \\nlocation and compass\\n• Typically it uses the smartphone’s camera and \\naugments the screen with additional \\ninformation, super-imposing something onto \\nreality\\n• Pokémon Go is AR .. Lets see an example …\\n- 37 -\\n•\\nVideo shows Alan’s office and \\nas I move around some \\ngreen bushes appear, then \\nan actual Pokémon (it’s a \\nwild Numen, if you didn’t \\nrecognize it) which I then \\ncatch and score points\\n•\\nNotice this is live video \\ncapture, from the camera \\nonto the screen, with reality \\nbeing augmented with \\nbushes appearing on my \\ndesk and then a Pokémon\\n- 38 -\\n• AR does not have to use actual GPS location, \\nit could just use the environment, but when it \\ndoes (like Pokémon Go) can be used for \\nnavigation by overlaying directions on the \\nscreen\\n• How does AR work ?  There are three kinds of \\nimage/screen augmentation:\\n1.\\nBased purely on location/compass … Pokémon Go is \\nan example of this\\n2.\\nBased on image content/analysis … here there is \\nsomething real in the camera video that is detected \\nand when detected the screen is augmented\\n3.\\nBased on a combination of the two\\n- 39 -\\n• For AR based on content, these don’t \\ncare where on earth you actually are, \\njust that your camera “sees” something \\nthe app is looking for, detects it, and \\nresponds\\n• This is a form of computer vision object \\nmatching\\n- 40 -\\n• Object-to-object matching \\nshould be invariant to size \\n(object is near or far away), \\nrotation, inversion, and seeing \\nobjects at an angle\\n• This technique called SIFT/SURF \\nis how it is done … thousands of \\n“interest points” in the query \\nobject and in objects in the \\nvideo are matched (only some \\nare shown in the image), lines \\nbetween them are drawn and if \\nthe connections are mostly \\nparallel lines, then it is a match\\n- 41 -\\n• Treasure hunts are a good example of AR on \\nmobiles based on context (what’s in the \\npicture) and on location\\n• These images are of (1) Guinness gate, (2) \\ngate detected by an AR app, (3) how the \\nactual gate is matched against a target image \\nin the app, and (4) AR overlays a treasure \\nhunt clue when the user is in the right location \\nand finds the gate\\n- 42 -\\nAR Treasure hunt\\n• See an example at \\nhttps://www.youtube.com/watch?v=TPi\\nG3Xrp9OY\\n- 43 -\\nAR on mobile\\n• To make AR possible on phone, manufacturers \\nadopted their processors to support fast, \\nenergy-minimising image content based AR \\napplications, which process camera output in \\nreal time.\\n• AR on mobiles is now easy to do and Layar\\nwas the first (best ?) generic platform with \\nlots of demos like Daft houses for rent, \\nnearest bus/Luas stops, details on overhead \\nflights\\n• See video at \\nhttps://www.youtube.com/watch?v=ZR4eSm\\nmPCxg\\n- 44 -\\nViews on LBS\\n• Back to LBS … what do people really \\nthink of tracking of their location on \\ntheir smartphones … the following \\nseries of infographics expand on this, \\navailable at \\nhttps://www.skyhook.com/blog/infogra\\nphic-cracking-the-code-on-location-\\nservices-on\\n- 45 -\\n- 46 -\\n- 47 -\\n- 48 -\\n- 49 -\\n- 50 -\\n• However there are downsides to LBS, mostly \\nits the personal data captured and the \\ntracking that manufacturers do on us\\n• LBS bring challenges (e.g. privacy, ethical, \\nand legal issues)\\n• Most people don’t realise how much personal \\ninformation is gathered on everyday activities\\n• The next series of slides show how an iPhone \\ntracks and stores your location, on the device\\n• Go to the “Settings” app and follow the menu \\noptions from there\\n- 51 -\\nData Ownership and Privacy\\n• There is much media coverage about \\nour personal data from our use of social \\nmedia being used to personalise \\nadverts for us (we see more of this in a \\nlater MOOC)\\n• In terms of location, both Google and \\nApple track our location on our phones\\n• This is to help improve services and it is \\non the phone only, but iPhone locations \\nwill be uploaded to the cloud and we \\nhave no control over it\\n• Here’s what the iPhone tracks …\\n- 52 -\\n- 53 -\\n- 54 -\\n- 55 -\\n- 56 -\\nNeed to give password to gain access\\n- 57 -\\nAnd here we are … \\n- 58 -\\nThere’s a hierarchy of locations\\n- 59 -\\nLocations, dates of visits\\n- 60 -\\nGoing back in time to when you last \\ncleared it\\n- 61 -\\nBig picture as well as fine detail\\n- 62 -\\n• The iPhone “Settings” menu just \\npresents the locations, no interactions \\nwith them, but it is easy to hack and \\nthen export all my location data from \\nmy phone to … wherever\\n- 63 -\\nLocation in Search\\n•\\nWe now know how Google and other services take \\nadvantage of the searcher’s actual location, especially \\non mobile\\n•\\nSuch services are for individuals mostly, except LBS \\ngaming, even location sharing is sharing of an \\nindividual’s location with another individual, its 1-to-1\\n•\\nThere’s not a lot more that can be done for solo \\nindividual search or information finding other services \\nfor an individual except to personalise search output by \\nlocation\\n•\\nBeyond that we can think of collaborative search or \\nother collaborative services\\n•\\nThis opens up shared searching, shared browsing, either \\nsynchronous or asynchronous and either co-located or \\nnot, but it fits into “location” as the closest form of \\ncontext\\n- 64 -\\nCollaborative Search\\n• Web search can be a social activity … \\nreally.\\n• Have you ever been, or been subjected \\nto a back seat searcher … you have the \\nkeyboard but somebody else telling you \\nwhat to search, what to click … GRRRR !\\n• Search systems are for individuals –\\nalways so – never for groups yet we \\noften search in groups either \\nsynchronously or asynchronously .. and \\n.. there is no computational support for \\nthis in any of the search tools we use\\n- 65 -\\nSearch Together\\n• Two (Jane and Bob) people want to \\ncollaborate on some task like choosing \\na vacation destination \\n• Both search the web and share results \\nby … shouting at each other, or \\nemailing URLs\\n• That is synchronous search – same \\ntime, same location – but Jane’s search \\ncan’t take advantage of the pages Bob \\nhas found, or vice versa\\n- 66 -\\nSearch Together\\n• Bob decides to go out for pizza while \\nJane continues to search, Bob gets \\ndelayed so Jane goes to bed and when \\nhe does get back, Bob picks up the \\ninternet search while Jane sleeps\\n• This is asynchronous search – different \\ntime, same location but same search –\\nand there are no computational tools to \\nsupport this\\n- 67 -\\nSearch Together\\n• Jane gets up early to go to work while \\nBob has a lie-on then during her lunch \\nbreak, Jane picks up the search and \\nWhatsApps Bob to do likewise … they \\nboth continue the same searchfor a \\nvacation destination synchronously, but \\nin different locations\\n• Again, no tools to support collaborative \\nasynchronous or synchronous, co-\\nlocated or remote, searching\\n• Any idea why this might be so ?\\n- 68 -\\nSearch Together\\n•\\nYet we’re seeing real time (synchronous) and delayed \\n(asynchronous) collaboration in other tools\\n•\\nGoogle Docs, Sheets etc. allows synchronousand\\nasynchronous editing and comments\\n•\\nSkype for Business and Zoom allow synchronous \\ncollaboration and shared desktops\\n•\\nShared calendar tools, file sharing like Dropbox and \\nBox, Slack channels and more all support remote or \\nshared location forms of collaboration\\n•\\nYet there’s no support for shared information finding \\ntasks.\\n- 69 -\\nSummary\\n• LBS attracts a lot of commercial interest \\naiming for 4A (anytime, anywhere, for \\nanyone and anything) ‘services’ \\n• Typically these have a very product or \\nservice oriented focus\\n• Huge demand for providing LBS for \\nindoor as well as outdoor\\n- 70 -\\nWeek 2: Sensing Human Activity\\n• By human activity we mean walk, drive, sit or \\nmore, what the body is doing, its movement, \\nits position, and we also mean limb movement \\nso jumping, waving, etc.\\n• Importance in niche applications like movies \\nand games and also useful in information \\nfinding\\n• Based on (wearable) accelerometers and \\ngyroscopes, or motion capture studios, or \\nMicrosoft Kinect\\n• Used as an interface to augmented reality for \\nin-home shopping, for example\\n- 71 -\\nKinds of Context\\n• Location – where you are\\n• Activity – what you are doing now\\n- 72 -\\nHuman Activity As Context\\n• Capturing human activity is done using 1 or more \\nsensors, so this is mostly about sensors and what we \\ncan do using simple sensors\\n• Applications are widespread - sports, ambient-\\nassisted living, gaming, health and wellness, etc.\\n• Wouldn’t it be great to be able to identify what a \\nperson is doing right now... and tailor our information \\naccess accordingly. Its not the primary function, but a \\nsecond-order effect \\n• Why would this be useful?\\n• How can we do it?\\n8\\n- 73 -\\nMotion Sensing on Smartphones\\n• In addition to GPS, which we saw earlier, \\nsmartphones, watches, cars all have built-in \\nmotion sensors\\n• Accelerometers measure the acceleration of a \\nmoving body in a single direction\\n• Put 3 of them together, perpendicularly, and \\nyou can measure acceleration in any direction \\n.. Left right, back forward, up down, or a \\ncombination.\\n• Accelerometers used to be physical devices \\nbut now they are microscopic crystals that \\nbecome stressed when accelerated and the \\nvoltage coming from the crystals changes and \\nthat’s what gives accelerometer values\\n- 74 -\\n• Gyroscopes also used to be large \\nphysical devices for keeping balance on \\nold airplanes, now they are reduced in \\nsize and fit on circuits.\\n• They help accelerometers to understand \\nwhich way your phone is orientated\\n• The magnetometer or compass \\nmeasures which way the phone is \\npointed\\n- 75 -\\nMore sensors \\n• … and it doesn’t end there.\\n• Many phones have a barometer, \\nmeasuring atmospheric pressure, a clue \\nfor altitude\\n• Others have a light sensor, measuring \\nbrightness\\n• Others have a proximity sensor near \\nthe speaker to detect if there’s anything \\n(like your ear) near to it.\\n• So from this orchestra of sensors on the \\nphone, we can detect a lot of \\ninformation\\n- 76 -\\n8\\nLets look at activity classification\\n• You only need an accelerometer-enabled \\nphone and some clever software … to get 98% \\naccuracy in classifying activities !\\n• Walking, standing, running, driving, etc. are \\nall detectable\\n• Accelerometer data is a stream of three \\nnumbers (tri axial) arriving at (at least) 1 Hz\\n• These numbers can be converted into activity \\nlabels using an Artificial Intelligence technique called \\nMachine Learning\\n– So what does that mean ...\\n• The activity labels are then  validated by \\nchecking it against a groundtruth of the \\n‘correct answers’ for different activities\\n- 77 -\\nHow to identify human activity from accelerometers?\\n•\\n1 week groundtruth (132,247 acc readings)\\n•\\nSVM – 39 features (mean/range/stdev of previous 1/5/20/120/300 on X/Y/Z axes)\\n•\\nPrecision score of 0.82 recorded after re-occurrence smoothing\\n8\\n- 78 -\\nIdentifying Activities\\nSitting/Standing = 93% accurate\\nUsing a range of machine learning classifiers: Logistic \\nRegression, Naïve Bayes, SVM, etc.\\n8\\n- 79 -\\nIdentifying Activities\\nWalking = 97% Accurate\\n8\\n- 80 -\\nIdentifying Activities\\nDriving = 98% Accurate\\n8\\n- 81 -\\nIdentifying Activities\\nLying down and resting = 98% \\nAccurate\\n- 82 -\\nActivity detection\\n•\\nSo with a smartphone in your pocket, or a fitness band \\non your wrist, we can classify what you are doing, in \\nreal time\\n•\\nWhy would we bother ?\\n•\\nGoogle speech on mobile uses accelerometers to detect \\nwhen the phone is moved to the mouth to ‘speak’\\nqueries on Android -> that kicks in Automatic Speech \\nRecognition for a user query\\n•\\nAlso used to trigger SIRI on phone\\n•\\nCould extend this further … knowing what the (mobile) \\nuser is doing based on accelerometer activities (and \\ncombine with location), select when to alert, what to \\nsearch, etc.\\n•\\nProblem with using the phone for this is we don’t “wear” \\nthe phone, but we do wear the watch ?\\n- 83 -\\nActivity Detection - Alternatives\\n• The phone or the wearable are good, \\nsometimes great, at classifying activity, \\nbut are there better techniques ?\\n• Yes, but the high-end approaches are \\nvery specialist, expensive, and operate \\nin niche applications\\n- 84 -\\nMore elaborate motion/activity capture\\n• Traditional approach to motion \\ncapture is a Vicon recording studio\\n•In this, a user wears more than a \\ndozen “markers” reflective spheres, \\nat the joints of limbs (knees, ankles, \\nelbows, etc.\\n•A network of infra-red lights and cameras around the subject \\ncapture the markers and in real time, combine them to generate \\na 3D model of the user\\n•This is very accurate - sampling rate is 120-250Hz\\n•Used in movies, in sports analysis, biomechanics\\n• Disadvantages are that it is ….\\n– Cumbersome, expensive\\n– Motion confined to small area, size of a small room\\n– Markers interfere with movement\\n7\\n- 85 -\\nMotion Capture\\n•We wanted to do something cheaper and our objectives \\nwere\\n– Viable, near real-time, cheap, accurate and unobtrusive\\n– Naturalistic (looks real) \\n– Matches real movement (as closely as possible)\\n•\\nSo we came up with the following based on only 6x \\naccelerometers (as used in your phone) worn around the \\nbody\\n- 86 -\\n2.86\\nMotion Capture, Our Approach\\n• Inertial sensing\\n– Synthesize realistic motion from \\nInertial Measurement Units (IMU)\\n• Contextual information\\n– Single low-cost camera if available\\n• Off-line\\n– Capture prototypical movements\\n– Build motion graph\\n• Pre-capture\\n– Define IMU placement\\n– Add virtual IMU data to motion graph\\n• On-line\\n– Search motion graph\\n– Match virtual & real IMU data\\n7\\n- 87 -\\nHow well does it work ?\\n2.87\\n7\\n• Video shows a real person (Sam Barry, Irish tennis player, in black) \\nwearing inertia sensors, data captured wirelessly to generate 3D model \\nwhich is then rendered as a Roger Federer lookalike\\n- 88 -\\nKinect\\n• And then came the Microsoft Kinect !\\n• Sits on top of a TV or computer screen and \\ncontains an integrated microphone array, \\nvisible spectrum camera and IR-based depth \\ncamera\\n• Intended to be a proprietary interface to the \\nX-Box gaming console but it was quickly \\nhacked, so Microsoft gave up and released an \\nAPI so anyone could use it for anything\\n- 89 -\\n• Kinect was released by Microsoft to \\nconnect to X-Box so there are many X-\\nBox games with Kinect interfaces where \\nplaters’ motion is captured\\n• Kinect targeted healthcare apps\\n• It targeted exergaming\\n- 90 -\\nMicrosoft Kinect\\n• Kinect is a form of AR\\n• Works by sending out patterns of dots \\nin invisible spectrum light, and then \\npicks them up with a camera\\n• https://www.youtube.com/watch?v=dT\\nKlNGSH9Po&feature=related\\n• Using this, Kinect knows how far you \\nare from the camera (depth map) and \\ncan augment the video camera image \\non the screen\\n• One example app is the virtual dressing \\nroom where you can “try on” clothes …\\n- 91 -\\n• There is a crude form of AR in \\nshopping – see JCPenny teen on \\nMoodle and t-shirt and shoes videos\\n• Working towards a virtual dressing \\nroom equipped with a Virtual Mirror \\nand a Clothing Advisor \\n• Several issues that are of interest \\nfor such a scenario:\\n– Robust real-time  tracking \\nmethods to ensure that the \\nvirtual clothes follow\\nthe movements of the user\\n– Methods and algorithms for \\nrealistic rendering of virtually \\ntextured clothes\\n– Image processing techniques for \\nscene analysis\\n– Texture and shape based \\nclothing retrieval\\n9\\n1\\nRobust Virtual Mirror\\n- 92 -\\n• Details at \\nhttps://www.youtube.com/watch?v=59\\nVUkMahcLI\\n- 93 -\\nSlide  11\\nClothing Advisor\\n• This is actually a form of location-as-context which \\ndisregards GPS location altogether but uses \\nhuman motion\\n• So could we take this further and search for \\nclothing from a catalog for use in a virtual mirror ?\\n• Yes, and for this need an interactive segmentation \\ntool, or an automatic one, and then use features \\nfrom segmented shirt in search\\n• Colleagues in Singapore are characterising cities \\nby types of clothes worn by general population, \\nbased on streetview !\\n- 94 -\\nTexture-based retrieval results\\n•\\nQuery :\\nTop 5 retrieved results:\\n- 95 -\\nTexture-based retrieval results\\n•\\nQuery :\\nTop 5 retrieved results:\\n- 96 -\\nColour-based retrieval results\\nQuery :\\nTop 5 retrieved results:\\n- 97 -\\nKinect\\n• Best hacks … \\n• #10 virtual dressing room captures \\ndepth of subject and wraps a 3D non-\\ndeforming model of clothes around the \\nsubject, ours deforms the clothes = \\nmore natural\\n• #9 (wall) we did this for NMI treasure \\nroom (award-winning at MM2011)\\n• Play the others and be inspired !\\n• All revolve around sensing what you are \\ndoing, now\\n- 98 -\\nSummary\\n• Human motion and movement will need to be \\ncaptured for high end applications like movies \\nand elite sports\\n• Human motion and movement will also be \\nneeded for low-end applications like using \\nyour phone, for which in-built accelerometers \\nand gyros will be sufficient\\n• Human motion and movement for games is \\npretty much solved with Kinect\\n• Now all we need are applications that use \\nhuman motion.\\n- 99 -\\nWeek 3: Sensing the Body\\n• Here we cover the technology behind wearable \\nsensors measuring heart rate, respiration, \\nGSR, EEG, movement\\n• These have applications like …\\n– Noting HR during the day during exercise or sports, \\ncombine with location for health apps\\n– Logging sleep and sleep quality\\n– Polygraphs\\n• Then we look at examples of pooling personal \\nsensor data including the body, location, \\nactivities .. Raises issues of data ownership, \\nGDPR, double-dipping on the advantages of \\ndata capture\\n- 100\\nSensing the Body - Physiology\\n• Our physiology is the set of outward signs that \\nour body gives constantly, to indicate what state \\nour bodies are in.\\n• For example \\n– when we perspire its an indication we’re too hot and \\nwe need to cool down; \\n– when we’ve goosepimples on our arms it means the \\nenvironment is too cold for us and we need to \\npreserve heat hence the goosepimples; \\n– when our breathing is fast it means we’re extending \\nourselves and we need to get more oxygen into our \\nblood streams because we’re exercising, or we’re \\ntense\\n- 101\\nSensing the Body - Physiology\\n• Sensing the body usually means using some \\nform of wearable sensor\\n• Sometimes it can mean taking samples of body \\nfluids like perspiration, urine, eye tears, blood or \\ninterstitial fluid and analysing this chemically\\n• Wearable sensors are cumbersome and \\ninterfere as our bodies are a hostile environment \\nfor sensors … we sweat thus interfering with \\ncontact between sensor and the skin, we move \\nso sensors don’t stay firmly in place unless they \\nare stuck on like plasters\\n- 102\\nSensing the Body - Physiology\\n• Mostly, and the main reason we sense our bodies, is for \\nhealth reasons, \\n– we monitor our heart rate when we exercise\\n– we track our movement so as to count our exercise or number of \\nsteps taken in a day\\n– older people at home and lone workers in forests and remote areas \\nwear fall detectors to detect when accidents have occurred\\n– the hard of hearing use hearing aids and some people have their \\nheart rates regularised with implanted pacemakers, etc. \\n• While health and wellness reasons are the main reason, \\nthere are others also, like measuring our reaction to \\nadvertising material (just as an example)\\n- 103\\nSensing the Body - Physiology\\n• We can sense and measure the body’s \\nphysiological reaction as we experience \\nsomething, some stimulus like watching a movie \\nor seeing a proposal for a new TV advert\\n• In such cases we see (it is usually seeing \\nbecause when we see something we have a \\nnear-instant reaction whereas when we hear, \\ntaste or feel something it takes some time for the \\nbody to react) the new stimulus and measure \\nsome physiology signals as a proxy to measure \\nhow good or emotional or impactful or terrorising\\nthe stimulus actually is \\n- 104\\n• Lets see some examples …. (see slide \\nnote)\\n• We’ll now see a series of images, each \\nof which will (probably) induce some \\nemotional reaction from you.\\n• Lets see them … \\n- 105\\n- 106\\n- 107\\n• Each one of these is from an advert \\nfor a popular drink in Ireland.\\n• What did you feel when you saw each \\none of them ? \\n• A sense of Irishness, pride, a sense of \\ntaste/quality, sense of excitement \\nwith the rugby picture ?\\n• The goal of the advertiser in this case \\nand the feelings/emotion/reaction \\nthey want to induce in the observer \\nare joy, pride, memory/nostalgia\\n- 108\\n• These adverts are different … they \\ninduce a sense of … cute !\\n• They’re meant to make you smile, you \\nmay even have laughed a bit (go on, \\nadmit it)\\n• You get a warm fuzzy feeling inside \\nwhen seeing these\\n- 109\\n• When advertisers want to measure the \\nimpact of their adverts they measure \\nthe reaction of subjects (like you and \\nme)\\n• The traditional approaches to this are to \\nuse \\n• Questionnaires, easy and can be done at \\nscale\\n• Self-reporting relying on people reporting \\nback themselves\\n• Interviews with subjects one-on-one\\n• Focus groups or meetings with small groups \\nand a structured discussion\\n- 110\\n• Problems with these include\\n– A time lag between seeing the stimulus and \\nhaving to describe the reaction afterwards\\n– Memory – not being able to remember \\nexactly and to what intensity you connected \\nwith the stimulus\\n– Subjective judgments – one person might \\nbe a hard judge and slow to rate highly \\nwhereas another might be more generous, \\nfor the same content\\n– Difficulty in verbally describing their \\nemotions/response … remember in MOOC-1 \\nwhere we discussed vocabulary and \\nmemory where we may not have the words \\nor the language?\\n- 111\\n• So this begs the question of whether \\nthere are valid and objective \\nmeasurements of psychophysiological \\nresponses to a stimulus … i.e. can we \\nmeasure our physiology and how it \\nchanges when we experience a stimulus\\n• Our bodies have evolved a basic  \\n(sympathetic) nervous system which \\nreacts to an unexpected stimulus in one \\nof two ways … we’re either going to \\nfight, or flight, and our physiology \\nreacts\\n- 112\\n(see text in note)\\nHeart Rate\\nBreathing Rate\\nSweat Rate\\n- 113\\nMeasuring Heart Rate\\n• Heart rate can be measured by\\n1. feeling the pulse at wrist or \\ntemple\\n2. listening to the chest\\n3. sensing the electrical pulses via electrodes\\n4. Sensing minute changes in blood flow via \\nphotoplethysmography\\n• (1) and (2) are ambulatory, for \\nemergency response while (3) and (4) \\ncan be embedded in wearable sensors\\n- 114\\n• Sensing HR electrically needs electrodes \\nplaced on the body like in a holtar\\nmonitor, a hospital intensive care unit \\nor a consumer-level wearable as a \\nchest strap connecting to a watch (but \\nthe watch itself is not measuring heart \\nrate here)\\nMeasuring Heart Rate\\n- 115\\n• Measuring HR using \\nphotoplethysmography (PPG) is \\nan optical technique measuring \\nblood flow changes based on \\nshining an LED into the skin and \\nsensing colour changes using a \\nsecond LED which reads the \\nlight form the first LED\\n• Used on watches like Apple \\nWatch where you see 2 LEDs \\nflashing (green) light and 2 \\nLEDs “watching” for changes in \\nlight\\nMeasuring Heart Rate\\n- 116\\n• Heart rate is fairly straightforward, the \\nmeasure is the number of heartbeats per \\nminute (bpm)\\n• It is regulated by our autonomic nervous \\nsystem and changes as follows:\\n– Sympathetic activity like exercise leads to increased \\nHR\\n– Parasympathetic activity like yoga relaxing or a \\ntrained athlete before start of a race leans to \\nreduced HR\\n• Heart rate variability (HRV) is beat-to-beat \\nvariation within a time window and is an \\nindicator of wellness\\nMeasuring Heart Rate\\n- 117\\nMeasuring Blood Pressure\\n• Blood pressure (BP) normally rises and falls \\nthroughout the day but persistently high is \\nbad, long-lasting is called hypertension\\n• BP normally measured by a health practitioner \\nas its two numbers, pressure when it beats, \\nand between beats, and uses a cuff around \\nthe upper arm\\n• BP changes slowly, not instantly, so it’s a \\nlongitudinal measure\\n• Smartphones already have a wide array of \\nsensors inside, but can't measure BP — at \\nleast not yet\\n- 118\\nMeasuring Blood Pressure\\n• To begin BP measurement, use a blood \\npressure cuff like one of these\\n- 119\\nMeasuring Respiration\\n• Respiration is a really good indicator of the \\nbody’s state, but really difficult to measure.\\n• Respiration rate is breaths per minute but \\nthese could be deep, or shallow, so also need \\nthe volume of air breathed\\n• Gold standard is a face mask (awkward, \\ncumbersome) but wearable vests that \\nmeasure expanding/contracting chests are \\nnow available\\n- 120\\nMeasuring GSR\\n• Galvanic Skin Response (GSR) \\nmeasures our skin’s response to \\n(mostly) emotional stimuli like stress\\n• Appears as sweaty palms and \\nelsewhere and we can sense this by \\nmeasuring the electrical conductivity of \\nthe skin (when its wetter it conducts \\nelectricity better)\\n• Not the same as perspiration caused by \\nover-heating\\n- 121\\n- 122\\nPolygraph\\n• One (popular, common) use of sensors \\ntogether is a polygraph\\n• Measures several physiological \\nindicators such as BP, HR, respiration, \\nand skin conductivity while subject is \\nasked and answers a series of questions\\n- 123\\nPolygraph\\nTest truthfulness\\nGSR, HR, BP & RR\\n- 124\\n• From ”The Simpsons”…. \\nhttps://www.youtube.com/watch?v=a1\\npWCkW95W0\\n- 125\\n- 126\\n• What does all this tell us …\\n• … we can measure record different aspects \\nof our physiology and use that data to \\nanalyse human responses to stimuli or \\nnormal daily human activities, sometimes in \\nreal time, using portable and wearable \\ntechnology\\n• It is specialist and niche, but not for long\\n• Lets look at one such activity … sleep\\n- 127\\n- 128\\n• Sleep is “active”, our brains do not shut \\ndown and are almost as active, cataloging \\nmemories\\n• Sleep 5 stages – wake, relaxed \\nwakefulness, light sleep, deep sleep and \\nREM sleep\\n• Starts from N1, goes through N2 to N3 \\n(deep) and then back up towards REM \\nsleep, there is an ordering\\n• The first sleep cycle is usually shortest at \\n70–100 minutes. Later cycles are 90–110 \\nminutes. \\n• If you sleep for 8 hours, you have 5 full \\ncycles\\nSleep Explained\\n- 129\\n• Each phase has characteristics\\n– REM – body paralysed, HR, RR \\nincreased, body temperature drops, \\nvivid dreams, brain active, towards \\nlatter end of the night, memory \\nconsolidation\\n– N1 – conscious of surroundings, hypnic \\njerks\\n– N2 – brief arousals, decreased HR, RR\\n– N3 or deep sleep – slowest HR, RR, \\ndifficult to wake and then groggy\\nSleep Explained\\n- 130\\nWhy is sleep important ?\\n• It is believed that during sleep we re-live \\n(parts of) our day, deciding which parts are \\nmore/less important and worth remembering\\n• Insufficient sleep makes you more stupid, \\nfatter, unhappier, poorer, sicker, worse at sex, \\nmore grumpy, more likely to get cancer, \\nAlzheimer’s and more likely to die in a car \\ncrash !  Who says … see book on next slide.\\n• Recent years have focused on this, we’re more \\naware, partly because we ourselves can now \\nmeasure it, exploiting its structured, \\npredictable, and characteristic nature\\n• Orthosomnia - preoccupation with perfecting \\nsleep data\\n- 131\\nWhy is sleep important ?\\n• This book has done a \\nlot to highlight its \\nimportance\\n- 132\\n• Insufficient sleep leads to reduced blood \\nflow to the skin in the face, so \\ncomplexion is drab, ashen and reveals \\ndark areas\\n• Leads to dark circles under the eyes, \\ntopical creams used to camouflage \\n• Also more wrinkles because less \\ncollagen produced, puffy eyes, no \\n“glow”\\n• … and … you don’t look happy\\nSleep and Appearance\\n- 133\\n• Sleep labs record EEGs \\n(electroencephalograms, \\nrecordings of brain \\nactivity), body and eye \\nmovement, HR, HRV, RR, \\nOxygen saturation, etc.\\n• They pool all these into a \\npolysomnograph for an \\nholistic overview of \\nsleep, which looks like …\\nMeasuring Sleep (Properly)\\n- 134\\n- 135\\nThere are consumer-level techniques for \\nmeasuring sleep which are being used by \\nordinary folks .. like me !\\n1. Phone apps\\n2. Wrist-worn accelerometer devices \\n3. Movement radar or sonar\\n4. The Ōuru ring\\nEach of these uses a subset of sensors to map \\nthe sleeper into different phases of sleep and \\nthen depending on completing the cycles, and \\ntime spent in deep (restorative) sleep, they can \\n“score” your night’s sleep.\\nA night’s sleep is presented as a hypnogram\\nSensing Sleep – Our Options\\n- 136\\nPresented as a Hypnogram\\n- 137\\n• How do they work ? Phones record different \\nthings depending on where they are placed .. \\n– Movement (if in the bed, under the pillow)\\n– Microphone (if beside the bed, actually listening to \\nyour breathing whether its deep and slow, or fast \\nand shallow)\\n– Sonar – inaudible frequency emitted by the phone’s \\nspeaker and listened to by the phone’s mic, picking \\nup your movement and respiration, just like bats \\nnavigate !\\n• There are many available apps, some are \\nfreebies, some are paid\\n• SleepScore, Sleep Cycle, Pillow, etc.\\n1. Smartphone Apps\\n- 138\\n• Examples are FitBit, \\nJawbone, Withings, \\nLARK, etc.\\n• These “just” do \\nmovement but directly \\nfrom the arm, so more \\naccurately than phone \\napps\\n• They then sync with \\nsmartphone and upload \\ndata to the cloud for \\nprocessing\\n2. Wrist-worn Accelerometers \\n- 139\\n• Developed by an Irish SME BiancaMed which \\nsold it to ResMed which developed the “S+” \\nand was first to market\\n• A box beside the bed emits very low levels of \\ntransmitted radio-frequency power acting as \\nsonar to detect in-bed movement\\n• Contactless, measures your\\nmotion, plus from the phone \\nit logs room temperature, \\nbrightness and noise level \\n(yes, your phone is \\nlistening to you as you sleep)\\n3. Sonar / Radar\\n- 140\\n4. The Ōura Ring\\n• From a Finnish start-up, a (finger) \\nring with in-built accelerometer and \\ngyroscope and also measures \\nbody temperature, and heart rate\\n• HR sampled using IR spectrum \\nlight from 2 LEDs at 250 Hz so \\nable to do much more than wrist-\\nworn HR sensors\\n• Contactless battery charge lasts 7 \\ndays, data capacity 6 weeks\\n• Low power Bluetooth download to \\nphone \\n- 141\\n• Consumer grade wearables like the \\nones we’ve een are not sleep labs, they \\nuse a proxy for an orchestra of sensors \\n!\\n• Each individual sensor will have errors \\n(movement, sweat, etc.)\\n• The algorithms to compute “sleep \\nefficiency” are opaque and proprietary\\nAccuracy of sleep tracking ?\\n- 142\\nAnd what about Alan’s Sleep ?\\n• Here’s a sample of summary data over \\n6 months … gaps are when I was \\ntravelling\\n- 143\\nAnd what about Alan’s Sleep ?\\n- 144\\nAnd what about Alan’s Sleep ?\\n- 145\\n• Some use it to inform or influence day-to-day \\nactivities\\n• Some look at trends, but the trends don’t say a lot \\nbecause other factors influence those trends \\n(travel, vacation, stress, colds and flu, sports \\nevents, etc.) and we can’t see those.\\n• That’s because sleep apps, activity apps, health \\napps, all work independently of each other, not \\nsynchronised\\n• So there is not a lot we can actually usefully do \\nwith our own sleep data or any other lifelog data\\n• We can’t easily integrate it or re-purpose it and \\nbecause it reports day-at-a-time information its \\ndifficult to get useful longitudinal analysis.\\nSo what to do with this information ?\\n- 146\\nAggregating health sensor data\\n• There are two ways in which we can \\npool or aggregate individual wearable \\nsensor data for some benefit\\n1. We can aggregate our own personal \\ndata with data from other users, \\nacross a population\\n2. We can aggregate our own personal \\ndata from different apps/sensors\\n- 147\\n• Almost all vendors who allow us gather \\nindividual data, get value from pooling \\nanonymised data\\n• Let’s look at 4 examples\\nPopulation-level Analytics from Pooled \\nIndividual Data\\n- 148\\n• Fitbit – wearable wrist-worn activity logger \\nand sleep recorder\\n• Fitbit mined 150B hours of heart rate data, \\ngathering statistics from millions of sleep \\nnights and discovered the following\\nPopulation-level Analytics from Pooled \\nIndividual Data\\n- 149\\n- 150\\n• Some fitbit devices also record heart \\nrate, so they mined that to correlate \\nresting heart rate (a wellness indicator) \\nwith body-mass index (a weight \\nindicator), age, and amount of exercise \\n• They found insights that cardiologists \\nwere not aware of\\n- 151\\nResting Heart Rate is an excellent indicator of overall health. \\nhttps://finance.yahoo.com/news/exclusive-fitbits-150-billion-hours-heart-data-reveals-secrets-human-health-133124215.html\\n- 152\\nPopulation-level Analytics from Pooled \\nIndividual Data\\n• 23andMe is a DNA testing company \\nwho’s catchphrase is to allow you to \\n”meet your genes”\\n• From a saliva sample they synthesise\\nyour DNA and search it for DNA \\nmarkers which \\n1. Reveal your ancestry\\n2. Report your Genetic Health Risks (whether \\nyou have genetic variants associated with \\nincreased risk for certain(+200) health \\nconditions) and Carrier Status (detect \\ngenetic variants that can cause inherited \\nconditions)\\n- 153\\nPopulation-level Analytics from \\nPooled Individual Data\\n• 23andMe provides benefit to the \\nindividual (gene markers) but even \\nmore benefit when data is pooled in \\norder to connect relatives and \\ndetermine actual exposure risk to \\ndiseases based on population analysis\\n- 154\\nPopulation-level Analytics from Pooled \\nIndividual Data\\n• Earlier we mentioned Strava for \\nrunning/cycling using a smartphone or \\nwatch to record runs or bike rides\\n• It logs (GPS) location and from that it \\ngives time, pace, elevation gain and \\nprofile, power output (bike), calories, \\nmap .. All very useful and interesting \\nfor each individual\\n• But when our data is is pooled, its even \\nmore useful\\n- 155\\n- 156\\n• Community-created segments are short \\n(or long) parts of runs/cycles where \\nparticipants can challenge others, or \\nmark their own personal performances \\non those segments (next slide)\\n- 157\\n- 158\\n• Strava Global Map is an anonymised\\nheatmap of run/cycle routes takenb by \\nall Strava users over previous 2 years, \\nupdated monthly, showing areas where \\npeople run/cycle \\n• Next slide is DCU campus, Albert \\nCollege Park stands out clearly\\n• Slide after that is running in Dublin, \\nPhoenix Park main avenue is a clear \\nhotspot\\n- 159\\nStrava Global Heatmap\\n- 160\\n- 161\\nPopulation-level Analytics from Pooled \\nIndividual Data\\n• Jawbone Up is a wrist-worn activity and \\nsleep tracker\\n• In 2014 a 6.0 earthquake hit Napa \\nValley in Northern California\\n• Jawbone mined the sleep data of those \\nusing their wearable to determine the \\n% of people in each area woken by the \\nearthquake\\n• The theory is the stringer the quake in \\na given area, the greater % of people \\nwho will wake up\\n- 162\\n2014 – Northern Calif. 6.0M Earthquake\\n% people who woke up correlates with distance from epicentre\\n- 163\\n- 164\\nAggregating our own Personal Data \\nAcross Sensors\\n• So what about aggregating our own \\ndata, across different sensors and apps \\n(as opposed to same sensor aggregated \\nacross people)\\n• Best example of this is Apple HealthKit\\n- 165\\n1\\n6\\n• Consolidates health data from iPhone, \\nApple Watch, third-party apps \\n• Activity, Sleep, Mindfulness, and \\nNutrition\\n• “You are in charge of your data”\\n• “The Health app lets you keep all your \\nhealth and fitness information under \\nyour control and in one place on your \\ndevice. You decide which information \\nis placed in Health and which apps \\ncan access your data through the \\nHealth app”\\nApple HealthKit\\nAggregating our own Personal Data \\nAcross Sensors\\n- 166\\nAggregating our own Personal Data \\nAcross Sensors\\n• Apple HealthKit is not the only one \\nthough …\\n• Another is dacadoo, though the revenue \\nmodel for this is different\\n- 167\\ndacadoo\\n- 168\\ndacadoo\\n- 169\\ndacadoo\\n- 170\\ndacadoo\\n- 171\\ndacadoo\\n- 172\\ndacadoo\\n• Revenue stream is \\ncorporate\\n• Employer signs up \\nas a service to \\nemployees, \\nemployees use it, \\nemployer gets \\nhealthier (more \\nproductive) staff\\n- 173\\nAnother Example of Combining \\nAcross Sensors\\n• Another example of how to combine the \\nsensors together, work we did for the Race \\nAround Ireland cycle race\\n– Non-stop, 1,350 miles, solo or team of 4, some hills, \\nmostly flat;\\n• Strategy and pacing are key to completion\\n– When to rest, how to pace, who to race, recovery;\\n• Human performance scientists interested in\\n– How the human body recovers, how to \\nmaximise performance over 4/5-day endurance race,\\nwhat recovery techniques work best.\\n- 174\\nSports - Cycling\\nSo we instrumented a team of 4 cyclists with sensors\\n•\\nOn Body …\\n– Heart rate, GSR, respiration, fluid intake, food \\nintake, sweat analysis, blood analysis, massage,\\n– Ankle-mounted WIMU gives \\ncadence, cycle/rest times\\n•\\nOn Bike …\\n– WIMU gives yaw and roll of the \\nbike, when cyclist is in/out of the\\nsaddle\\n– Power gauge gives power output\\n•\\nEnvironment …\\n– A van followed whichever cyclist was on the road at the time, \\n24 hous a day for 5 days, recording weather, wind, \\ntemperature, road surface, wet/dry, day/night and also did\\nvideo tracking of the cyclist\\n- 175\\nSports - Cycling\\n• We aggregated all this data for each of \\n4 cyclists in the team to study their \\nperformance (degradation) over \\ntime and the impact of different \\nrecovery techniques\\n– Insights into endurance \\nperformance\\n- 176\\nSports - Cycling\\n• This was their aggregated effort, \\naggregated from multiple sensors:\\n- 177\\nWeek 4: Sensing the Brain\\n•\\nThe structure of the human brain … neurons firing … \\nelectrical signals which we can sense with EEG\\n•\\nEEG kit and an outline of some variations of it\\n•\\nWhat can EEG be used for\\n•\\nLocalising areas in the brain to see what areas are \\nactive\\n•\\nPareodolia\\n•\\nERPs P300\\n•\\nBCIs\\n- 178\\n• In MOOC1 we looked at the human \\nbrain and memory and forgetting\\n• We also referenced the human brain \\nwhen covering sleep and how EEGs \\nwhich measure brain activity form part \\nof polysomnographs\\n• Now lets look at the structure of the \\nhuman brain and how it works and how \\nwe can sense it\\n- 179\\nThe Human Brain\\n• 1.5kg, or 2% of our body weight, made of 86B \\nneurons (grey matter) connected by trillions of \\nconnections (synapses) which transmit electric \\npulses as messages\\n• This architecture of huge number of \\nsimple connected processors, is now\\nrealised as good for solving very \\ncomplex problems, like vision, and learning\\n• (That’s why we have deep learning and “AI”)\\n• The brain is responsible for executive \\nfunctions both autonomic (heart, breathing, \\ndigestion, etc.) and voluntary, in addition to \\nexecutive functions like self-control, planning, \\nreasoning, memory and abstract thought.\\n- 180\\nHuman Memory\\n• The brain has been coarsely mapped so we \\nknow which areas are responsible for which \\nkinds of function\\n• So if we can measure activity levels at given \\npoints in the brain, we know what kind of \\n“work” the brain is doing\\n- 181\\nHuman Memory\\n• Like the Human Genome Mapping project \\nwhich ran 1990-2003 and who’s task was to \\nmap the sequence of DNA base pairs that \\nmade up the human DNA, there is a brain \\nmapping project, announced by Obama in \\n2013, to create a dynamic picture of the \\nfunctioning brain, value $100M\\n• Dwarfed by the EU’s €1.5B Human Brain \\nProject, 2013-2023, largest scientific EU \\nproject ever, 100 Universities with the \\nfollowing 6 themes:\\n- 182\\nHuman Brain Project - Structure\\n• Neuroinformatics (access to shared brain data)\\n• Brain Simulation (replication of brain \\narchitecture and activity on computers)\\n• High Performance Analytics and Computing\\n(providing the required computing and \\nanalytics capabilities),\\n• Medical Informatics (access to patient data, \\nidentification of disease signatures)\\n• Neuromorphic Computing (development of \\nbrain-inspired computing) \\n• Neurorobotics (use of robots to test brain \\nsimulations)\\n- 183\\n• We know the brain consists of simple but \\nmassively parallel processing\\n• Each of the 86B cells in the brain connects to \\n000’s of others via neurons\\n• The overall brain “orchestrates” (but without a \\nconductor) activity by sensing messages from \\ncell to cell along neurons\\n• Brain activity is actually electrical charges sent \\nfrom one cell to another, measured in milli-\\nvolts\\n• Such is the scale of the activity, it represents \\nsophisticated processing like thought, \\nconsciousness, control over the body, and as \\nwe saw earlier, memory \\n- 184\\nHuman Memory\\n• As a re-cap from earlier MOOC on memory … \\n• Sensory – short term, \\nrapid decay unless \\nrefreshed, passed to…\\n• Short-term if attentive,\\nthe “post-it” note, \\nusually only 7 items, or \\nchunks, discarded unless\\nconsciously decide to …\\n• Long-term memory, more\\npermanent, this is our\\ninterest\\n- 185\\nBrain Activity\\n• So if brain activity is “only” firing neural \\ncircuits, can we “listen” to this by sensing the \\nelectrical activity ? \\n• Yes of course\\n• BCI (Brain Computer Interface) is a \\ncommunication channel capable of operation \\nentirely on neural signals\\n• Many sensing technologies exist: \\nEEG, nIR, MEG, PET, ECoG, Local Field \\nPotentials, fMRI\\n• Each offers its own interaction paradigms and \\ncapabilities but we are interested in EEG\\n- 186\\nEEG\\n• EEG stands for Electroencephalography and it \\ninvolves the detection of electrical signals \\ngenerated by the brain on the scalp\\n• Non-invasive, requires N sensors on and in \\ncontact with the scalp where an amplification \\nunit digitises the tiny electrical potentials \\ngenerated by the brain\\n• The “N” can be as small as 1\\nor 2 but they’re not much use\\nso 32, 64, 128 (as in image)\\nor even 256 nodes are used,\\nplus a couple on the ear and on\\nthe chin as “ground” (to \\ncomplete the electrical circuit)\\n- 187\\nEEG\\n• Some more \\nexamples of \\nEEG\\n- 188\\nEEG\\nEEG nodes \\n(electrical \\nsensors) are \\nplaced on the \\nscalp according \\nto a Universal \\nplacement \\nstandard, \\nshown here, so \\nthere is \\nconsistency\\nI can add generate some video of me \\nor somebody form the lab searing one \\nof these, needs some recording in \\nSchool Nursing where the EEG lab is \\n… it’ll look cool ;-)\\n- 189\\nEEG – What to Measure ?\\n•\\nIn MOOC 1 we looked at measuring attention levels and \\nshowed, anecdotally, how attention level correlates with \\nmemory recall\\n•\\nWe showed that in the video clipped below, where we \\nused a simple 2-node EEG \\n•\\nSo we can use EEG to measure attention in a way that \\nis similar to “listening” to the amount of “traffic” in the \\nbrain, not localising it or determining where in the \\nbrain, just how active the brain actually is\\n•\\nBut we can do more \\nwhen we determine \\nwhere in the brain, the\\nactivity is, so we use \\nmany nodes and even\\ntriangulate to pinpoint\\nthe places in the brain \\nwhere the greatest activities\\nare\\n- 190\\nBrain Functioning\\n• The brain works in different ways to \\nstore and recall memories, make \\ndecisions, formulate language, make a \\ndecision, create an idea, initiate a \\nmovement, etc.\\n• Understanding these processes is the \\nleading edge of neuroscience\\n• One brain function that is well \\nunderstood is our reaction to external \\nstimuli (not thoughts or ideas we might \\nhave but things we see, hear, feel)\\n• These are called Event Related \\nPotentials or ERPs\\n- 191\\n• We are interested in ERPs (Event Related \\nPotentials) electrical responses at certain scalp \\npoints, generated by the brain in response to \\nstimuli such as an image, \\nsound, touch, taste… \\n• There are several \\nknown ERPs including \\nP1, N1, P2, N2 and P3\\nwhich occur 100, 170,\\n200, 250 and 300 \\nmilliseconds (approx.)\\nafter the stimulation\\nERPs\\n© By Original:ChomsVector:Mononomic - Own work based on: \\nConstudevent.gif, CC BY-SA 3.0, \\nhttps://commons.wikimedia.org/w/index.php?curid=5543904\\n- 192\\nERPs\\n• What is important is knowing the time of \\npresentation of the stimulus, so sound, taste, \\nvideo are not good for this\\n• An example, is an image, presented on a screen\\n• Every time you see a new slide or change of \\nimage in this MOOC, it generates an ERP in your \\nbrain, and it is reflective/indicative of your visual \\nand interpretative processing … namely the fact \\nthat milli-voltages on your scalp are generated \\nand could be recorded is an indication that you \\nhave actually seen, as opposed to eyes glazed \\nover, the images\\n• There are ERPs related simply to visual changes \\n(i.e. there’s a new image), while other ERPs are \\nrelated to specific concepts or elements of the \\nimage (i.e. depend on what’s in the image)\\n- 193\\nA Face\\n- 194\\nThe N170 ERP\\n• The last screen was a face. You might recognise \\nit, you might not, it doesn’t matter because \\nwhether you know who it was or don’t, just \\nseeing a face elicited an N170 ERP (negative at \\n170ms), discovered in 1996, in certain parts of \\nyour brain (unless you were mindwandering or \\nasleep and didn’t actually see the face, so pay \\nattention !)\\n• It was probably around your occipitotemporal \\narea, slightly to the right side, \\nbetween Pz and P4\\n• If you had a couple of EEG nodes\\nthere then 0.17 seconds after\\nseeing Michael D’s face on \\nyour screen, they would have \\ndetected a voltage change\\n- 195\\nERP\\n• Regardless of what I told you to do, or whatever \\nyou are doing so long as you are paying some \\nattention to what you’re seeing, there will always \\nbe a N170 ERP when you see a face, about 0.17 \\nseconds after seeing it, there’s an electrical pulse\\n• We call this type of ERP exogenous – it occurs \\nregardless of your internal mental state or \\nperception\\n• When we see faces that aren’t really faces they \\njust look like faces, its called “pareodolia” and it’s \\na consequence of our evolution … we are social \\nanimals, we are always looking for other people \\nto meet and talk to \\n• We see faces in the patterns of bushes, or leaves, \\nor even when we look at clouds\\n- 196\\n- 197\\n- 198\\n- 199\\nERP – P3\\n• In addition to exogenous ERPs there are \\nendogenous ERPs too !\\n• These ERPs are sensitive and modulated by \\nyour internal cognitive state with regard to \\nthings like expectation .. in other words we \\n“wind you up” and get you ready to see \\nsomething, then when you see it you have an \\nendogenous ERP because you’re expecting \\nsomething to happen, and it does\\n• These tend to appear 220ms after you see \\nsomething and one of these of importance is \\nthe P3 or P300 (same thing, P3 as shorthand \\nfor P300) ERP\\n• Lets make one in your …\\n- 200\\nP300 elicitation\\n• We’re going to show a series of \\nimages, about 1 second apart, \\nand you are to look out for the \\nCocaCola can like the one below, \\nfrom among the following images. \\n• When you see it, as quick as you \\ncan, clap your hands.\\n- 201\\nP300 elicitation\\n- 202\\nP300 elicitation\\n- 203\\nP300 elicitation\\n- 204\\nP300 elicitation\\n- 205\\nP300 elicitation\\n- 206\\nP300 elicitation\\n- 207\\nP300 elicitation\\n- 208\\nP300 elicitation\\n- 209\\nP300 elicitation\\n- 210\\nP300 elicitation\\n- 211\\nP300 elicitation\\n- 212\\nP300 elicitation\\n- 213\\nP300 elicitation\\n- 214\\nP300 wave\\n• When you saw the Coke can, it generated a \\nP300 wave like the dotted line below, and \\nwhen you saw something that wasn’t a Coke \\ncan you flatlined, like the solid line below.\\n• Thiswas generated over your parietal brain \\nareas, so top and back of your head\\n• In experiments, when we do this we average it \\nover many recordings, not just one.\\n- 215\\nP300 wave\\n•\\nThere’s nothing special about the Coke \\ncan. It’s just that you did not know when \\nit was going to appear, and since I told \\nyou to look out for it, its appearance \\ncaught your attention, you recognised it\\n•\\nI could have as equally used any object \\nthat you may be looking for or expecting \\n•\\nSo there is an idea that when searching \\nfor images, we can have a BCI interface \\nbased on using EEG sensors to detect \\nwhen you see something you recognise\\n•\\nResearchers (like us) are working on this \\nkind of interface\\n- 216\\nEEG\\n• So what about BCI ?\\n• It can be used to measure attention levels and \\nto measure reaction to (visual) stimuli … an \\nuncontrollable and natural reaction\\n• And what does that get us ? When EEG \\nbecomes less intrusive to use – and it will –\\nthen we, or others, can ”tap into our brains”, \\nin real time, perhaps to sense what we are \\nthinking.\\n• Sci-Fi ?  Maybe, but it’s the ultimate form of \\nsensing the human, and it’ll happen in our \\nlifetime.\\n\""
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extracting the contents from the pdf slides.\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    extracted_text = \"\"\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "    for page_number in range(pdf_document.page_count):\n",
        "        current_page = pdf_document[page_number]\n",
        "        extracted_text += current_page.get_text()\n",
        "\n",
        "    pdf_document.close()\n",
        "    return extracted_text\n",
        "\n",
        "pdf_file_path = 'data/HumanSensing.pdf'\n",
        "extracted_text = extract_text_from_pdf(pdf_file_path)\n",
        "extracted_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the function to process the text and split on page number. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN8zc1bDJT7R",
        "outputId": "08bec433-2401-4a69-e138-df8025db2709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Page Number: 1\n",
            "Content: -\n",
            "mooc\n",
            "\n",
            "Page Number: 2\n",
            "Content: -\n",
            "overview\n",
            ". in mooc-\n",
            "\n",
            "Page Number: 2\n",
            "Content: we’ll look at technologies for \n",
            "sensing the human body and where it is and \n",
            "what its doing, and applications which use \n",
            "such sensing\n",
            ". this covers sensing location, sensing the \n",
            "body’s activities, sensing our physiology with a \n",
            "particular focus on sleep applications, and \n",
            "finishing with sensing activity in the brain\n",
            "-\n",
            "\n",
            "Page Number: 4\n",
            "Content: -\n",
            "kinds of context\n",
            ". there is no universally agreed \n",
            "classification of “user context”, just an \n",
            "arbitrary one, different kinds of user \n",
            "context that can be captured.\n",
            ". i divide it into\n",
            "\n",
            "Page Number: 5\n",
            "Content: -\n",
            "week\n",
            "\n",
            "Page Number: 1\n",
            "Content: : sensing actual location\n",
            ". gps how it works, in smartphones, \n",
            "computers, watches, cars, etc.\n",
            ". a review of some location based \n",
            "services (lbs) that use actual location \n",
            ". strava and mapmyrun for the individual\n",
            ". google and apple tracking … iphone \n",
            "locations … to illustrate ethical and data \n",
            "privacy issues.\n",
            "-\n",
            "\n",
            "Page Number: 20\n",
            "Content: satellites in \n",
            "geostationary orbit around the early, at\n",
            "\n",
            "Page Number: 7\n",
            "Content: -\n",
            "location tracking – cellular masts \n",
            ". gps is based on satellites but its not \n",
            "the only location identifier\n",
            ". phones collect cellular network signals \n",
            "including signal strength, from masts \n",
            "which have fixed, known locations so \n",
            "phones also use cellular data to \n",
            "determine location\n",
            ". these work indoor but depend on a \n",
            "dense array of phone coverage masts, \n",
            "so not great in rural areas, for example, \n",
            "or where there’s just one mast for \n",
            "contact\n",
            "-\n",
            "\n",
            "Page Number: 9\n",
            "Content: -\n",
            "determining location\n",
            ". using any of gps, cellular networks and \n",
            "wifi networks, or more likely a \n",
            "combination of all three, a smartphone \n",
            "can determine location to within a \n",
            "couple of meters, outdoor or indoor\n",
            ". this used to be computationally \n",
            "expensive but now smartphones have \n",
            "dedicated chips to do this, so it \n",
            "effectively costs almost nothing.\n",
            "-\n",
            "\n",
            "Page Number: 11\n",
            "Content: -\n",
            "using location on smartphones\n",
            ".\n",
            "location based services (lbs) using actual location are \n",
            "pretty much complete, they are reliable, they work, \n",
            "they bring us advantage, its hard to think of ways to \n",
            "improve them\n",
            ".\n",
            "they first appeared in early 1990s with standalone gps \n",
            "devices coupled to phones\n",
            ".\n",
            "lbs initially were outdoor and then through 2000s \n",
            "moved indoors into shopping malls, museums, airports, \n",
            "many other indoor environments\n",
            ".\n",
            "in may\n",
            "\n",
            "Page Number: 12\n",
            "Content: -\n",
            "types of lbs\n",
            "haosheng huang, georg gartner, jukka m. krisp, martin raubal & nico van de weghe (\n",
            "\n",
            "Page Number: 12\n",
            "Content: :\n",
            "\n",
            "Page Number: 63\n",
            "Content: -\n",
            "\n",
            "Page Number: 10\n",
            "Content: .\n",
            "\n",
            "Page Number: 17489725\n",
            "Content: .\n",
            "\n",
            "Page Number: 1508763\n",
            "Content: -\n",
            "\n",
            "Page Number: 2018\n",
            "Content: ) \n",
            "location based services: ongoing evolution and research agenda, journal of location based services,\n",
            "\n",
            "Page Number: 2\n",
            "Content: ,\n",
            "\n",
            "Page Number: 93\n",
            "Content: , doi:\n",
            "\n",
            "Page Number: 1080\n",
            "Content: /\n",
            "\n",
            "Page Number: 2018\n",
            "Content: .\n",
            "\n",
            "Page Number: 14\n",
            "Content: -\n",
            "mobile guides\n",
            ". mobile guides are like tourist route \n",
            "guides, downloadable apps on \n",
            "smartphones\n",
            ". similar to travel guides but being \n",
            "location-based they can personalize \n",
            "messages .. you are only 100m from an \n",
            "interesting exhibit or tourist spot\n",
            ". because the know the location of the \n",
            "user they are great opportunities for \n",
            "tourist advertising … “eat at our \n",
            "restaurant”, or “visit our museum”\n",
            "-\n",
            "\n",
            "Page Number: 2018\n",
            "Content: ) \n",
            "location based services: ongoing evolution and research agenda, journal of location based services,\n",
            "\n",
            "Page Number: 2\n",
            "Content: ,\n",
            "\n",
            "Page Number: 93\n",
            "Content: , doi:\n",
            "\n",
            "Page Number: 1080\n",
            "Content: /\n",
            "\n",
            "Page Number: 2018\n",
            "Content: .\n",
            "\n",
            "Page Number: 16\n",
            "Content: -\n",
            "location-based social networking\n",
            ". foursquare used to have 50m users but not as \n",
            "popular now \n",
            ". users used to “check in” to locations and rate \n",
            "them and accumulate points the more they \n",
            "travelled\n",
            ". based on which of your friends checked into \n",
            "where, and their ratings, a user is \n",
            "recommended places to go nearby\n",
            ". not as popular now because facebook does \n",
            "location check-ins and people are now more \n",
            "wary of tracking of users’ locations, and \n",
            "foursquare is openly tracking\n",
            "-\n",
            "\n",
            "Page Number: 2018\n",
            "Content: ) \n",
            "location based services: ongoing evolution and research agenda, journal of location based services,\n",
            "\n",
            "Page Number: 2\n",
            "Content: ,\n",
            "\n",
            "Page Number: 93\n",
            "Content: , doi:\n",
            "\n",
            "Page Number: 1080\n",
            "Content: /\n",
            "\n",
            "Page Number: 2018\n",
            "Content: .\n",
            "\n",
            "Page Number: 18\n",
            "Content: -\n",
            "assistive systems\n",
            ". assistive lbs is more than navigation \n",
            "for the elderly, it supports older adults \n",
            "with memory loss or dementia and their \n",
            "caregivers during getting lost events\n",
            ". sometimes used by defining physical \n",
            "areas where normal activities take place \n",
            "like the route to the shops or to friends \n",
            "(called geofencing) and when deviating \n",
            "from geofenced areas it triggers a \n",
            "“potentially getting lost” event\n",
            "-\n",
            "\n",
            "Page Number: 2018\n",
            "Content: ) \n",
            "location based services: ongoing evolution and research agenda, journal of location based services,\n",
            "\n",
            "Page Number: 2\n",
            "Content: ,\n",
            "\n",
            "Page Number: 93\n",
            "Content: , doi:\n",
            "\n",
            "Page Number: 1080\n",
            "Content: /\n",
            "\n",
            "Page Number: 2018\n",
            "Content: .\n",
            "\n",
            "Page Number: 20\n",
            "Content: -\n",
            "other apps\n",
            ". an open-ended catch-all category\n",
            "– lbs safety is lone workers carrying trackers\n",
            "– advertising is in-taxi screens showing \n",
            "adverts for local restaurants based on taxi \n",
            "location, or google search results on \n",
            "smartphone filtered for location\n",
            "– education is loop on mobiles, tailoring \n",
            "content depending on whether you’re on-\n",
            "campus or not\n",
            "-\n",
            "\n",
            "Page Number: 2018\n",
            "Content: ) \n",
            "location based services: ongoing evolution and research agenda, journal of location based services,\n",
            "\n",
            "Page Number: 2\n",
            "Content: ,\n",
            "\n",
            "Page Number: 93\n",
            "Content: , doi:\n",
            "\n",
            "Page Number: 1080\n",
            "Content: /\n",
            "\n",
            "Page Number: 2018\n",
            "Content: .\n",
            "\n",
            "Page Number: 22\n",
            "Content: -\n",
            "lbs in transport\n",
            ". this one is easy …\n",
            "– “free now” or uber .. you track the taxi, \n",
            "the taxi tracks you\n",
            "– parking … nearest available spots, or where \n",
            "you parked your car (google maps)\n",
            "– bus or train arrival times, on-screen bus \n",
            "locations\n",
            "– estimated arrival times on \n",
            "navigation apps based on \n",
            "where you are, and where \n",
            "everybody else is, namely \n",
            "causing traffic jams\n",
            "-\n",
            "\n",
            "Page Number: 2018\n",
            "Content: ) \n",
            "location based services: ongoing evolution and research agenda, journal of location based services,\n",
            "\n",
            "Page Number: 2\n",
            "Content: ,\n",
            "\n",
            "Page Number: 93\n",
            "Content: , doi:\n",
            "\n",
            "Page Number: 1080\n",
            "Content: /\n",
            "\n",
            "Page Number: 2018\n",
            "Content: .\n",
            "\n",
            "Page Number: 24\n",
            "Content: -\n",
            "lbs fitness monitoring\n",
            ". strava a service for running/cycling that \n",
            "uses a smartphone or watch to record \n",
            "runs or bike rides\n",
            ". it logs (gps) location and from that it \n",
            "gives time, pace, elevation gain and \n",
            "profile, power output (bike), calories, \n",
            "map .. all very useful and interesting for \n",
            "each individual\n",
            ". mapmyrun, several others exist\n",
            "-\n",
            "\n",
            "Page Number: 26\n",
            "Content: -\n",
            "haosheng huang, georg gartner, jukka m. krisp, martin raubal & nico van de weghe (\n",
            "\n",
            "Page Number: 12\n",
            "Content: :\n",
            "\n",
            "Page Number: 63\n",
            "Content: -\n",
            "\n",
            "Page Number: 10\n",
            "Content: .\n",
            "\n",
            "Page Number: 17489725\n",
            "Content: .\n",
            "\n",
            "Page Number: 1508763\n",
            "Content: -\n",
            "\n",
            "Page Number: 2016\n",
            "Content: , pokémon go is an \n",
            "augmented reality mobile game for \n",
            "smartphones\n",
            ". if you’ve played it, you’ll know it; if you \n",
            "haven’t then it will seem weird !\n",
            ". basically your cameraphone screen is \n",
            "augmented with cartoon characters that you \n",
            "have to “catch” and the characters exist at \n",
            "precise (gps) locations so you have to go to \n",
            "those locations to find them\n",
            ". if these are rare characters in the game, then \n",
            "many players will gather there, with \n",
            "smartphones and battery packs because their \n",
            "phone batteries run out ;-)\n",
            "-\n",
            "\n",
            "Page Number: 29\n",
            "Content: -\n",
            "pokémon go\n",
            "-\n",
            "\n",
            "Page Number: 31\n",
            "Content: -\n",
            "pokémon go\n",
            "-\n",
            "\n",
            "Page Number: 33\n",
            "Content: -\n",
            "haosheng huang, georg gartner, jukka m. krisp, martin raubal & nico van de weghe (\n",
            "\n",
            "Page Number: 12\n",
            "Content: :\n",
            "\n",
            "Page Number: 63\n",
            "Content: -\n",
            "\n",
            "Page Number: 10\n",
            "Content: .\n",
            "\n",
            "Page Number: 17489725\n",
            "Content: .\n",
            "\n",
            "Page Number: 1508763\n",
            "Content: -\n",
            "\n",
            "Page Number: 35\n",
            "Content: -\n",
            "augmented reality\n",
            ". one of the very attractive types of \n",
            "technology on smartphones which use \n",
            "location, camera and screen is \n",
            "augmented reality (ar)\n",
            ". virtual reality (vr) is not the same, its \n",
            "immersive, you wear a headset which \n",
            "controls all that you see, and you \n",
            "believe you move into a different world\n",
            ". in the picture here, i’m making pottery \n",
            "on a spinning wheel, or so i believe\n",
            ". vr platforms include microsoft hololens \n",
            "or oculus rift (which is facebook’s)\n",
            "-\n",
            "\n",
            "Page Number: 37\n",
            "Content: -\n",
            ".\n",
            "video shows alan’s office and \n",
            "as i move around some \n",
            "green bushes appear, then \n",
            "an actual pokémon (it’s a \n",
            "wild numen, if you didn’t \n",
            "recognize it) which i then \n",
            "catch and score points\n",
            ".\n",
            "notice this is live video \n",
            "capture, from the camera \n",
            "onto the screen, with reality \n",
            "being augmented with \n",
            "bushes appearing on my \n",
            "desk and then a pokémon\n",
            "-\n",
            "\n",
            "Page Number: 1\n",
            "Content: .\n",
            "based purely on location/compass … pokémon go is \n",
            "an example of this\n",
            "\n",
            "Page Number: 3\n",
            "Content: .\n",
            "based on a combination of the two\n",
            "-\n",
            "\n",
            "Page Number: 40\n",
            "Content: -\n",
            ". object-to-object matching \n",
            "should be invariant to size \n",
            "(object is near or far away), \n",
            "rotation, inversion, and seeing \n",
            "objects at an angle\n",
            ". this technique called sift/surf \n",
            "is how it is done … thousands of \n",
            "“interest points” in the query \n",
            "object and in objects in the \n",
            "video are matched (only some \n",
            "are shown in the image), lines \n",
            "between them are drawn and if \n",
            "the connections are mostly \n",
            "parallel lines, then it is a match\n",
            "-\n",
            "\n",
            "Page Number: 1\n",
            "Content: ) guinness gate, (\n",
            "\n",
            "Page Number: 3\n",
            "Content: ) how the \n",
            "actual gate is matched against a target image \n",
            "in the app, and (\n",
            "\n",
            "Page Number: 42\n",
            "Content: -\n",
            "ar treasure hunt\n",
            ". see an example at \n",
            "https://www.youtube.com/watch?v=tpi\n",
            "g3xrp9oy\n",
            "-\n",
            "\n",
            "Page Number: 44\n",
            "Content: -\n",
            "views on lbs\n",
            ". back to lbs … what do people really \n",
            "think of tracking of their location on \n",
            "their smartphones … the following \n",
            "series of infographics expand on this, \n",
            "available at \n",
            "https://www.skyhook.com/blog/infogra\n",
            "phic-cracking-the-code-on-location-\n",
            "services-on\n",
            "-\n",
            "\n",
            "Page Number: 46\n",
            "Content: -\n",
            "-\n",
            "\n",
            "Page Number: 48\n",
            "Content: -\n",
            "-\n",
            "\n",
            "Page Number: 50\n",
            "Content: -\n",
            ". however there are downsides to lbs, mostly \n",
            "its the personal data captured and the \n",
            "tracking that manufacturers do on us\n",
            ". lbs bring challenges (e.g. privacy, ethical, \n",
            "and legal issues)\n",
            ". most people don’t realise how much personal \n",
            "information is gathered on everyday activities\n",
            ". the next series of slides show how an iphone \n",
            "tracks and stores your location, on the device\n",
            ". go to the “settings” app and follow the menu \n",
            "options from there\n",
            "-\n",
            "\n",
            "Page Number: 52\n",
            "Content: -\n",
            "-\n",
            "\n",
            "Page Number: 54\n",
            "Content: -\n",
            "-\n",
            "\n",
            "Page Number: 56\n",
            "Content: -\n",
            "need to give password to gain access\n",
            "-\n",
            "\n",
            "Page Number: 58\n",
            "Content: -\n",
            "there’s a hierarchy of locations\n",
            "-\n",
            "\n",
            "Page Number: 60\n",
            "Content: -\n",
            "going back in time to when you last \n",
            "cleared it\n",
            "-\n",
            "\n",
            "Page Number: 62\n",
            "Content: -\n",
            ". the iphone “settings” menu just \n",
            "presents the locations, no interactions \n",
            "with them, but it is easy to hack and \n",
            "then export all my location data from \n",
            "my phone to … wherever\n",
            "-\n",
            "\n",
            "Page Number: 1\n",
            "Content: -to-\n",
            "\n",
            "Page Number: 64\n",
            "Content: -\n",
            "collaborative search\n",
            ". web search can be a social activity … \n",
            "really.\n",
            ". have you ever been, or been subjected \n",
            "to a back seat searcher … you have the \n",
            "keyboard but somebody else telling you \n",
            "what to search, what to click … grrrr !\n",
            ". search systems are for individuals –\n",
            "always so – never for groups yet we \n",
            "often search in groups either \n",
            "synchronously or asynchronously .. and \n",
            ".. there is no computational support for \n",
            "this in any of the search tools we use\n",
            "-\n",
            "\n",
            "Page Number: 66\n",
            "Content: -\n",
            "search together\n",
            ". bob decides to go out for pizza while \n",
            "jane continues to search, bob gets \n",
            "delayed so jane goes to bed and when \n",
            "he does get back, bob picks up the \n",
            "internet search while jane sleeps\n",
            ". this is asynchronous search – different \n",
            "time, same location but same search –\n",
            "and there are no computational tools to \n",
            "support this\n",
            "-\n",
            "\n",
            "Page Number: 68\n",
            "Content: -\n",
            "search together\n",
            ".\n",
            "yet we’re seeing real time (synchronous) and delayed \n",
            "(asynchronous) collaboration in other tools\n",
            ".\n",
            "google docs, sheets etc. allows synchronousand\n",
            "asynchronous editing and comments\n",
            ".\n",
            "skype for business and zoom allow synchronous \n",
            "collaboration and shared desktops\n",
            ".\n",
            "shared calendar tools, file sharing like dropbox and \n",
            "box, slack channels and more all support remote or \n",
            "shared location forms of collaboration\n",
            ".\n",
            "yet there’s no support for shared information finding \n",
            "tasks.\n",
            "-\n",
            "\n",
            "Page Number: 70\n",
            "Content: -\n",
            "week\n",
            "\n",
            "Page Number: 71\n",
            "Content: -\n",
            "kinds of context\n",
            ". location – where you are\n",
            ". activity – what you are doing now\n",
            "-\n",
            "\n",
            "Page Number: 1\n",
            "Content: or more \n",
            "sensors, so this is mostly about sensors and what we \n",
            "can do using simple sensors\n",
            ". applications are widespread - sports, ambient-\n",
            "assisted living, gaming, health and wellness, etc.\n",
            ". wouldn’t it be great to be able to identify what a \n",
            "person is doing right now... and tailor our information \n",
            "access accordingly. its not the primary function, but a \n",
            "second-order effect \n",
            ". why would this be useful?\n",
            ". how can we do it?\n",
            "\n",
            "Page Number: 73\n",
            "Content: -\n",
            "motion sensing on smartphones\n",
            ". in addition to gps, which we saw earlier, \n",
            "smartphones, watches, cars all have built-in \n",
            "motion sensors\n",
            ". accelerometers measure the acceleration of a \n",
            "moving body in a single direction\n",
            ". put\n",
            "\n",
            "Page Number: 74\n",
            "Content: -\n",
            ". gyroscopes also used to be large \n",
            "physical devices for keeping balance on \n",
            "old airplanes, now they are reduced in \n",
            "size and fit on circuits.\n",
            ". they help accelerometers to understand \n",
            "which way your phone is orientated\n",
            ". the magnetometer or compass \n",
            "measures which way the phone is \n",
            "pointed\n",
            "-\n",
            "\n",
            "Page Number: 76\n",
            "Content: -\n",
            "\n",
            "Page Number: 98\n",
            "Content: % \n",
            "accuracy in classifying activities !\n",
            ". walking, standing, running, driving, etc. are \n",
            "all detectable\n",
            ". accelerometer data is a stream of three \n",
            "numbers (tri axial) arriving at (at least)\n",
            "\n",
            "Page Number: 77\n",
            "Content: -\n",
            "how to identify human activity from accelerometers?\n",
            ".\n",
            "\n",
            "Page Number: 132\n",
            "Content: ,\n",
            "\n",
            "Page Number: 39\n",
            "Content: features (mean/range/stdev of previous\n",
            "\n",
            "Page Number: 5\n",
            "Content: /\n",
            "\n",
            "Page Number: 120\n",
            "Content: /\n",
            "\n",
            "Page Number: 0\n",
            "Content: .\n",
            "\n",
            "Page Number: 8\n",
            "Content: -\n",
            "\n",
            "Page Number: 93\n",
            "Content: % accurate\n",
            "using a range of machine learning classifiers: logistic \n",
            "regression, naïve bayes, svm, etc.\n",
            "\n",
            "Page Number: 79\n",
            "Content: -\n",
            "identifying activities\n",
            "walking =\n",
            "\n",
            "Page Number: 8\n",
            "Content: -\n",
            "\n",
            "Page Number: 98\n",
            "Content: % accurate\n",
            "\n",
            "Page Number: 81\n",
            "Content: -\n",
            "identifying activities\n",
            "lying down and resting =\n",
            "\n",
            "Page Number: 82\n",
            "Content: -\n",
            "activity detection\n",
            ".\n",
            "so with a smartphone in your pocket, or a fitness band \n",
            "on your wrist, we can classify what you are doing, in \n",
            "real time\n",
            ".\n",
            "why would we bother ?\n",
            ".\n",
            "google speech on mobile uses accelerometers to detect \n",
            "when the phone is moved to the mouth to ‘speak’\n",
            "queries on android -> that kicks in automatic speech \n",
            "recognition for a user query\n",
            ".\n",
            "also used to trigger siri on phone\n",
            ".\n",
            "could extend this further … knowing what the (mobile) \n",
            "user is doing based on accelerometer activities (and \n",
            "combine with location), select when to alert, what to \n",
            "search, etc.\n",
            ".\n",
            "problem with using the phone for this is we don’t “wear” \n",
            "the phone, but we do wear the watch ?\n",
            "-\n",
            "\n",
            "Page Number: 84\n",
            "Content: -\n",
            "more elaborate motion/activity capture\n",
            ". traditional approach to motion \n",
            "capture is a vicon recording studio\n",
            ".in this, a user wears more than a \n",
            "dozen “markers” reflective spheres, \n",
            "at the joints of limbs (knees, ankles, \n",
            "elbows, etc.\n",
            ".a network of infra-red lights and cameras around the subject \n",
            "capture the markers and in real time, combine them to generate \n",
            "a 3d model of the user\n",
            ".this is very accurate - sampling rate is\n",
            "\n",
            "Page Number: 7\n",
            "Content: -\n",
            "\n",
            "Page Number: 86\n",
            "Content: -\n",
            "\n",
            "Page Number: 86\n",
            "Content: motion capture, our approach\n",
            ". inertial sensing\n",
            "– synthesize realistic motion from \n",
            "inertial measurement units (imu)\n",
            ". contextual information\n",
            "– single low-cost camera if available\n",
            ". off-line\n",
            "– capture prototypical movements\n",
            "– build motion graph\n",
            ". pre-capture\n",
            "– define imu placement\n",
            "– add virtual imu data to motion graph\n",
            ". on-line\n",
            "– search motion graph\n",
            "– match virtual & real imu data\n",
            "\n",
            "Page Number: 87\n",
            "Content: -\n",
            "how well does it work ?\n",
            "\n",
            "Page Number: 87\n",
            "Content: \n",
            "\n",
            "Page Number: 88\n",
            "Content: -\n",
            "kinect\n",
            ". and then came the microsoft kinect !\n",
            ". sits on top of a tv or computer screen and \n",
            "contains an integrated microphone array, \n",
            "visible spectrum camera and ir-based depth \n",
            "camera\n",
            ". intended to be a proprietary interface to the \n",
            "x-box gaming console but it was quickly \n",
            "hacked, so microsoft gave up and released an \n",
            "api so anyone could use it for anything\n",
            "-\n",
            "\n",
            "Page Number: 90\n",
            "Content: -\n",
            "microsoft kinect\n",
            ". kinect is a form of ar\n",
            ". works by sending out patterns of dots \n",
            "in invisible spectrum light, and then \n",
            "picks them up with a camera\n",
            ". https://www.youtube.com/watch?v=dt\n",
            "klngsh9po&feature=related\n",
            ". using this, kinect knows how far you \n",
            "are from the camera (depth map) and \n",
            "can augment the video camera image \n",
            "on the screen\n",
            ". one example app is the virtual dressing \n",
            "room where you can “try on” clothes …\n",
            "-\n",
            "\n",
            "Page Number: 9\n",
            "Content: \n",
            "\n",
            "Page Number: 92\n",
            "Content: -\n",
            ". details at \n",
            "https://www.youtube.com/watch?v=\n",
            "\n",
            "Page Number: 93\n",
            "Content: -\n",
            "slide\n",
            "\n",
            "Page Number: 94\n",
            "Content: -\n",
            "texture-based retrieval results\n",
            ".\n",
            "query :\n",
            "top\n",
            "\n",
            "Page Number: 95\n",
            "Content: -\n",
            "texture-based retrieval results\n",
            ".\n",
            "query :\n",
            "top\n",
            "\n",
            "Page Number: 96\n",
            "Content: -\n",
            "colour-based retrieval results\n",
            "query :\n",
            "top\n",
            "\n",
            "Page Number: 97\n",
            "Content: -\n",
            "kinect\n",
            ". best hacks … \n",
            ". #\n",
            "\n",
            "Page Number: 9\n",
            "Content: (wall) we did this for nmi treasure \n",
            "room (award-winning at mm2011)\n",
            ". play the others and be inspired !\n",
            ". all revolve around sensing what you are \n",
            "doing, now\n",
            "-\n",
            "\n",
            "Page Number: 99\n",
            "Content: -\n",
            "week\n",
            "\n",
            "Page Number: 100\n",
            "Content: sensing the body - physiology\n",
            ". our physiology is the set of outward signs that \n",
            "our body gives constantly, to indicate what state \n",
            "our bodies are in.\n",
            ". for example \n",
            "– when we perspire its an indication we’re too hot and \n",
            "we need to cool down; \n",
            "– when we’ve goosepimples on our arms it means the \n",
            "environment is too cold for us and we need to \n",
            "preserve heat hence the goosepimples; \n",
            "– when our breathing is fast it means we’re extending \n",
            "ourselves and we need to get more oxygen into our \n",
            "blood streams because we’re exercising, or we’re \n",
            "tense\n",
            "-\n",
            "\n",
            "Page Number: 102\n",
            "Content: sensing the body - physiology\n",
            ". mostly, and the main reason we sense our bodies, is for \n",
            "health reasons, \n",
            "– we monitor our heart rate when we exercise\n",
            "– we track our movement so as to count our exercise or number of \n",
            "steps taken in a day\n",
            "– older people at home and lone workers in forests and remote areas \n",
            "wear fall detectors to detect when accidents have occurred\n",
            "– the hard of hearing use hearing aids and some people have their \n",
            "heart rates regularised with implanted pacemakers, etc. \n",
            ". while health and wellness reasons are the main reason, \n",
            "there are others also, like measuring our reaction to \n",
            "advertising material (just as an example)\n",
            "-\n",
            "\n",
            "Page Number: 104\n",
            "Content: . lets see some examples …. (see slide \n",
            "note)\n",
            ". we’ll now see a series of images, each \n",
            "of which will (probably) induce some \n",
            "emotional reaction from you.\n",
            ". lets see them … \n",
            "-\n",
            "\n",
            "Page Number: 106\n",
            "Content: -\n",
            "\n",
            "Page Number: 108\n",
            "Content: . these adverts are different … they \n",
            "induce a sense of … cute !\n",
            ". they’re meant to make you smile, you \n",
            "may even have laughed a bit (go on, \n",
            "admit it)\n",
            ". you get a warm fuzzy feeling inside \n",
            "when seeing these\n",
            "-\n",
            "\n",
            "Page Number: 110\n",
            "Content: . problems with these include\n",
            "– a time lag between seeing the stimulus and \n",
            "having to describe the reaction afterwards\n",
            "– memory – not being able to remember \n",
            "exactly and to what intensity you connected \n",
            "with the stimulus\n",
            "– subjective judgments – one person might \n",
            "be a hard judge and slow to rate highly \n",
            "whereas another might be more generous, \n",
            "for the same content\n",
            "– difficulty in verbally describing their \n",
            "emotions/response … remember in mooc-\n",
            "\n",
            "Page Number: 111\n",
            "Content: . so this begs the question of whether \n",
            "there are valid and objective \n",
            "measurements of psychophysiological \n",
            "responses to a stimulus … i.e. can we \n",
            "measure our physiology and how it \n",
            "changes when we experience a stimulus\n",
            ". our bodies have evolved a basic  \n",
            "(sympathetic) nervous system which \n",
            "reacts to an unexpected stimulus in one \n",
            "of two ways … we’re either going to \n",
            "fight, or flight, and our physiology \n",
            "reacts\n",
            "-\n",
            "\n",
            "Page Number: 113\n",
            "Content: measuring heart rate\n",
            ". heart rate can be measured by\n",
            "\n",
            "Page Number: 2\n",
            "Content: . listening to the chest\n",
            "\n",
            "Page Number: 4\n",
            "Content: . sensing minute changes in blood flow via \n",
            "photoplethysmography\n",
            ". (\n",
            "\n",
            "Page Number: 2\n",
            "Content: ) are ambulatory, for \n",
            "emergency response while (\n",
            "\n",
            "Page Number: 4\n",
            "Content: ) \n",
            "can be embedded in wearable sensors\n",
            "-\n",
            "\n",
            "Page Number: 115\n",
            "Content: . measuring hr using \n",
            "photoplethysmography (ppg) is \n",
            "an optical technique measuring \n",
            "blood flow changes based on \n",
            "shining an led into the skin and \n",
            "sensing colour changes using a \n",
            "second led which reads the \n",
            "light form the first led\n",
            ". used on watches like apple \n",
            "watch where you see\n",
            "\n",
            "Page Number: 2\n",
            "Content: leds “watching” for changes in \n",
            "light\n",
            "measuring heart rate\n",
            "-\n",
            "\n",
            "Page Number: 117\n",
            "Content: measuring blood pressure\n",
            ". blood pressure (bp) normally rises and falls \n",
            "throughout the day but persistently high is \n",
            "bad, long-lasting is called hypertension\n",
            ". bp normally measured by a health practitioner \n",
            "as its two numbers, pressure when it beats, \n",
            "and between beats, and uses a cuff around \n",
            "the upper arm\n",
            ". bp changes slowly, not instantly, so it’s a \n",
            "longitudinal measure\n",
            ". smartphones already have a wide array of \n",
            "sensors inside, but can't measure bp — at \n",
            "least not yet\n",
            "-\n",
            "\n",
            "Page Number: 119\n",
            "Content: measuring respiration\n",
            ". respiration is a really good indicator of the \n",
            "body’s state, but really difficult to measure.\n",
            ". respiration rate is breaths per minute but \n",
            "these could be deep, or shallow, so also need \n",
            "the volume of air breathed\n",
            ". gold standard is a face mask (awkward, \n",
            "cumbersome) but wearable vests that \n",
            "measure expanding/contracting chests are \n",
            "now available\n",
            "-\n",
            "\n",
            "Page Number: 121\n",
            "Content: -\n",
            "\n",
            "Page Number: 123\n",
            "Content: polygraph\n",
            "test truthfulness\n",
            "gsr, hr, bp & rr\n",
            "-\n",
            "\n",
            "Page Number: 125\n",
            "Content: -\n",
            "\n",
            "Page Number: 127\n",
            "Content: -\n",
            "\n",
            "Page Number: 5\n",
            "Content: stages – wake, relaxed \n",
            "wakefulness, light sleep, deep sleep and \n",
            "rem sleep\n",
            ". starts from n1, goes through n2 to n3 \n",
            "(deep) and then back up towards rem \n",
            "sleep, there is an ordering\n",
            ". the first sleep cycle is usually shortest at\n",
            "\n",
            "Page Number: 100\n",
            "Content: minutes. later cycles are\n",
            "\n",
            "Page Number: 110\n",
            "Content: minutes. \n",
            ". if you sleep for\n",
            "\n",
            "Page Number: 5\n",
            "Content: full \n",
            "cycles\n",
            "sleep explained\n",
            "-\n",
            "\n",
            "Page Number: 130\n",
            "Content: why is sleep important ?\n",
            ". it is believed that during sleep we re-live \n",
            "(parts of) our day, deciding which parts are \n",
            "more/less important and worth remembering\n",
            ". insufficient sleep makes you more stupid, \n",
            "fatter, unhappier, poorer, sicker, worse at sex, \n",
            "more grumpy, more likely to get cancer, \n",
            "alzheimer’s and more likely to die in a car \n",
            "crash !  who says … see book on next slide.\n",
            ". recent years have focused on this, we’re more \n",
            "aware, partly because we ourselves can now \n",
            "measure it, exploiting its structured, \n",
            "predictable, and characteristic nature\n",
            ". orthosomnia - preoccupation with perfecting \n",
            "sleep data\n",
            "-\n",
            "\n",
            "Page Number: 132\n",
            "Content: . insufficient sleep leads to reduced blood \n",
            "flow to the skin in the face, so \n",
            "complexion is drab, ashen and reveals \n",
            "dark areas\n",
            ". leads to dark circles under the eyes, \n",
            "topical creams used to camouflage \n",
            ". also more wrinkles because less \n",
            "collagen produced, puffy eyes, no \n",
            "“glow”\n",
            ". … and … you don’t look happy\n",
            "sleep and appearance\n",
            "-\n",
            "\n",
            "Page Number: 134\n",
            "Content: -\n",
            "\n",
            "Page Number: 1\n",
            "Content: . phone apps\n",
            "\n",
            "Page Number: 3\n",
            "Content: . movement radar or sonar\n",
            "\n",
            "Page Number: 136\n",
            "Content: presented as a hypnogram\n",
            "-\n",
            "\n",
            "Page Number: 1\n",
            "Content: . smartphone apps\n",
            "-\n",
            "\n",
            "Page Number: 2\n",
            "Content: . wrist-worn accelerometers \n",
            "-\n",
            "\n",
            "Page Number: 3\n",
            "Content: . sonar / radar\n",
            "-\n",
            "\n",
            "Page Number: 4\n",
            "Content: . the ōura ring\n",
            ". from a finnish start-up, a (finger) \n",
            "ring with in-built accelerometer and \n",
            "gyroscope and also measures \n",
            "body temperature, and heart rate\n",
            ". hr sampled using ir spectrum \n",
            "light from\n",
            "\n",
            "Page Number: 250\n",
            "Content: hz so \n",
            "able to do much more than wrist-\n",
            "worn hr sensors\n",
            ". contactless battery charge lasts\n",
            "\n",
            "Page Number: 6\n",
            "Content: weeks\n",
            ". low power bluetooth download to \n",
            "phone \n",
            "-\n",
            "\n",
            "Page Number: 142\n",
            "Content: and what about alan’s sleep ?\n",
            ". here’s a sample of summary data over\n",
            "\n",
            "Page Number: 143\n",
            "Content: and what about alan’s sleep ?\n",
            "-\n",
            "\n",
            "Page Number: 145\n",
            "Content: . some use it to inform or influence day-to-day \n",
            "activities\n",
            ". some look at trends, but the trends don’t say a lot \n",
            "because other factors influence those trends \n",
            "(travel, vacation, stress, colds and flu, sports \n",
            "events, etc.) and we can’t see those.\n",
            ". that’s because sleep apps, activity apps, health \n",
            "apps, all work independently of each other, not \n",
            "synchronised\n",
            ". so there is not a lot we can actually usefully do \n",
            "with our own sleep data or any other lifelog data\n",
            ". we can’t easily integrate it or re-purpose it and \n",
            "because it reports day-at-a-time information its \n",
            "difficult to get useful longitudinal analysis.\n",
            "so what to do with this information ?\n",
            "-\n",
            "\n",
            "Page Number: 1\n",
            "Content: . we can aggregate our own personal \n",
            "data with data from other users, \n",
            "across a population\n",
            "\n",
            "Page Number: 147\n",
            "Content: . almost all vendors who allow us gather \n",
            "individual data, get value from pooling \n",
            "anonymised data\n",
            ". let’s look at\n",
            "\n",
            "Page Number: 148\n",
            "Content: . fitbit – wearable wrist-worn activity logger \n",
            "and sleep recorder\n",
            ". fitbit mined 150b hours of heart rate data, \n",
            "gathering statistics from millions of sleep \n",
            "nights and discovered the following\n",
            "population-level analytics from pooled \n",
            "individual data\n",
            "-\n",
            "\n",
            "Page Number: 150\n",
            "Content: . some fitbit devices also record heart \n",
            "rate, so they mined that to correlate \n",
            "resting heart rate (a wellness indicator) \n",
            "with body-mass index (a weight \n",
            "indicator), age, and amount of exercise \n",
            ". they found insights that cardiologists \n",
            "were not aware of\n",
            "-\n",
            "\n",
            "Page Number: 150\n",
            "Content: -billion-hours-heart-data-reveals-secrets-human-health-\n",
            "\n",
            "Page Number: 152\n",
            "Content: population-level analytics from pooled \n",
            "individual data\n",
            ". 23andme is a dna testing company \n",
            "who’s catchphrase is to allow you to \n",
            "”meet your genes”\n",
            ". from a saliva sample they synthesise\n",
            "your dna and search it for dna \n",
            "markers which\n",
            "\n",
            "Page Number: 2\n",
            "Content: . report your genetic health risks (whether \n",
            "you have genetic variants associated with \n",
            "increased risk for certain(+\n",
            "\n",
            "Page Number: 153\n",
            "Content: population-level analytics from \n",
            "pooled individual data\n",
            ". 23andme provides benefit to the \n",
            "individual (gene markers) but even \n",
            "more benefit when data is pooled in \n",
            "order to connect relatives and \n",
            "determine actual exposure risk to \n",
            "diseases based on population analysis\n",
            "-\n",
            "\n",
            "Page Number: 155\n",
            "Content: -\n",
            "\n",
            "Page Number: 157\n",
            "Content: -\n",
            "\n",
            "Page Number: 2\n",
            "Content: years, \n",
            "updated monthly, showing areas where \n",
            "people run/cycle \n",
            ". next slide is dcu campus, albert \n",
            "college park stands out clearly\n",
            ". slide after that is running in dublin, \n",
            "phoenix park main avenue is a clear \n",
            "hotspot\n",
            "-\n",
            "\n",
            "Page Number: 160\n",
            "Content: -\n",
            "\n",
            "Page Number: 2014\n",
            "Content: a\n",
            "\n",
            "Page Number: 0\n",
            "Content: earthquake hit napa \n",
            "valley in northern california\n",
            ". jawbone mined the sleep data of those \n",
            "using their wearable to determine the \n",
            "% of people in each area woken by the \n",
            "earthquake\n",
            ". the theory is the stringer the quake in \n",
            "a given area, the greater % of people \n",
            "who will wake up\n",
            "-\n",
            "\n",
            "Page Number: 2014\n",
            "Content: – northern calif.\n",
            "\n",
            "Page Number: 163\n",
            "Content: -\n",
            "\n",
            "Page Number: 165\n",
            "Content: \n",
            "\n",
            "Page Number: 6\n",
            "Content: . consolidates health data from iphone, \n",
            "apple watch, third-party apps \n",
            ". activity, sleep, mindfulness, and \n",
            "nutrition\n",
            ". “you are in charge of your data”\n",
            ". “the health app lets you keep all your \n",
            "health and fitness information under \n",
            "your control and in one place on your \n",
            "device. you decide which information \n",
            "is placed in health and which apps \n",
            "can access your data through the \n",
            "health app”\n",
            "apple healthkit\n",
            "aggregating our own personal data \n",
            "across sensors\n",
            "-\n",
            "\n",
            "Page Number: 167\n",
            "Content: dacadoo\n",
            "-\n",
            "\n",
            "Page Number: 169\n",
            "Content: dacadoo\n",
            "-\n",
            "\n",
            "Page Number: 171\n",
            "Content: dacadoo\n",
            "-\n",
            "\n",
            "Page Number: 173\n",
            "Content: another example of combining \n",
            "across sensors\n",
            ". another example of how to combine the \n",
            "sensors together, work we did for the race \n",
            "around ireland cycle race\n",
            "– non-stop,\n",
            "\n",
            "Page Number: 350\n",
            "Content: miles, solo or team of\n",
            "\n",
            "Page Number: 4\n",
            "Content: /\n",
            "\n",
            "Page Number: 174\n",
            "Content: sports - cycling\n",
            "so we instrumented a team of\n",
            "\n",
            "Page Number: 24\n",
            "Content: hous a day for\n",
            "\n",
            "Page Number: 175\n",
            "Content: sports - cycling\n",
            ". we aggregated all this data for each of\n",
            "\n",
            "Page Number: 176\n",
            "Content: sports - cycling\n",
            ". this was their aggregated effort, \n",
            "aggregated from multiple sensors:\n",
            "-\n",
            "\n",
            "Page Number: 4\n",
            "Content: : sensing the brain\n",
            ".\n",
            "the structure of the human brain … neurons firing … \n",
            "electrical signals which we can sense with eeg\n",
            ".\n",
            "eeg kit and an outline of some variations of it\n",
            ".\n",
            "what can eeg be used for\n",
            ".\n",
            "localising areas in the brain to see what areas are \n",
            "active\n",
            ".\n",
            "pareodolia\n",
            ".\n",
            "erps p300\n",
            ".\n",
            "bcis\n",
            "-\n",
            "\n",
            "Page Number: 179\n",
            "Content: the human brain\n",
            ".\n",
            "\n",
            "Page Number: 2\n",
            "Content: % of our body weight, made of 86b \n",
            "neurons (grey matter) connected by trillions of \n",
            "connections (synapses) which transmit electric \n",
            "pulses as messages\n",
            ". this architecture of huge number of \n",
            "simple connected processors, is now\n",
            "realised as good for solving very \n",
            "complex problems, like vision, and learning\n",
            ". (that’s why we have deep learning and “ai”)\n",
            ". the brain is responsible for executive \n",
            "functions both autonomic (heart, breathing, \n",
            "digestion, etc.) and voluntary, in addition to \n",
            "executive functions like self-control, planning, \n",
            "reasoning, memory and abstract thought.\n",
            "-\n",
            "\n",
            "Page Number: 181\n",
            "Content: human memory\n",
            ". like the human genome mapping project \n",
            "which ran\n",
            "\n",
            "Page Number: 2003\n",
            "Content: and who’s task was to \n",
            "map the sequence of dna base pairs that \n",
            "made up the human dna, there is a brain \n",
            "mapping project, announced by obama in\n",
            "\n",
            "Page Number: 1\n",
            "Content: .5b human brain \n",
            "project,\n",
            "\n",
            "Page Number: 2023\n",
            "Content: , largest scientific eu \n",
            "project ever,\n",
            "\n",
            "Page Number: 6\n",
            "Content: themes:\n",
            "-\n",
            "\n",
            "Page Number: 183\n",
            "Content: . we know the brain consists of simple but \n",
            "massively parallel processing\n",
            ". each of the 86b cells in the brain connects to\n",
            "\n",
            "Page Number: 184\n",
            "Content: human memory\n",
            ". as a re-cap from earlier mooc on memory … \n",
            ". sensory – short term, \n",
            "rapid decay unless \n",
            "refreshed, passed to…\n",
            ". short-term if attentive,\n",
            "the “post-it” note, \n",
            "usually only\n",
            "\n",
            "Page Number: 185\n",
            "Content: brain activity\n",
            ". so if brain activity is “only” firing neural \n",
            "circuits, can we “listen” to this by sensing the \n",
            "electrical activity ? \n",
            ". yes of course\n",
            ". bci (brain computer interface) is a \n",
            "communication channel capable of operation \n",
            "entirely on neural signals\n",
            ". many sensing technologies exist: \n",
            "eeg, nir, meg, pet, ecog, local field \n",
            "potentials, fmri\n",
            ". each offers its own interaction paradigms and \n",
            "capabilities but we are interested in eeg\n",
            "-\n",
            "\n",
            "Page Number: 1\n",
            "Content: or\n",
            "\n",
            "Page Number: 32\n",
            "Content: ,\n",
            "\n",
            "Page Number: 128\n",
            "Content: (as in image)\n",
            "or even\n",
            "\n",
            "Page Number: 187\n",
            "Content: eeg\n",
            ". some more \n",
            "examples of \n",
            "eeg\n",
            "-\n",
            "\n",
            "Page Number: 189\n",
            "Content: eeg – what to measure ?\n",
            ".\n",
            "in mooc\n",
            "\n",
            "Page Number: 2\n",
            "Content: -node eeg \n",
            ".\n",
            "so we can use eeg to measure attention in a way that \n",
            "is similar to “listening” to the amount of “traffic” in the \n",
            "brain, not localising it or determining where in the \n",
            "brain, just how active the brain actually is\n",
            ".\n",
            "but we can do more \n",
            "when we determine \n",
            "where in the brain, the\n",
            "activity is, so we use \n",
            "many nodes and even\n",
            "triangulate to pinpoint\n",
            "the places in the brain \n",
            "where the greatest activities\n",
            "are\n",
            "-\n",
            "\n",
            "Page Number: 191\n",
            "Content: . we are interested in erps (event related \n",
            "potentials) electrical responses at certain scalp \n",
            "points, generated by the brain in response to \n",
            "stimuli such as an image, \n",
            "sound, touch, taste… \n",
            ". there are several \n",
            "known erps including \n",
            "p1, n1, p2, n2 and p3\n",
            "which occur\n",
            "\n",
            "Page Number: 170\n",
            "Content: ,\n",
            "\n",
            "Page Number: 250\n",
            "Content: and\n",
            "\n",
            "Page Number: 3\n",
            "Content: .\n",
            "\n",
            "Page Number: 5543904\n",
            "Content: -\n",
            "\n",
            "Page Number: 193\n",
            "Content: a face\n",
            "-\n",
            "\n",
            "Page Number: 1996\n",
            "Content: , in certain parts of \n",
            "your brain (unless you were mindwandering or \n",
            "asleep and didn’t actually see the face, so pay \n",
            "attention !)\n",
            ". it was probably around your occipitotemporal \n",
            "area, slightly to the right side, \n",
            "between pz and p4\n",
            ". if you had a couple of eeg nodes\n",
            "there then\n",
            "\n",
            "Page Number: 17\n",
            "Content: seconds after\n",
            "seeing michael d’s face on \n",
            "your screen, they would have \n",
            "detected a voltage change\n",
            "-\n",
            "\n",
            "Page Number: 0\n",
            "Content: .\n",
            "\n",
            "Page Number: 196\n",
            "Content: -\n",
            "\n",
            "Page Number: 198\n",
            "Content: -\n",
            "\n",
            "Page Number: 200\n",
            "Content: p300 elicitation\n",
            ". we’re going to show a series of \n",
            "images, about\n",
            "\n",
            "Page Number: 201\n",
            "Content: p300 elicitation\n",
            "-\n",
            "\n",
            "Page Number: 203\n",
            "Content: p300 elicitation\n",
            "-\n",
            "\n",
            "Page Number: 205\n",
            "Content: p300 elicitation\n",
            "-\n",
            "\n",
            "Page Number: 207\n",
            "Content: p300 elicitation\n",
            "-\n",
            "\n",
            "Page Number: 209\n",
            "Content: p300 elicitation\n",
            "-\n",
            "\n",
            "Page Number: 211\n",
            "Content: p300 elicitation\n",
            "-\n",
            "\n",
            "Page Number: 213\n",
            "Content: p300 elicitation\n",
            "-\n",
            "\n",
            "Page Number: 215\n",
            "Content: p300 wave\n",
            ".\n",
            "there’s nothing special about the coke \n",
            "can. it’s just that you did not know when \n",
            "it was going to appear, and since i told \n",
            "you to look out for it, its appearance \n",
            "caught your attention, you recognised it\n",
            ".\n",
            "i could have as equally used any object \n",
            "that you may be looking for or expecting \n",
            ".\n",
            "so there is an idea that when searching \n",
            "for images, we can have a bci interface \n",
            "based on using eeg sensors to detect \n",
            "when you see something you recognise\n",
            ".\n",
            "researchers (like us) are working on this \n",
            "kind of interface\n",
            "-\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def split_text_into_pages(text):\n",
        "    # Replace bullet points with a full stop\n",
        "    text = text.replace('•', '.')\n",
        "    text = text.lower()\n",
        "\n",
        "    # Trying to define the pattern for page numbers\n",
        "    page_pattern = re.compile(r'\\b\\d+\\b')\n",
        "\n",
        "    # Find all occurrences of the pattern\n",
        "    matches = page_pattern.finditer(text)\n",
        "\n",
        "    page_numbers = []\n",
        "    page_contents = []\n",
        "\n",
        "    # Iterate through the matches\n",
        "    matches_iter = iter(matches)\n",
        "    for match in matches_iter:\n",
        "        # Extract page number and content\n",
        "        page_number = int(match.group().strip())\n",
        "\n",
        "        # End position of the current match\n",
        "        end_pos = match.end()\n",
        "        # Position of next match\n",
        "        next_match = next(matches_iter, None)\n",
        "        content = text[end_pos:next_match.start()] if next_match else text[end_pos:]\n",
        "\n",
        "        page_numbers.append(page_number)\n",
        "        page_contents.append(content.strip())\n",
        "\n",
        "    return page_numbers, page_contents\n",
        "\n",
        "page_numbers, page_contents = split_text_into_pages(extracted_text)\n",
        "\n",
        "for page_number, content in zip(page_numbers, page_contents):\n",
        "    print(f\"Page Number: {page_number}\\nContent: {content}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I am converting the lists produced by the above function to create a dataframe and export it to a csv file in a folder I created called preproccessed_data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFV_5_i5TrXN",
        "outputId": "335c91b6-b7df-4b84-ee5f-18e61ab4f1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Page                                           Contents\n",
            "0       1                                            -\\nMOOC\n",
            "1       2                            -\\nOverview\\n. In MOOC-\n",
            "2       2  we’ll look at technologies for \\nsensing the h...\n",
            "3       4  -\\nKinds of Context\\n. There is no universally...\n",
            "4       5                                            -\\nWeek\n",
            "..    ...                                                ...\n",
            "225   207                                P300 elicitation\\n-\n",
            "226   209                                P300 elicitation\\n-\n",
            "227   211                                P300 elicitation\\n-\n",
            "228   213                                P300 elicitation\\n-\n",
            "229   215  P300 wave\\n.\\nThere’s nothing special about th...\n",
            "\n",
            "[230 rows x 2 columns]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = data = {'Page': page_numbers,\n",
        "        'Contents': page_contents}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# Created approximately 14 extra splits through the text\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "bNizN3QIUhQg"
      },
      "outputs": [],
      "source": [
        "csv_file_path = \"preprocessed_data/preproccesed.csv\"\n",
        "df.to_csv(csv_file_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
